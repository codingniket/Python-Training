{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1Br7I2_vqhtd"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "spark = SparkSession.builder \\\n",
        ".appName(\"Food Delivery Analytics\") \\\n",
        ".getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "orders_data = [\n",
        "(\"O001\",\"North\",\"Delhi\",\"Rest-01\",\"Pizza\",\"2024-02-01\",450,35),\n",
        "(\"O002\",\"North\",\"Delhi\",\"Rest-01\",\"Burger\",\"2024-02-01\",250,25),\n",
        "(\"O003\",\"North\",\"Chandigarh\",\"Rest-02\",\"Pasta\",\"2024-02-02\",350,30),\n",
        "(\"O004\",\"South\",\"Bangalore\",\"Rest-03\",\"Pizza\",\"2024-02-01\",500,40),\n",
        "(\"O005\",\"South\",\"Chennai\",\"Rest-04\",\"Burger\",\"2024-02-02\",220,20),\n",
        "(\"O006\",\"South\",\"Bangalore\",\"Rest-03\",\"Pasta\",\"2024-02-03\",380,32),\n",
        "(\"O007\",\"East\",\"Kolkata\",\"Rest-05\",\"Pizza\",\"2024-02-01\",420,38),\n",
        "(\"O008\",\"East\",\"Kolkata\",\"Rest-05\",\"Burger\",\"2024-02-02\",260,26),\n",
        "(\"O009\",\"East\",\"Patna\",\"Rest-06\",\"Pasta\",\"2024-02-03\",300,28),\n",
        "(\"O010\",\"West\",\"Mumbai\",\"Rest-07\",\"Pizza\",\"2024-02-01\",520,42),\n",
        "(\"O011\",\"West\",\"Mumbai\",\"Rest-07\",\"Burger\",\"2024-02-02\",280,27),\n",
        "(\"O012\",\"West\",\"Pune\",\"Rest-08\",\"Pasta\",\"2024-02-03\",340,31),\n",
        "(\"O013\",\"North\",\"Delhi\",\"Rest-01\",\"Pizza\",\"2024-02-04\",480,37),\n",
        "(\"O014\",\"South\",\"Chennai\",\"Rest-04\",\"Pizza\",\"2024-02-04\",510,41),\n",
        "(\"O015\",\"East\",\"Patna\",\"Rest-06\",\"Burger\",\"2024-02-04\",240,24),\n",
        "(\"O016\",\"West\",\"Pune\",\"Rest-08\",\"Pizza\",\"2024-02-04\",500,39),\n",
        "(\"O017\",\"North\",\"Chandigarh\",\"Rest-02\",\"Burger\",\"2024-02-05\",260,26),\n",
        "(\"O018\",\"South\",\"Bangalore\",\"Rest-03\",\"Burger\",\"2024-02-05\",290,29),\n",
        "(\"O019\",\"East\",\"Kolkata\",\"Rest-05\",\"Pasta\",\"2024-02-05\",360,33),\n",
        "(\"O020\",\"West\",\"Mumbai\",\"Rest-07\",\"Pasta\",\"2024-02-05\",390,34),\n",
        "(\"O021\",\"North\",\"Delhi\",\"Rest-01\",\"Pasta\",\"2024-02-06\",370,30),\n",
        "(\"O022\",\"South\",\"Chennai\",\"Rest-04\",\"Pasta\",\"2024-02-06\",330,29),\n",
        "(\"O023\",\"East\",\"Patna\",\"Rest-06\",\"Pizza\",\"2024-02-06\",460,36),\n",
        "(\"O024\",\"West\",\"Pune\",\"Rest-08\",\"Burger\",\"2024-02-06\",270,26)\n",
        "]\n",
        "columns = [\n",
        "\"order_id\",\"region\",\"city\",\"restaurant_id\",\n",
        "\"food_item\",\"order_date\",\"amount\",\"delivery_time_min\"\n",
        "]\n",
        "df_orders = spark.createDataFrame(orders_data, columns)\n",
        "df_orders.show(5)\n",
        "df_orders.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_io5RCIBqrq_",
        "outputId": "ab2097a0-0161-409d-cc5d-25ac06b4b4b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+----------+-------------+---------+----------+------+-----------------+\n",
            "|order_id|region|      city|restaurant_id|food_item|order_date|amount|delivery_time_min|\n",
            "+--------+------+----------+-------------+---------+----------+------+-----------------+\n",
            "|    O001| North|     Delhi|      Rest-01|    Pizza|2024-02-01|   450|               35|\n",
            "|    O002| North|     Delhi|      Rest-01|   Burger|2024-02-01|   250|               25|\n",
            "|    O003| North|Chandigarh|      Rest-02|    Pasta|2024-02-02|   350|               30|\n",
            "|    O004| South| Bangalore|      Rest-03|    Pizza|2024-02-01|   500|               40|\n",
            "|    O005| South|   Chennai|      Rest-04|   Burger|2024-02-02|   220|               20|\n",
            "+--------+------+----------+-------------+---------+----------+------+-----------------+\n",
            "only showing top 5 rows\n",
            "root\n",
            " |-- order_id: string (nullable = true)\n",
            " |-- region: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- restaurant_id: string (nullable = true)\n",
            " |-- food_item: string (nullable = true)\n",
            " |-- order_date: string (nullable = true)\n",
            " |-- amount: long (nullable = true)\n",
            " |-- delivery_time_min: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EXERCISE SET 1 — SELECT OPERATIONS"
      ],
      "metadata": {
        "id": "mzCf3UTmrCCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Select only order_id , region , food_item , amount"
      ],
      "metadata": {
        "id": "mkaste_krDim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_orders.select(\"order_id\", \"region\", \"food_item\", \"amount\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ9I7QBwq1ZT",
        "outputId": "a60d216d-accf-4e51-902e-3cf31c48afda"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+---------+------+\n",
            "|order_id|region|food_item|amount|\n",
            "+--------+------+---------+------+\n",
            "|    O001| North|    Pizza|   450|\n",
            "|    O002| North|   Burger|   250|\n",
            "|    O003| North|    Pasta|   350|\n",
            "|    O004| South|    Pizza|   500|\n",
            "|    O005| South|   Burger|   220|\n",
            "|    O006| South|    Pasta|   380|\n",
            "|    O007|  East|    Pizza|   420|\n",
            "|    O008|  East|   Burger|   260|\n",
            "|    O009|  East|    Pasta|   300|\n",
            "|    O010|  West|    Pizza|   520|\n",
            "|    O011|  West|   Burger|   280|\n",
            "|    O012|  West|    Pasta|   340|\n",
            "|    O013| North|    Pizza|   480|\n",
            "|    O014| South|    Pizza|   510|\n",
            "|    O015|  East|   Burger|   240|\n",
            "|    O016|  West|    Pizza|   500|\n",
            "|    O017| North|   Burger|   260|\n",
            "|    O018| South|   Burger|   290|\n",
            "|    O019|  East|    Pasta|   360|\n",
            "|    O020|  West|    Pasta|   390|\n",
            "+--------+------+---------+------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Rename amount to order_value"
      ],
      "metadata": {
        "id": "dn9w07qZrZkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_orders.select(\n",
        "    col(\"amount\").alias(\"order_value\")\n",
        ").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91AZINNerSxz",
        "outputId": "9df5ca9c-cb64-48db-8b91-9797ea63dfcf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|order_value|\n",
            "+-----------+\n",
            "|        450|\n",
            "|        250|\n",
            "|        350|\n",
            "|        500|\n",
            "|        220|\n",
            "|        380|\n",
            "|        420|\n",
            "|        260|\n",
            "|        300|\n",
            "|        520|\n",
            "|        280|\n",
            "|        340|\n",
            "|        480|\n",
            "|        510|\n",
            "|        240|\n",
            "|        500|\n",
            "|        260|\n",
            "|        290|\n",
            "|        360|\n",
            "|        390|\n",
            "+-----------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Create a new column amount_in_hundreds"
      ],
      "metadata": {
        "id": "dKOHGyFUrmLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_orders = df_orders.withColumn(\n",
        "    \"amount_in_hundreds\", col(\"amount\") / 1000\n",
        ")\n",
        "df_orders.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THz5duxFritF",
        "outputId": "9e5a1c11-f372-40cd-f5fd-cc411fcb2df3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+----------+-------------+---------+----------+------+-----------------+------------------+\n",
            "|order_id|region|      city|restaurant_id|food_item|order_date|amount|delivery_time_min|amount_in_hundreds|\n",
            "+--------+------+----------+-------------+---------+----------+------+-----------------+------------------+\n",
            "|    O001| North|     Delhi|      Rest-01|    Pizza|2024-02-01|   450|               35|              0.45|\n",
            "|    O002| North|     Delhi|      Rest-01|   Burger|2024-02-01|   250|               25|              0.25|\n",
            "|    O003| North|Chandigarh|      Rest-02|    Pasta|2024-02-02|   350|               30|              0.35|\n",
            "|    O004| South| Bangalore|      Rest-03|    Pizza|2024-02-01|   500|               40|               0.5|\n",
            "|    O005| South|   Chennai|      Rest-04|   Burger|2024-02-02|   220|               20|              0.22|\n",
            "|    O006| South| Bangalore|      Rest-03|    Pasta|2024-02-03|   380|               32|              0.38|\n",
            "|    O007|  East|   Kolkata|      Rest-05|    Pizza|2024-02-01|   420|               38|              0.42|\n",
            "|    O008|  East|   Kolkata|      Rest-05|   Burger|2024-02-02|   260|               26|              0.26|\n",
            "|    O009|  East|     Patna|      Rest-06|    Pasta|2024-02-03|   300|               28|               0.3|\n",
            "|    O010|  West|    Mumbai|      Rest-07|    Pizza|2024-02-01|   520|               42|              0.52|\n",
            "|    O011|  West|    Mumbai|      Rest-07|   Burger|2024-02-02|   280|               27|              0.28|\n",
            "|    O012|  West|      Pune|      Rest-08|    Pasta|2024-02-03|   340|               31|              0.34|\n",
            "|    O013| North|     Delhi|      Rest-01|    Pizza|2024-02-04|   480|               37|              0.48|\n",
            "|    O014| South|   Chennai|      Rest-04|    Pizza|2024-02-04|   510|               41|              0.51|\n",
            "|    O015|  East|     Patna|      Rest-06|   Burger|2024-02-04|   240|               24|              0.24|\n",
            "|    O016|  West|      Pune|      Rest-08|    Pizza|2024-02-04|   500|               39|               0.5|\n",
            "|    O017| North|Chandigarh|      Rest-02|   Burger|2024-02-05|   260|               26|              0.26|\n",
            "|    O018| South| Bangalore|      Rest-03|   Burger|2024-02-05|   290|               29|              0.29|\n",
            "|    O019|  East|   Kolkata|      Rest-05|    Pasta|2024-02-05|   360|               33|              0.36|\n",
            "|    O020|  West|    Mumbai|      Rest-07|    Pasta|2024-02-05|   390|               34|              0.39|\n",
            "+--------+------+----------+-------------+---------+----------+------+-----------------+------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Select distinct combinations of region and food_item"
      ],
      "metadata": {
        "id": "2lTy-yyar75J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_orders.select(\"region\", \"food_item\").distinct().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8yBNsg0r4NB",
        "outputId": "85058419-30c5-4dff-ac2f-39c4d28531d4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+\n",
            "|region|food_item|\n",
            "+------+---------+\n",
            "|  West|   Burger|\n",
            "|  East|    Pizza|\n",
            "|  West|    Pizza|\n",
            "| North|    Pizza|\n",
            "| South|    Pizza|\n",
            "|  East|   Burger|\n",
            "| North|    Pasta|\n",
            "|  East|    Pasta|\n",
            "| North|   Burger|\n",
            "| South|    Pasta|\n",
            "| South|   Burger|\n",
            "|  West|    Pasta|\n",
            "+------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Reorder columns in a logical reporting format"
      ],
      "metadata": {
        "id": "-GFnySNrsIgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_orders = df_orders.select(\n",
        "    \"order_id\",\n",
        "    \"order_date\",\n",
        "    \"region\",\n",
        "    \"city\",\n",
        "    \"restaurant_id\",\n",
        "    \"food_item\",\n",
        "    \"delivery_time_min\",\n",
        "    \"amount\",\n",
        "    \"amount_in_hundreds\"\n",
        ")\n",
        "df_orders.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Rus7uEnsAfq",
        "outputId": "1bc0fb4d-24d1-43ce-9117-c2579695b667"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------+----------+-------------+---------+-----------------+------+------------------+\n",
            "|order_id|order_date|region|      city|restaurant_id|food_item|delivery_time_min|amount|amount_in_hundreds|\n",
            "+--------+----------+------+----------+-------------+---------+-----------------+------+------------------+\n",
            "|    O001|2024-02-01| North|     Delhi|      Rest-01|    Pizza|               35|   450|              0.45|\n",
            "|    O002|2024-02-01| North|     Delhi|      Rest-01|   Burger|               25|   250|              0.25|\n",
            "|    O003|2024-02-02| North|Chandigarh|      Rest-02|    Pasta|               30|   350|              0.35|\n",
            "|    O004|2024-02-01| South| Bangalore|      Rest-03|    Pizza|               40|   500|               0.5|\n",
            "|    O005|2024-02-02| South|   Chennai|      Rest-04|   Burger|               20|   220|              0.22|\n",
            "|    O006|2024-02-03| South| Bangalore|      Rest-03|    Pasta|               32|   380|              0.38|\n",
            "|    O007|2024-02-01|  East|   Kolkata|      Rest-05|    Pizza|               38|   420|              0.42|\n",
            "|    O008|2024-02-02|  East|   Kolkata|      Rest-05|   Burger|               26|   260|              0.26|\n",
            "|    O009|2024-02-03|  East|     Patna|      Rest-06|    Pasta|               28|   300|               0.3|\n",
            "|    O010|2024-02-01|  West|    Mumbai|      Rest-07|    Pizza|               42|   520|              0.52|\n",
            "|    O011|2024-02-02|  West|    Mumbai|      Rest-07|   Burger|               27|   280|              0.28|\n",
            "|    O012|2024-02-03|  West|      Pune|      Rest-08|    Pasta|               31|   340|              0.34|\n",
            "|    O013|2024-02-04| North|     Delhi|      Rest-01|    Pizza|               37|   480|              0.48|\n",
            "|    O014|2024-02-04| South|   Chennai|      Rest-04|    Pizza|               41|   510|              0.51|\n",
            "|    O015|2024-02-04|  East|     Patna|      Rest-06|   Burger|               24|   240|              0.24|\n",
            "|    O016|2024-02-04|  West|      Pune|      Rest-08|    Pizza|               39|   500|               0.5|\n",
            "|    O017|2024-02-05| North|Chandigarh|      Rest-02|   Burger|               26|   260|              0.26|\n",
            "|    O018|2024-02-05| South| Bangalore|      Rest-03|   Burger|               29|   290|              0.29|\n",
            "|    O019|2024-02-05|  East|   Kolkata|      Rest-05|    Pasta|               33|   360|              0.36|\n",
            "|    O020|2024-02-05|  West|    Mumbai|      Rest-07|    Pasta|               34|   390|              0.39|\n",
            "+--------+----------+------+----------+-------------+---------+-----------------+------+------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Create a column order_day extracted from order_date"
      ],
      "metadata": {
        "id": "-RaMdrpuuSXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import day, col\n",
        "df_orders = df_orders.withColumn(\n",
        "    \"order_day\", day(col(\"order_date\")))\n",
        "df_orders.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojxpQrypt_KH",
        "outputId": "dacbb9c5-0202-432e-e0a7-3a759104150a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------+----------+-------------+---------+-----------------+------+------------------+---------+\n",
            "|order_id|order_date|region|      city|restaurant_id|food_item|delivery_time_min|amount|amount_in_hundreds|order_day|\n",
            "+--------+----------+------+----------+-------------+---------+-----------------+------+------------------+---------+\n",
            "|    O001|2024-02-01| North|     Delhi|      Rest-01|    Pizza|               35|   450|              0.45|        1|\n",
            "|    O002|2024-02-01| North|     Delhi|      Rest-01|   Burger|               25|   250|              0.25|        1|\n",
            "|    O003|2024-02-02| North|Chandigarh|      Rest-02|    Pasta|               30|   350|              0.35|        2|\n",
            "|    O004|2024-02-01| South| Bangalore|      Rest-03|    Pizza|               40|   500|               0.5|        1|\n",
            "|    O005|2024-02-02| South|   Chennai|      Rest-04|   Burger|               20|   220|              0.22|        2|\n",
            "|    O006|2024-02-03| South| Bangalore|      Rest-03|    Pasta|               32|   380|              0.38|        3|\n",
            "|    O007|2024-02-01|  East|   Kolkata|      Rest-05|    Pizza|               38|   420|              0.42|        1|\n",
            "|    O008|2024-02-02|  East|   Kolkata|      Rest-05|   Burger|               26|   260|              0.26|        2|\n",
            "|    O009|2024-02-03|  East|     Patna|      Rest-06|    Pasta|               28|   300|               0.3|        3|\n",
            "|    O010|2024-02-01|  West|    Mumbai|      Rest-07|    Pizza|               42|   520|              0.52|        1|\n",
            "|    O011|2024-02-02|  West|    Mumbai|      Rest-07|   Burger|               27|   280|              0.28|        2|\n",
            "|    O012|2024-02-03|  West|      Pune|      Rest-08|    Pasta|               31|   340|              0.34|        3|\n",
            "|    O013|2024-02-04| North|     Delhi|      Rest-01|    Pizza|               37|   480|              0.48|        4|\n",
            "|    O014|2024-02-04| South|   Chennai|      Rest-04|    Pizza|               41|   510|              0.51|        4|\n",
            "|    O015|2024-02-04|  East|     Patna|      Rest-06|   Burger|               24|   240|              0.24|        4|\n",
            "|    O016|2024-02-04|  West|      Pune|      Rest-08|    Pizza|               39|   500|               0.5|        4|\n",
            "|    O017|2024-02-05| North|Chandigarh|      Rest-02|   Burger|               26|   260|              0.26|        5|\n",
            "|    O018|2024-02-05| South| Bangalore|      Rest-03|   Burger|               29|   290|              0.29|        5|\n",
            "|    O019|2024-02-05|  East|   Kolkata|      Rest-05|    Pasta|               33|   360|              0.36|        5|\n",
            "|    O020|2024-02-05|  West|    Mumbai|      Rest-07|    Pasta|               34|   390|              0.39|        5|\n",
            "+--------+----------+------+----------+-------------+---------+-----------------+------+------------------+---------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EXERCISE SET 2 — FILTER OPERATIONS"
      ],
      "metadata": {
        "id": "u42fWaudvQjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Filter orders where amount > 400"
      ],
      "metadata": {
        "id": "wYUNqgdJvUNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_orders.filter(col(\"amount\") > 400).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayRdt1a2uqAJ",
        "outputId": "826bc57c-e534-474e-87e0-fd8e40b5ac26"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------+---------+-------------+---------+-----------------+------+------------------+---------+\n",
            "|order_id|order_date|region|     city|restaurant_id|food_item|delivery_time_min|amount|amount_in_hundreds|order_day|\n",
            "+--------+----------+------+---------+-------------+---------+-----------------+------+------------------+---------+\n",
            "|    O001|2024-02-01| North|    Delhi|      Rest-01|    Pizza|               35|   450|              0.45|        1|\n",
            "|    O004|2024-02-01| South|Bangalore|      Rest-03|    Pizza|               40|   500|               0.5|        1|\n",
            "|    O007|2024-02-01|  East|  Kolkata|      Rest-05|    Pizza|               38|   420|              0.42|        1|\n",
            "|    O010|2024-02-01|  West|   Mumbai|      Rest-07|    Pizza|               42|   520|              0.52|        1|\n",
            "|    O013|2024-02-04| North|    Delhi|      Rest-01|    Pizza|               37|   480|              0.48|        4|\n",
            "|    O014|2024-02-04| South|  Chennai|      Rest-04|    Pizza|               41|   510|              0.51|        4|\n",
            "|    O016|2024-02-04|  West|     Pune|      Rest-08|    Pizza|               39|   500|               0.5|        4|\n",
            "|    O023|2024-02-06|  East|    Patna|      Rest-06|    Pizza|               36|   460|              0.46|        6|\n",
            "+--------+----------+------+---------+-------------+---------+-----------------+------+------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Filter only Pizza orders"
      ],
      "metadata": {
        "id": "CkyUWQ-tvmyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_orders.filter(col(\"food_item\") == \"Pizza\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExspYC3Yvlg-",
        "outputId": "2ebb97fc-fd33-4141-a6a2-9d235d1cd292"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------+---------+-------------+---------+-----------------+------+------------------+---------+\n",
            "|order_id|order_date|region|     city|restaurant_id|food_item|delivery_time_min|amount|amount_in_hundreds|order_day|\n",
            "+--------+----------+------+---------+-------------+---------+-----------------+------+------------------+---------+\n",
            "|    O001|2024-02-01| North|    Delhi|      Rest-01|    Pizza|               35|   450|              0.45|        1|\n",
            "|    O004|2024-02-01| South|Bangalore|      Rest-03|    Pizza|               40|   500|               0.5|        1|\n",
            "|    O007|2024-02-01|  East|  Kolkata|      Rest-05|    Pizza|               38|   420|              0.42|        1|\n",
            "|    O010|2024-02-01|  West|   Mumbai|      Rest-07|    Pizza|               42|   520|              0.52|        1|\n",
            "|    O013|2024-02-04| North|    Delhi|      Rest-01|    Pizza|               37|   480|              0.48|        4|\n",
            "|    O014|2024-02-04| South|  Chennai|      Rest-04|    Pizza|               41|   510|              0.51|        4|\n",
            "|    O016|2024-02-04|  West|     Pune|      Rest-08|    Pizza|               39|   500|               0.5|        4|\n",
            "|    O023|2024-02-06|  East|    Patna|      Rest-06|    Pizza|               36|   460|              0.46|        6|\n",
            "+--------+----------+------+---------+-------------+---------+-----------------+------+------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Filter orders from Delhi and Mumbai"
      ],
      "metadata": {
        "id": "wiidfblUv2W_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_orders = df_orders.filter(\n",
        "    col(\"city\").isin(\"Delhi\", \"Mumbai\"\n",
        "))\n",
        "df_orders.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvPa1xaCv1Hj",
        "outputId": "179d6214-8f98-4ca1-fcdb-feb69794f91a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+\n",
            "|order_id|order_date|region|  city|restaurant_id|food_item|delivery_time_min|amount|amount_in_hundreds|order_day|\n",
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+\n",
            "|    O001|2024-02-01| North| Delhi|      Rest-01|    Pizza|               35|   450|              0.45|        1|\n",
            "|    O002|2024-02-01| North| Delhi|      Rest-01|   Burger|               25|   250|              0.25|        1|\n",
            "|    O010|2024-02-01|  West|Mumbai|      Rest-07|    Pizza|               42|   520|              0.52|        1|\n",
            "|    O011|2024-02-02|  West|Mumbai|      Rest-07|   Burger|               27|   280|              0.28|        2|\n",
            "|    O013|2024-02-04| North| Delhi|      Rest-01|    Pizza|               37|   480|              0.48|        4|\n",
            "|    O020|2024-02-05|  West|Mumbai|      Rest-07|    Pasta|               34|   390|              0.39|        5|\n",
            "|    O021|2024-02-06| North| Delhi|      Rest-01|    Pasta|               30|   370|              0.37|        6|\n",
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Filter orders with delivery time greater than 35 minutes"
      ],
      "metadata": {
        "id": "rHfp91kDwVrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_orders.filter((col(\"delivery_time_min\") >= 35)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPN1ZwDlwRiM",
        "outputId": "86ee30db-959c-4191-e886-b4de135de66f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+\n",
            "|order_id|order_date|region|  city|restaurant_id|food_item|delivery_time_min|amount|amount_in_hundreds|order_day|\n",
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+\n",
            "|    O001|2024-02-01| North| Delhi|      Rest-01|    Pizza|               35|   450|              0.45|        1|\n",
            "|    O010|2024-02-01|  West|Mumbai|      Rest-07|    Pizza|               42|   520|              0.52|        1|\n",
            "|    O013|2024-02-04| North| Delhi|      Rest-01|    Pizza|               37|   480|              0.48|        4|\n",
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Apply multiple conditions using AND and OR"
      ],
      "metadata": {
        "id": "4mjtynWHw_IN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_orders.filter(col(\"amount\") > 300).filter(\n",
        "    col(\"delivery_time_min\") < 40).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxYHzmH5w-FE",
        "outputId": "34e66189-e03a-4cbc-dc7b-bc8861b20754"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+\n",
            "|order_id|order_date|region|  city|restaurant_id|food_item|delivery_time_min|amount|amount_in_hundreds|order_day|\n",
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+\n",
            "|    O001|2024-02-01| North| Delhi|      Rest-01|    Pizza|               35|   450|              0.45|        1|\n",
            "|    O013|2024-02-04| North| Delhi|      Rest-01|    Pizza|               37|   480|              0.48|        4|\n",
            "|    O020|2024-02-05|  West|Mumbai|      Rest-07|    Pasta|               34|   390|              0.39|        5|\n",
            "|    O021|2024-02-06| North| Delhi|      Rest-01|    Pasta|               30|   370|              0.37|        6|\n",
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_orders.filter((col(\"region\")==\"east\")|(col(\"region\")==\"west\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiWhF5jlxuXq",
        "outputId": "596a8a6c-3e8c-4df5-91a4-7770e0713b0e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------+----+-------------+---------+-----------------+------+------------------+---------+\n",
            "|order_id|order_date|region|city|restaurant_id|food_item|delivery_time_min|amount|amount_in_hundreds|order_day|\n",
            "+--------+----------+------+----+-------------+---------+-----------------+------+------------------+---------+\n",
            "+--------+----------+------+----+-------------+---------+-----------------+------+------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Apply filters in different orders and compare explain(True)"
      ],
      "metadata": {
        "id": "hJRJs3sax92v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_case1 = df_orders.filter(col(\"region\")==\"East\").filter(col(\"city\")==\"Kolkata\")\n",
        "df_case1.show()\n",
        "df_case1.explain(True)\n",
        "\n",
        "df_case2 = df_orders.filter(col(\"city\")==\"Delhi\").filter(col(\"region\")==\"North\")\n",
        "df_case2.show()\n",
        "df_case2.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4PSJEIAx84u",
        "outputId": "ef02f690-1765-44ea-cedb-28fa8d91c2b6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------+----+-------------+---------+-----------------+------+------------------+---------+\n",
            "|order_id|order_date|region|city|restaurant_id|food_item|delivery_time_min|amount|amount_in_hundreds|order_day|\n",
            "+--------+----------+------+----+-------------+---------+-----------------+------+------------------+---------+\n",
            "+--------+----------+------+----+-------------+---------+-----------------+------+------------------+---------+\n",
            "\n",
            "== Parsed Logical Plan ==\n",
            "'Filter '`=`('city, Kolkata)\n",
            "+- Filter (region#1 = East)\n",
            "   +- Filter city#2 IN (Delhi,Mumbai)\n",
            "      +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "         +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51]\n",
            "            +- Project [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L, (cast(amount#6L as double) / cast(1000 as double)) AS amount_in_hundreds#51]\n",
            "               +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "order_id: string, order_date: string, region: string, city: string, restaurant_id: string, food_item: string, delivery_time_min: bigint, amount: bigint, amount_in_hundreds: double, order_day: int\n",
            "Filter (city#2 = Kolkata)\n",
            "+- Filter (region#1 = East)\n",
            "   +- Filter city#2 IN (Delhi,Mumbai)\n",
            "      +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "         +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51]\n",
            "            +- Project [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L, (cast(amount#6L as double) / cast(1000 as double)) AS amount_in_hundreds#51]\n",
            "               +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, (cast(amount#6L as double) / 1000.0) AS amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "+- Filter ((isnotnull(region#1) AND isnotnull(city#2)) AND (city#2 IN (Delhi,Mumbai) AND ((region#1 = East) AND (city#2 = Kolkata))))\n",
            "   +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Physical Plan ==\n",
            "*(1) Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, (cast(amount#6L as double) / 1000.0) AS amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "+- *(1) Filter ((isnotnull(region#1) AND isnotnull(city#2)) AND (city#2 IN (Delhi,Mumbai) AND ((region#1 = East) AND (city#2 = Kolkata))))\n",
            "   +- *(1) Scan ExistingRDD[order_id#0,region#1,city#2,restaurant_id#3,food_item#4,order_date#5,amount#6L,delivery_time_min#7L]\n",
            "\n",
            "+--------+----------+------+-----+-------------+---------+-----------------+------+------------------+---------+\n",
            "|order_id|order_date|region| city|restaurant_id|food_item|delivery_time_min|amount|amount_in_hundreds|order_day|\n",
            "+--------+----------+------+-----+-------------+---------+-----------------+------+------------------+---------+\n",
            "|    O001|2024-02-01| North|Delhi|      Rest-01|    Pizza|               35|   450|              0.45|        1|\n",
            "|    O002|2024-02-01| North|Delhi|      Rest-01|   Burger|               25|   250|              0.25|        1|\n",
            "|    O013|2024-02-04| North|Delhi|      Rest-01|    Pizza|               37|   480|              0.48|        4|\n",
            "|    O021|2024-02-06| North|Delhi|      Rest-01|    Pasta|               30|   370|              0.37|        6|\n",
            "+--------+----------+------+-----+-------------+---------+-----------------+------+------------------+---------+\n",
            "\n",
            "== Parsed Logical Plan ==\n",
            "'Filter '`=`('region, North)\n",
            "+- Filter (city#2 = Delhi)\n",
            "   +- Filter city#2 IN (Delhi,Mumbai)\n",
            "      +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "         +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51]\n",
            "            +- Project [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L, (cast(amount#6L as double) / cast(1000 as double)) AS amount_in_hundreds#51]\n",
            "               +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "order_id: string, order_date: string, region: string, city: string, restaurant_id: string, food_item: string, delivery_time_min: bigint, amount: bigint, amount_in_hundreds: double, order_day: int\n",
            "Filter (region#1 = North)\n",
            "+- Filter (city#2 = Delhi)\n",
            "   +- Filter city#2 IN (Delhi,Mumbai)\n",
            "      +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "         +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51]\n",
            "            +- Project [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L, (cast(amount#6L as double) / cast(1000 as double)) AS amount_in_hundreds#51]\n",
            "               +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, (cast(amount#6L as double) / 1000.0) AS amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "+- Filter ((isnotnull(city#2) AND isnotnull(region#1)) AND (city#2 IN (Delhi,Mumbai) AND ((city#2 = Delhi) AND (region#1 = North))))\n",
            "   +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Physical Plan ==\n",
            "*(1) Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, (cast(amount#6L as double) / 1000.0) AS amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "+- *(1) Filter ((isnotnull(city#2) AND isnotnull(region#1)) AND (city#2 IN (Delhi,Mumbai) AND ((city#2 = Delhi) AND (region#1 = North))))\n",
            "   +- *(1) Scan ExistingRDD[order_id#0,region#1,city#2,restaurant_id#3,food_item#4,order_date#5,amount#6L,delivery_time_min#7L]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Identify which filters are pushed down by Spark"
      ],
      "metadata": {
        "id": "x8071D19yuPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_orders.filter(col(\"region\")==\"East\").filter(col(\"amount\")>500).explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWMtgsnGysP4",
        "outputId": "d874a6b9-fad5-4450-b8a2-0f16cc3d5461"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Filter '`>`('amount, 500)\n",
            "+- Filter (region#1 = East)\n",
            "   +- Filter city#2 IN (Delhi,Mumbai)\n",
            "      +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "         +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51]\n",
            "            +- Project [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L, (cast(amount#6L as double) / cast(1000 as double)) AS amount_in_hundreds#51]\n",
            "               +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "order_id: string, order_date: string, region: string, city: string, restaurant_id: string, food_item: string, delivery_time_min: bigint, amount: bigint, amount_in_hundreds: double, order_day: int\n",
            "Filter (amount#6L > cast(500 as bigint))\n",
            "+- Filter (region#1 = East)\n",
            "   +- Filter city#2 IN (Delhi,Mumbai)\n",
            "      +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "         +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51]\n",
            "            +- Project [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L, (cast(amount#6L as double) / cast(1000 as double)) AS amount_in_hundreds#51]\n",
            "               +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, (cast(amount#6L as double) / 1000.0) AS amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "+- Filter ((isnotnull(region#1) AND isnotnull(amount#6L)) AND (city#2 IN (Delhi,Mumbai) AND ((region#1 = East) AND (amount#6L > 500))))\n",
            "   +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Physical Plan ==\n",
            "*(1) Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, (cast(amount#6L as double) / 1000.0) AS amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "+- *(1) Filter ((isnotnull(region#1) AND isnotnull(amount#6L)) AND (city#2 IN (Delhi,Mumbai) AND ((region#1 = East) AND (amount#6L > 500))))\n",
            "   +- *(1) Scan ExistingRDD[order_id#0,region#1,city#2,restaurant_id#3,food_item#4,order_date#5,amount#6L,delivery_time_min#7L]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EXERCISE SET 3 — TRANSFORMATIONS vs ACTIONS"
      ],
      "metadata": {
        "id": "aws9HdZWzA07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Build a pipeline with:\n",
        "select\n",
        "filter\n",
        "derived column\n",
        "\n",
        "2. Do not call any action"
      ],
      "metadata": {
        "id": "VZ5HLKmCzLAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pipeline = (\n",
        "    df_orders.select(\"order_id\", \"region\", \"amount\").filter(col(\"amount\") > 400).withColumn(\"amount_in_hundreds\", col(\"amount\") *0.9)\n",
        ")"
      ],
      "metadata": {
        "id": "v1j2TAtTy7nx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Explain what Spark has done so far"
      ],
      "metadata": {
        "id": "bfG0c4WAz5aO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Trigger count() and observe execution"
      ],
      "metadata": {
        "id": "eHbIjuVS0I0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pipeline.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-e0n5mZ10SFk",
        "outputId": "496c2998-2500-4def-bedd-ebb6bc1d8a6e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Trigger show() and compare behavior"
      ],
      "metadata": {
        "id": "9ImNah4a0LXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pipeline.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLZzWdXSzzdm",
        "outputId": "4ae21bfe-c0a1-4062-f50b-24e5cbb7bf2e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+------+------------------+\n",
            "|order_id|region|amount|amount_in_hundreds|\n",
            "+--------+------+------+------------------+\n",
            "|    O001| North|   450|             405.0|\n",
            "|    O010|  West|   520|             468.0|\n",
            "|    O013| North|   480|             432.0|\n",
            "+--------+------+------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EXERCISE SET 4 — PARTITIONS & FILE LAYOUT"
      ],
      "metadata": {
        "id": "100HUUDi0hcb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Check the number of partitions of df_orders"
      ],
      "metadata": {
        "id": "XRB8Eh_J0xsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_orders.rdd.getNumPartitions())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z9uPaYb0yxU",
        "outputId": "d12c10ec-a00c-49ce-808e-b9e43e30fad0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Repartition the DataFrame into 4 partitions"
      ],
      "metadata": {
        "id": "tkkFMj6v05TW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_orders_repartitioned = df_orders.repartition(4)\n",
        "print(df_orders_repartitioned.rdd.getNumPartitions())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCPFZVTq0RMK",
        "outputId": "c9527153-6da7-400c-fae2-8c40c7e579b0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Coalesce the DataFrame into 1 partition"
      ],
      "metadata": {
        "id": "C-119ao906ZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_orders_coalesced = df_orders_repartitioned.coalesce(1)\n",
        "print(df_orders_coalesced.rdd.getNumPartitions())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4b_BA0F0-hx",
        "outputId": "f198a3a4-bb67-425d-c0d0-b96faa1778df"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Write repartitioned data to Parquet and count files"
      ],
      "metadata": {
        "id": "7_Xlj1Ms1NyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "output_path = \"/tmp/repartitioned_orders.parquet\"\n",
        "\n",
        "# Clean up previous run if any\n",
        "if os.path.exists(output_path):\n",
        "    shutil.rmtree(output_path)\n",
        "\n",
        "# Write the repartitioned DataFrame to Parquet\n",
        "df_orders_repartitioned.write.mode(\"overwrite\").parquet(output_path)\n",
        "\n",
        "# Count the number of Parquet files (part files)\n",
        "parquet_files = [f for f in os.listdir(output_path) if f.startswith('part-') and f.endswith('.parquet')]\n",
        "print(f\"Number of Parquet files created: {len(parquet_files)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ph8mY2Zs1L30",
        "outputId": "83c74139-6a8d-4b4c-9984-985ed63b7f00"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Parquet files created: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Write coalesced data to Parquet and count files"
      ],
      "metadata": {
        "id": "eGcjVVqU1VtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "output_path_coalesced = \"/tmp/coalesced_orders.parquet\"\n",
        "\n",
        "# Clean up previous run if any\n",
        "if os.path.exists(output_path_coalesced):\n",
        "    shutil.rmtree(output_path_coalesced)\n",
        "\n",
        "# Write the coalesced DataFrame to Parquet\n",
        "df_orders_coalesced.write.mode(\"overwrite\").parquet(output_path_coalesced)\n",
        "\n",
        "# Count the number of Parquet files (part files)\n",
        "parquet_files_coalesced = [f for f in os.listdir(output_path_coalesced) if f.startswith('part-') and f.endswith('.parquet')]\n",
        "print(f\"Number of Parquet files created for coalesced data: {len(parquet_files_coalesced)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiGIGNJv1TcP",
        "outputId": "00cb04af-70df-4b6b-c8a0-e7a34b50ea64"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Parquet files created for coalesced data: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Explain why file counts differ"
      ],
      "metadata": {
        "id": "XPhYwhgw1bPY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of output files when writing a Spark DataFrame to a file format like Parquet directly corresponds to the number of partitions the DataFrame has at that moment.\n",
        "Here's why the counts differed:\n",
        "df_orders_repartitioned (4 files):\n",
        "We used df_orders.repartition(4). The repartition() operation creates a new DataFrame with the specified number of partitions (in this case, 4). This typically involves a full shuffle of the data across the cluster to distribute it evenly among the new partitions.\n",
        "When df_orders_repartitioned was written to Parquet, each of its 4 partitions was written as a separate file, resulting in 4 Parquet files.\n",
        "df_orders_coalesced (1 file):\n",
        "We used df_orders_repartitioned.coalesce(1). The coalesce() operation is used to reduce the number of partitions. Unlike repartition(), coalesce() tries to minimize data shuffling by combining existing partitions where possible. It's often more efficient when decreasing the number of partitions.\n",
        "In this case, coalesce(1) combined all the partitions of df_orders_repartitioned into a single partition.\n",
        "When df_orders_coalesced (which had 1 partition) was written to Parquet, it produced only 1 Parquet file."
      ],
      "metadata": {
        "id": "vvwgGOG21i7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EXERCISE SET 5 — GROUPBY & AGGREGATE FUNCTIONS"
      ],
      "metadata": {
        "id": "egVplUwY1j3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Total revenue per region"
      ],
      "metadata": {
        "id": "_s12-2_T1ooH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum\n",
        "revenue_per_region = df_orders.groupBy(\"region\").agg(sum(\"amount\").alias(\"total_revenue\"))\n",
        "revenue_per_region.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0h4td9K1qiy",
        "outputId": "13322d7c-9412-4185-d3fd-ae163e008386"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+\n",
            "|region|total_revenue|\n",
            "+------+-------------+\n",
            "|  West|         1190|\n",
            "| North|         1550|\n",
            "+------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Average order amount per food item"
      ],
      "metadata": {
        "id": "ZdNnNGEh1zl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg\n",
        "\n",
        "average_amount_per_food_item = df_orders.groupBy(\"food_item\").agg(avg(\"amount\").alias(\"average_order_amount\"))\n",
        "average_amount_per_food_item.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPZQt2Eg1yw_",
        "outputId": "f30aa5c9-d6c8-4f83-efda-9d7ad3b56045"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------------+\n",
            "|food_item|average_order_amount|\n",
            "+---------+--------------------+\n",
            "|   Burger|               265.0|\n",
            "|    Pizza|   483.3333333333333|\n",
            "|    Pasta|               380.0|\n",
            "+---------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Maximum order amount per city"
      ],
      "metadata": {
        "id": "YZ15kKTf16Wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import max\n",
        "\n",
        "max_amount_per_city = df_orders.groupBy(\"city\").agg(max(\"amount\").alias(\"max_order_amount\"))\n",
        "max_amount_per_city.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-bKhu6X15bX",
        "outputId": "9f33fc4f-61c0-4e36-fb1e-b6fd637afe0c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------------+\n",
            "|  city|max_order_amount|\n",
            "+------+----------------+\n",
            "|Mumbai|             520|\n",
            "| Delhi|             480|\n",
            "+------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Minimum delivery time per restaurant"
      ],
      "metadata": {
        "id": "A2y9PvUf2CnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import min\n",
        "\n",
        "min_delivery_time_per_restaurant = df_orders.groupBy(\"restaurant_id\").agg(min(\"delivery_time_min\").alias(\"min_delivery_time\"))\n",
        "min_delivery_time_per_restaurant.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jhjbh-H1_1F",
        "outputId": "b1e2fb0c-45bb-42df-e77c-f0204a2d4bba"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----------------+\n",
            "|restaurant_id|min_delivery_time|\n",
            "+-------------+-----------------+\n",
            "|      Rest-01|               25|\n",
            "|      Rest-07|               27|\n",
            "+-------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Count number of orders per region"
      ],
      "metadata": {
        "id": "pkaxDtLz2GkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import count\n",
        "\n",
        "orders_per_region = df_orders.groupBy(\"region\").agg(count(\"order_id\").alias(\"number_of_orders\"))\n",
        "orders_per_region.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgoVCLsj2FmG",
        "outputId": "8cc483be-c064-47db-c73d-335a3e17cb6c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------------+\n",
            "|region|number_of_orders|\n",
            "+------+----------------+\n",
            "|  West|               3|\n",
            "| North|               4|\n",
            "+------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Total revenue per restaurant"
      ],
      "metadata": {
        "id": "US2z1IFY2LZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum\n",
        "\n",
        "total_revenue_per_restaurant = df_orders.groupBy(\"restaurant_id\").agg(sum(\"amount\").alias(\"total_revenue\"))\n",
        "total_revenue_per_restaurant.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_9DSBPd2L_r",
        "outputId": "899ebb22-26bb-43a4-d2a2-e990b36ae534"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-------------+\n",
            "|restaurant_id|total_revenue|\n",
            "+-------------+-------------+\n",
            "|      Rest-01|         1550|\n",
            "|      Rest-07|         1190|\n",
            "+-------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Region + food item wise total revenue"
      ],
      "metadata": {
        "id": "5ZbuSzAe2VH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "region_food_item_revenue = df_orders.groupBy(\"region\", \"food_item\").agg(sum(\"amount\").alias(\"total_revenue\"))\n",
        "region_food_item_revenue.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD7sApIg2St0",
        "outputId": "27434bd2-1ab0-4295-851a-e40038cfc544"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+-------------+\n",
            "|region|food_item|total_revenue|\n",
            "+------+---------+-------------+\n",
            "|  West|   Burger|          280|\n",
            "|  West|    Pizza|          520|\n",
            "| North|    Pizza|          930|\n",
            "| North|   Burger|          250|\n",
            "| North|    Pasta|          370|\n",
            "|  West|    Pasta|          390|\n",
            "+------+---------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. City wise average delivery time"
      ],
      "metadata": {
        "id": "Gc-R-0P82hQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg\n",
        "\n",
        "city_avg_delivery_time = df_orders.groupBy(\"city\").agg(avg(\"delivery_time_min\").alias(\"average_delivery_time\"))\n",
        "city_avg_delivery_time.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K0Wh8vb2cXn",
        "outputId": "a9c7567e-5849-4287-81dc-dc83d29fbca3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------------------+\n",
            "|  city|average_delivery_time|\n",
            "+------+---------------------+\n",
            "|Mumbai|   34.333333333333336|\n",
            "| Delhi|                31.75|\n",
            "+------+---------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Identify regions with revenue above a threshold"
      ],
      "metadata": {
        "id": "kOkxzA-p2k7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "revenue_threshold = 2100\n",
        "regions_above_threshold = revenue_per_region.filter(col(\"total_revenue\") > revenue_threshold)\n",
        "regions_above_threshold.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m19EXGNd2fCS",
        "outputId": "4b3fe7c6-63fb-4b55-8e8f-997e38183826"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+\n",
            "|region|total_revenue|\n",
            "+------+-------------+\n",
            "+------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Use explain(True) and identify shuffle operators"
      ],
      "metadata": {
        "id": "8MPt1MGT2s8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "revenue_per_region.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqUeE8ok2oMZ",
        "outputId": "b5cb3998-302a-4039-9c25-a9f4abfd9a46"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Aggregate ['region], ['region, 'sum('amount) AS total_revenue#417]\n",
            "+- Filter city#2 IN (Delhi,Mumbai)\n",
            "   +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "      +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51]\n",
            "         +- Project [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L, (cast(amount#6L as double) / cast(1000 as double)) AS amount_in_hundreds#51]\n",
            "            +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "region: string, total_revenue: bigint\n",
            "Aggregate [region#1], [region#1, sum(amount#6L) AS total_revenue#417L]\n",
            "+- Filter city#2 IN (Delhi,Mumbai)\n",
            "   +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "      +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51]\n",
            "         +- Project [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L, (cast(amount#6L as double) / cast(1000 as double)) AS amount_in_hundreds#51]\n",
            "            +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Aggregate [region#1], [region#1, sum(amount#6L) AS total_revenue#417L]\n",
            "+- Project [region#1, amount#6L]\n",
            "   +- Filter city#2 IN (Delhi,Mumbai)\n",
            "      +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- HashAggregate(keys=[region#1], functions=[sum(amount#6L)], output=[region#1, total_revenue#417L])\n",
            "   +- Exchange hashpartitioning(region#1, 200), ENSURE_REQUIREMENTS, [plan_id=1025]\n",
            "      +- HashAggregate(keys=[region#1], functions=[partial_sum(amount#6L)], output=[region#1, sum#432L])\n",
            "         +- Project [region#1, amount#6L]\n",
            "            +- Filter city#2 IN (Delhi,Mumbai)\n",
            "               +- Scan ExistingRDD[order_id#0,region#1,city#2,restaurant_id#3,food_item#4,order_date#5,amount#6L,delivery_time_min#7L]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The explain(True) output for revenue_per_region shows the physical execution plan for calculating the total revenue per region. The key line indicating a shuffle operation is:\n",
        "+- Exchange hashpartitioning(region#1, 200), ENSURE_REQUIREMENTS, [plan_id=575]\n",
        "The Exchange operator, specifically with hashpartitioning, signifies a shuffle in Spark. This shuffle is necessary because the groupBy(\"region\") operation requires all rows with the same region to be brought together on the same executor to correctly calculate the sum(\"amount\") for each region. Spark redistributes the data across the network based on the region column, which is a resource-intensive operation."
      ],
      "metadata": {
        "id": "RoFRkypI2wXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EXERCISE SET 6 — WINDOW FUNCTIONS(OVER)"
      ],
      "metadata": {
        "id": "iH8ViCJl2y0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Compute running total of revenue per region ordered by date"
      ],
      "metadata": {
        "id": "6bo7TNme25yO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import sum, rank, row_number, dense_rank,col\n",
        "window_spec_revenue = Window.partitionBy(\"region\").orderBy(\"order_date\")\n",
        "\n",
        "running_total_revenue = df_orders.withColumn(\n",
        "    \"running_total_revenue\",\n",
        "    sum(col(\"amount\")).over(window_spec_revenue)\n",
        ")\n",
        "\n",
        "running_total_revenue.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTj5Y-Y02sJC",
        "outputId": "f49fd16c-b309-4f31-8e8a-81ab4f02a495"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+---------------------+\n",
            "|order_id|order_date|region|  city|restaurant_id|food_item|delivery_time_min|amount|amount_in_hundreds|order_day|running_total_revenue|\n",
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+---------------------+\n",
            "|    O001|2024-02-01| North| Delhi|      Rest-01|    Pizza|               35|   450|              0.45|        1|                  700|\n",
            "|    O002|2024-02-01| North| Delhi|      Rest-01|   Burger|               25|   250|              0.25|        1|                  700|\n",
            "|    O013|2024-02-04| North| Delhi|      Rest-01|    Pizza|               37|   480|              0.48|        4|                 1180|\n",
            "|    O021|2024-02-06| North| Delhi|      Rest-01|    Pasta|               30|   370|              0.37|        6|                 1550|\n",
            "|    O010|2024-02-01|  West|Mumbai|      Rest-07|    Pizza|               42|   520|              0.52|        1|                  520|\n",
            "|    O011|2024-02-02|  West|Mumbai|      Rest-07|   Burger|               27|   280|              0.28|        2|                  800|\n",
            "|    O020|2024-02-05|  West|Mumbai|      Rest-07|    Pasta|               34|   390|              0.39|        5|                 1190|\n",
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+---------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Rank orders by amount within each region"
      ],
      "metadata": {
        "id": "r3eDWAA_3CYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import rank, col\n",
        "\n",
        "window_spec_rank = Window.partitionBy(\"region\").orderBy(col(\"amount\").desc())\n",
        "\n",
        "ranked_orders = df_orders.withColumn(\n",
        "    \"rank_by_amount_in_region\",\n",
        "    rank().over(window_spec_rank)\n",
        ")\n",
        "\n",
        "ranked_orders.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2V2CYTG28rY",
        "outputId": "4056bb09-ce34-46ec-f5a5-0db08d520bed"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+------------------------+\n",
            "|order_id|order_date|region|  city|restaurant_id|food_item|delivery_time_min|amount|amount_in_hundreds|order_day|rank_by_amount_in_region|\n",
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+------------------------+\n",
            "|    O013|2024-02-04| North| Delhi|      Rest-01|    Pizza|               37|   480|              0.48|        4|                       1|\n",
            "|    O001|2024-02-01| North| Delhi|      Rest-01|    Pizza|               35|   450|              0.45|        1|                       2|\n",
            "|    O021|2024-02-06| North| Delhi|      Rest-01|    Pasta|               30|   370|              0.37|        6|                       3|\n",
            "|    O002|2024-02-01| North| Delhi|      Rest-01|   Burger|               25|   250|              0.25|        1|                       4|\n",
            "|    O010|2024-02-01|  West|Mumbai|      Rest-07|    Pizza|               42|   520|              0.52|        1|                       1|\n",
            "|    O020|2024-02-05|  West|Mumbai|      Rest-07|    Pasta|               34|   390|              0.39|        5|                       2|\n",
            "|    O011|2024-02-02|  West|Mumbai|      Rest-07|   Burger|               27|   280|              0.28|        2|                       3|\n",
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Assign row numbers per restaurant based on delivery time"
      ],
      "metadata": {
        "id": "xb1qxheC3LLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number, col\n",
        "\n",
        "window_spec_row_number = Window.partitionBy(\"restaurant_id\").orderBy(\"delivery_time_min\")\n",
        "\n",
        "orders_with_row_number = df_orders.withColumn(\n",
        "    \"row_number_by_delivery_time\",\n",
        "    row_number().over(window_spec_row_number)\n",
        ")\n",
        "\n",
        "orders_with_row_number.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KU2uICY2_H7",
        "outputId": "6954fdf5-77d3-4e47-b9e4-b43a98791926"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+---------------------------+\n",
            "|order_id|order_date|region|  city|restaurant_id|food_item|delivery_time_min|amount|amount_in_hundreds|order_day|row_number_by_delivery_time|\n",
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+---------------------------+\n",
            "|    O002|2024-02-01| North| Delhi|      Rest-01|   Burger|               25|   250|              0.25|        1|                          1|\n",
            "|    O021|2024-02-06| North| Delhi|      Rest-01|    Pasta|               30|   370|              0.37|        6|                          2|\n",
            "|    O001|2024-02-01| North| Delhi|      Rest-01|    Pizza|               35|   450|              0.45|        1|                          3|\n",
            "|    O013|2024-02-04| North| Delhi|      Rest-01|    Pizza|               37|   480|              0.48|        4|                          4|\n",
            "|    O011|2024-02-02|  West|Mumbai|      Rest-07|   Burger|               27|   280|              0.28|        2|                          1|\n",
            "|    O020|2024-02-05|  West|Mumbai|      Rest-07|    Pasta|               34|   390|              0.39|        5|                          2|\n",
            "|    O010|2024-02-01|  West|Mumbai|      Rest-07|    Pizza|               42|   520|              0.52|        1|                          3|\n",
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+---------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Use dense rank to rank food items per region by revenue"
      ],
      "metadata": {
        "id": "5YtJnqd-3QA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import dense_rank, col\n",
        "\n",
        "window_spec_dense_rank = Window.partitionBy(\"region\").orderBy(col(\"total_revenue\").desc())\n",
        "\n",
        "dense_ranked_food_items = region_food_item_revenue.withColumn(\n",
        "    \"dense_rank_by_revenue_in_region\",\n",
        "    dense_rank().over(window_spec_dense_rank)\n",
        ")\n",
        "\n",
        "dense_ranked_food_items.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS8eh30q3GSY",
        "outputId": "dfb48e58-8342-4dad-843e-8abcc3974957"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+-------------+-------------------------------+\n",
            "|region|food_item|total_revenue|dense_rank_by_revenue_in_region|\n",
            "+------+---------+-------------+-------------------------------+\n",
            "| North|    Pizza|          930|                              1|\n",
            "| North|    Pasta|          370|                              2|\n",
            "| North|   Burger|          250|                              3|\n",
            "|  West|    Pizza|          520|                              1|\n",
            "|  West|    Pasta|          390|                              2|\n",
            "|  West|   Burger|          280|                              3|\n",
            "+------+---------+-------------+-------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Identify top 2 highest value orders per region"
      ],
      "metadata": {
        "id": "6nuDbISm3WWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import row_number, col\n",
        "\n",
        "window_spec_top_orders = Window.partitionBy(\"region\").orderBy(col(\"amount\").desc())\n",
        "\n",
        "top_2_orders_per_region = df_orders.withColumn(\n",
        "    \"rank_in_region\",\n",
        "    row_number().over(window_spec_top_orders)\n",
        ").filter(col(\"rank_in_region\") <= 2)\n",
        "\n",
        "top_2_orders_per_region.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCzbOLHI3VAM",
        "outputId": "67417e44-6f90-4e71-c47f-0428e58a38d8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+--------------+\n",
            "|order_id|order_date|region|  city|restaurant_id|food_item|delivery_time_min|amount|amount_in_hundreds|order_day|rank_in_region|\n",
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+--------------+\n",
            "|    O013|2024-02-04| North| Delhi|      Rest-01|    Pizza|               37|   480|              0.48|        4|             1|\n",
            "|    O001|2024-02-01| North| Delhi|      Rest-01|    Pizza|               35|   450|              0.45|        1|             2|\n",
            "|    O010|2024-02-01|  West|Mumbai|      Rest-07|    Pizza|               42|   520|              0.52|        1|             1|\n",
            "|    O020|2024-02-05|  West|Mumbai|      Rest-07|    Pasta|               34|   390|              0.39|        5|             2|\n",
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Compare rank , dense_rank , and row_number outputs"
      ],
      "metadata": {
        "id": "WY8Y4zbr3kAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window_spec_compare = Window.partitionBy(\"region\").orderBy(col(\"amount\").desc())\n",
        "\n",
        "comparison_df = df_orders.withColumn(\n",
        "    \"rank\",\n",
        "    rank().over(window_spec_compare)\n",
        ").withColumn(\n",
        "    \"dense_rank\",\n",
        "    dense_rank().over(window_spec_compare)\n",
        ").withColumn(\n",
        "    \"row_number\",\n",
        "    row_number().over(window_spec_compare)\n",
        ")\n",
        "\n",
        "comparison_df.select(\"region\", \"order_id\", \"amount\", \"rank\", \"dense_rank\", \"row_number\").orderBy(\"region\", \"amount\", \"order_id\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iht__wM_3dzR",
        "outputId": "90779bbf-718d-461f-8f78-63e89f913823"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+------+----+----------+----------+\n",
            "|region|order_id|amount|rank|dense_rank|row_number|\n",
            "+------+--------+------+----+----------+----------+\n",
            "| North|    O002|   250|   4|         4|         4|\n",
            "| North|    O021|   370|   3|         3|         3|\n",
            "| North|    O001|   450|   2|         2|         2|\n",
            "| North|    O013|   480|   1|         1|         1|\n",
            "|  West|    O011|   280|   3|         3|         3|\n",
            "|  West|    O020|   390|   2|         2|         2|\n",
            "|  West|    O010|   520|   1|         1|         1|\n",
            "+------+--------+------+----+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Calculate cumulative delivery time per restaurant"
      ],
      "metadata": {
        "id": "C_mWr_N23pcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window_spec_cumulative_delivery = Window.partitionBy(\"restaurant_id\").orderBy(\"order_date\")\n",
        "\n",
        "cumulative_delivery_time = df_orders.withColumn(\n",
        "    \"cumulative_delivery_time\",\n",
        "    sum(col(\"delivery_time_min\")).over(window_spec_cumulative_delivery)\n",
        ")\n",
        "\n",
        "cumulative_delivery_time.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMJhhzUP3ogU",
        "outputId": "9a6f53e5-24c5-4105-f1a5-938006fdb621"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+------------------------+\n",
            "|order_id|order_date|region|  city|restaurant_id|food_item|delivery_time_min|amount|amount_in_hundreds|order_day|cumulative_delivery_time|\n",
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+------------------------+\n",
            "|    O001|2024-02-01| North| Delhi|      Rest-01|    Pizza|               35|   450|              0.45|        1|                      60|\n",
            "|    O002|2024-02-01| North| Delhi|      Rest-01|   Burger|               25|   250|              0.25|        1|                      60|\n",
            "|    O013|2024-02-04| North| Delhi|      Rest-01|    Pizza|               37|   480|              0.48|        4|                      97|\n",
            "|    O021|2024-02-06| North| Delhi|      Rest-01|    Pasta|               30|   370|              0.37|        6|                     127|\n",
            "|    O010|2024-02-01|  West|Mumbai|      Rest-07|    Pizza|               42|   520|              0.52|        1|                      42|\n",
            "|    O011|2024-02-02|  West|Mumbai|      Rest-07|   Burger|               27|   280|              0.28|        2|                      69|\n",
            "|    O020|2024-02-05|  West|Mumbai|      Rest-07|    Pasta|               34|   390|              0.39|        5|                     103|\n",
            "+--------+----------+------+------+-------------+---------+-----------------+------+------------------+---------+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EXERCISE SET 7 — GROUPBY vs WINDOW(CONCEPTUAL)"
      ],
      "metadata": {
        "id": "AMELjzye3ywf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Calculate total revenue per region using GroupBy"
      ],
      "metadata": {
        "id": "Tmtmagju31Bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_revenue_groupby = df_orders.groupBy(\"region\").agg(sum(\"amount\").alias(\"total_revenue\"))\n",
        "total_revenue_groupby.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I3z9_cH3wIv",
        "outputId": "892a8ee7-fdae-4fbb-c45c-f4f24e29a92e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+\n",
            "|region|total_revenue|\n",
            "+------+-------------+\n",
            "|  West|         1190|\n",
            "| North|         1550|\n",
            "+------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Calculate total revenue per region using Window"
      ],
      "metadata": {
        "id": "rrH2V7Yg39p3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window_spec_total_revenue = Window.partitionBy(\"region\")\n",
        "total_revenue_window = df_orders.withColumn(\n",
        "    \"total_revenue\",\n",
        "    sum(col(\"amount\")).over(window_spec_total_revenue)\n",
        ")\n",
        "total_revenue_window.select(\"region\", \"order_id\", \"amount\", \"total_revenue\").orderBy(\"region\", \"order_id\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFkAZhh838Vl",
        "outputId": "8b4b6ef5-77b2-4137-d952-61d2b48c831f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+------+-------------+\n",
            "|region|order_id|amount|total_revenue|\n",
            "+------+--------+------+-------------+\n",
            "| North|    O001|   450|         1550|\n",
            "| North|    O002|   250|         1550|\n",
            "| North|    O013|   480|         1550|\n",
            "| North|    O021|   370|         1550|\n",
            "|  West|    O010|   520|         1190|\n",
            "|  West|    O011|   280|         1190|\n",
            "|  West|    O020|   390|         1190|\n",
            "+------+--------+------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Compare:\n",
        "Row count\n",
        "Output structure\n",
        "Use case"
      ],
      "metadata": {
        "id": "RrOV8Wtg4Owj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7087a723"
      },
      "source": [
        "### Comparison between GROUP BY and Window Functions\n",
        "\n",
        "**1. Row Count**\n",
        "*   **`groupBy`**: Reduces the number of rows in the DataFrame. It aggregates rows based on the grouping keys, resulting in one row per unique group.\n",
        "    *   `total_revenue_groupby` has 2 rows (one for 'North' and one for 'West').\n",
        "\n",
        "*   **`Window`**: Maintains the original number of rows in the DataFrame. It adds new columns with calculated values to each row, where calculations are performed over a defined window.\n",
        "    *   `total_revenue_window` has the same number of rows as `df_orders` (which is 7 rows based on the filtered data, as it simply adds a `total_revenue` column to each existing row).\n",
        "\n",
        "**2. Output Structure**\n",
        "*   **`groupBy`**: The output DataFrame contains only the grouping columns and the aggregated columns.\n",
        "    *   `total_revenue_groupby`: `region`, `total_revenue`\n",
        "\n",
        "*   **`Window`**: The output DataFrame contains all the original columns from the input DataFrame, plus the new column(s) generated by the window function.\n",
        "    *   `total_revenue_window`: All original columns of `df_orders` (`order_id`, `order_date`, `region`, etc.) plus `total_revenue`.\n",
        "\n",
        "**3. Use Case**\n",
        "*   **`groupBy`**: Use when you need to **summarize** data at a higher level of granularity, reducing the dataset to one record per group. Examples include calculating total sales per region, average amount per food item, or counting orders per city.\n",
        "\n",
        "*   **`Window`**: Use when you need to perform calculations that involve a group of rows but want to **retain the original row-level detail**. This is often for contextual analysis, such as calculating running totals, rankings within groups, moving averages, or comparing a row's value to the group's average/max/min."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Explain why Window does not reduce rows"
      ],
      "metadata": {
        "id": "BikOK80d4__U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Window functions do not reduce the number of rows in a DataFrame because their primary purpose is to perform calculations over a defined window of rows while retaining the original row-level detail. Unlike groupBy aggregations, which collapse groups of rows into a single summary row, window functions add new columns to the existing DataFrame, where each new column contains the result of a calculation performed on a subset of rows (the 'window') that is somehow related to the current row. This allows you to enrich each row with contextual information without losing any of your original data."
      ],
      "metadata": {
        "id": "wZyvojSC5ECT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EXERCISE SET 8 — DAG & PERFORMANCE ANALYSIS"
      ],
      "metadata": {
        "id": "wAOU6He24kyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Run explain(True) for:\n",
        "Simple select\n",
        "Filter\n",
        "GroupBy aggregation\n",
        "Window function"
      ],
      "metadata": {
        "id": "ZBylbvo_4ntM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e78ca4f"
      },
      "source": [
        "### Explain(True) for Different Spark Operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a65caf84",
        "outputId": "e840de7b-63bd-4fe5-f803-6eab4cc27463"
      },
      "source": [
        "# Simple Select\n",
        "print(\"\\n--- Explain for Simple Select ---\")\n",
        "df_orders.select(\"order_id\", \"region\", \"food_item\").explain(True)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Explain for Simple Select ---\n",
            "== Parsed Logical Plan ==\n",
            "'Project ['order_id, 'region, 'food_item]\n",
            "+- Filter city#2 IN (Delhi,Mumbai)\n",
            "   +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "      +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51]\n",
            "         +- Project [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L, (cast(amount#6L as double) / cast(1000 as double)) AS amount_in_hundreds#51]\n",
            "            +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "order_id: string, region: string, food_item: string\n",
            "Project [order_id#0, region#1, food_item#4]\n",
            "+- Filter city#2 IN (Delhi,Mumbai)\n",
            "   +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "      +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51]\n",
            "         +- Project [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L, (cast(amount#6L as double) / cast(1000 as double)) AS amount_in_hundreds#51]\n",
            "            +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [order_id#0, region#1, food_item#4]\n",
            "+- Filter city#2 IN (Delhi,Mumbai)\n",
            "   +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Physical Plan ==\n",
            "*(1) Project [order_id#0, region#1, food_item#4]\n",
            "+- *(1) Filter city#2 IN (Delhi,Mumbai)\n",
            "   +- *(1) Scan ExistingRDD[order_id#0,region#1,city#2,restaurant_id#3,food_item#4,order_date#5,amount#6L,delivery_time_min#7L]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dec3b55",
        "outputId": "b9560adf-54db-4afd-a5c4-e205c081a714"
      },
      "source": [
        "# Filter Operation\n",
        "print(\"\\n--- Explain for Filter Operation ---\")\n",
        "df_orders.filter(col(\"amount\") > 400).explain(True)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Explain for Filter Operation ---\n",
            "== Parsed Logical Plan ==\n",
            "'Filter '`>`('amount, 400)\n",
            "+- Filter city#2 IN (Delhi,Mumbai)\n",
            "   +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "      +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51]\n",
            "         +- Project [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L, (cast(amount#6L as double) / cast(1000 as double)) AS amount_in_hundreds#51]\n",
            "            +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "order_id: string, order_date: string, region: string, city: string, restaurant_id: string, food_item: string, delivery_time_min: bigint, amount: bigint, amount_in_hundreds: double, order_day: int\n",
            "Filter (amount#6L > cast(400 as bigint))\n",
            "+- Filter city#2 IN (Delhi,Mumbai)\n",
            "   +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "      +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51]\n",
            "         +- Project [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L, (cast(amount#6L as double) / cast(1000 as double)) AS amount_in_hundreds#51]\n",
            "            +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, (cast(amount#6L as double) / 1000.0) AS amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "+- Filter (isnotnull(amount#6L) AND (city#2 IN (Delhi,Mumbai) AND (amount#6L > 400)))\n",
            "   +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Physical Plan ==\n",
            "*(1) Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, (cast(amount#6L as double) / 1000.0) AS amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "+- *(1) Filter (isnotnull(amount#6L) AND (city#2 IN (Delhi,Mumbai) AND (amount#6L > 400)))\n",
            "   +- *(1) Scan ExistingRDD[order_id#0,region#1,city#2,restaurant_id#3,food_item#4,order_date#5,amount#6L,delivery_time_min#7L]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f8e764b",
        "outputId": "ff392e0b-5c7a-4bb7-b9fc-46e71292327d"
      },
      "source": [
        "# GroupBy Aggregation\n",
        "print(\"\\n--- Explain for GroupBy Aggregation (revenue_per_region) ---\")\n",
        "revenue_per_region.explain(True)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Explain for GroupBy Aggregation (revenue_per_region) ---\n",
            "== Parsed Logical Plan ==\n",
            "'Aggregate ['region], ['region, 'sum('amount) AS total_revenue#417]\n",
            "+- Filter city#2 IN (Delhi,Mumbai)\n",
            "   +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "      +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51]\n",
            "         +- Project [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L, (cast(amount#6L as double) / cast(1000 as double)) AS amount_in_hundreds#51]\n",
            "            +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "region: string, total_revenue: bigint\n",
            "Aggregate [region#1], [region#1, sum(amount#6L) AS total_revenue#417L]\n",
            "+- Filter city#2 IN (Delhi,Mumbai)\n",
            "   +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "      +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51]\n",
            "         +- Project [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L, (cast(amount#6L as double) / cast(1000 as double)) AS amount_in_hundreds#51]\n",
            "            +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Aggregate [region#1], [region#1, sum(amount#6L) AS total_revenue#417L]\n",
            "+- Project [region#1, amount#6L]\n",
            "   +- Filter city#2 IN (Delhi,Mumbai)\n",
            "      +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- HashAggregate(keys=[region#1], functions=[sum(amount#6L)], output=[region#1, total_revenue#417L])\n",
            "   +- Exchange hashpartitioning(region#1, 200), ENSURE_REQUIREMENTS, [plan_id=1025]\n",
            "      +- HashAggregate(keys=[region#1], functions=[partial_sum(amount#6L)], output=[region#1, sum#432L])\n",
            "         +- Project [region#1, amount#6L]\n",
            "            +- Filter city#2 IN (Delhi,Mumbai)\n",
            "               +- Scan ExistingRDD[order_id#0,region#1,city#2,restaurant_id#3,food_item#4,order_date#5,amount#6L,delivery_time_min#7L]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d2bf88c",
        "outputId": "000e0e07-449a-4ece-b68c-5702967c47ab"
      },
      "source": [
        "# Window Function\n",
        "print(\"\\n--- Explain for Window Function (running_total_revenue) ---\")\n",
        "running_total_revenue.explain(True)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Explain for Window Function (running_total_revenue) ---\n",
            "== Parsed Logical Plan ==\n",
            "'Project [unresolvedstarwithcolumns(running_total_revenue, 'sum('amount) windowspecdefinition('region, 'order_date ASC NULLS FIRST, unspecifiedframe$()), None)]\n",
            "+- Filter city#2 IN (Delhi,Mumbai)\n",
            "   +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "      +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51]\n",
            "         +- Project [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L, (cast(amount#6L as double) / cast(1000 as double)) AS amount_in_hundreds#51]\n",
            "            +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "order_id: string, order_date: string, region: string, city: string, restaurant_id: string, food_item: string, delivery_time_min: bigint, amount: bigint, amount_in_hundreds: double, order_day: int, running_total_revenue: bigint\n",
            "Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51, order_day#115, running_total_revenue#610L]\n",
            "+- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51, order_day#115, running_total_revenue#610L, running_total_revenue#610L]\n",
            "   +- Window [sum(amount#6L) windowspecdefinition(region#1, order_date#5 ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS running_total_revenue#610L], [region#1], [order_date#5 ASC NULLS FIRST]\n",
            "      +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51, order_day#115]\n",
            "         +- Filter city#2 IN (Delhi,Mumbai)\n",
            "            +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "               +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, amount_in_hundreds#51]\n",
            "                  +- Project [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L, (cast(amount#6L as double) / cast(1000 as double)) AS amount_in_hundreds#51]\n",
            "                     +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Window [sum(amount#6L) windowspecdefinition(region#1, order_date#5 ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS running_total_revenue#610L], [region#1], [order_date#5 ASC NULLS FIRST]\n",
            "+- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, (cast(amount#6L as double) / 1000.0) AS amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "   +- Filter city#2 IN (Delhi,Mumbai)\n",
            "      +- LogicalRDD [order_id#0, region#1, city#2, restaurant_id#3, food_item#4, order_date#5, amount#6L, delivery_time_min#7L], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Window [sum(amount#6L) windowspecdefinition(region#1, order_date#5 ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS running_total_revenue#610L], [region#1], [order_date#5 ASC NULLS FIRST]\n",
            "   +- Sort [region#1 ASC NULLS FIRST, order_date#5 ASC NULLS FIRST], false, 0\n",
            "      +- Exchange hashpartitioning(region#1, 200), ENSURE_REQUIREMENTS, [plan_id=1765]\n",
            "         +- Project [order_id#0, order_date#5, region#1, city#2, restaurant_id#3, food_item#4, delivery_time_min#7L, amount#6L, (cast(amount#6L as double) / 1000.0) AS amount_in_hundreds#51, day(cast(order_date#5 as date)) AS order_day#115]\n",
            "            +- Filter city#2 IN (Delhi,Mumbai)\n",
            "               +- Scan ExistingRDD[order_id#0,region#1,city#2,restaurant_id#3,food_item#4,order_date#5,amount#6L,delivery_time_min#7L]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Identify:\n",
        "Exchange operators\n",
        "Sort operations\n",
        "Stage boundaries"
      ],
      "metadata": {
        "id": "oHRWil4C5Jjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exchange Operators (Shuffles)\n",
        "\n",
        "Purpose: Redistribute data across partitions; costly operation.\n",
        "GroupBy Aggregation:\n",
        "Exchange hashpartitioning(region, 200) → Shuffle by region to group records before HashAggregate.\n",
        "Window Function:\n",
        "Exchange hashpartitioning(region, 200) → Shuffle by region for Window.partitionBy(\"region\").\n",
        "\n",
        "Sort Operations\n",
        "\n",
        "Purpose: Reorder data within partitions.\n",
        "Triggered by: orderBy in window specs or global sort.\n",
        "Example:\n",
        "Sort [region ASC, order_date ASC] → After shuffle, sort within region for running total.\n",
        "\n",
        "Stage Boundaries\n",
        "\n",
        "Marked by: Exchange operators.\n",
        "GroupBy Aggregation:\n",
        "\n",
        "Stage 1: Scan, Project, Partial HashAggregate.\n",
        "Stage 2: After shuffle → Final HashAggregate.\n",
        "\n",
        "\n",
        "Window Function:\n",
        "\n",
        "Stage 1: Scan.\n",
        "Stage 2: After shuffle → Sort + Window calculations."
      ],
      "metadata": {
        "id": "Ex_P4bNg5Kbe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Explain why window functions require sorting"
      ],
      "metadata": {
        "id": "eVCF9Owl5dDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Order-Dependent Calculations:\n",
        "\n",
        "Running Aggregates (sum, avg with frames): Need rows in correct order for cumulative totals.\n",
        "Ranking Functions (rank(), row_number(), ntile()): Assign ranks based on row order.\n",
        "Lag/Lead Functions: Depend on preceding/succeeding rows → requires consistent ordering.\n",
        "\n",
        "\n",
        "\n",
        "Window Frame:\n",
        "\n",
        "Defines rows relative to the current row (e.g., ROWS BETWEEN ...).\n",
        "Only meaningful if rows are sorted.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Physical Plan Implications\n",
        "\n",
        "Spark performs Sort after Exchange when ORDER BY is in window spec.\n",
        "Ensures correct ordering within each partition before applying window logic.\n",
        "Without sorting → results are non-deterministic or wrong.\n",
        "\n",
        "\n",
        "Most Expensive Operations in Spark DAG\n",
        "\n",
        "Shuffles (Exchange operators):\n",
        "\n",
        "Data movement across network → highest cost.\n",
        "\n",
        "\n",
        "Sort operations:\n",
        "\n",
        "Reordering data → CPU/memory intensive.\n",
        "\n",
        "\n",
        "Aggregations (post-shuffle):\n",
        "\n",
        "Heavy on resources.\n",
        "\n",
        "\n",
        "Cheap operations:\n",
        "\n",
        "Simple Select and Filter (no shuffle/sort)."
      ],
      "metadata": {
        "id": "WKZZl_js6DUY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Identify expensive operations in each DAG"
      ],
      "metadata": {
        "id": "NFYzocwB6Lyy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EXERCISE SET 9 — THINKING QUESTIONS"
      ],
      "metadata": {
        "id": "kBLlVixz6OXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Why does GroupBy introduce shuffle?\n",
        "\n",
        "Answer: In Spark, groupBy aggregates data based on keys. To do this, all rows with the same key must end up on the same partition.\n",
        "Since keys can be spread across multiple partitions, Spark shuffles data across the cluster so that identical keys are co-located.\n",
        "Reason: Shuffle ensures correctness of aggregation but is expensive because it involves disk I/O, network transfer, and serialization."
      ],
      "metadata": {
        "id": "GEJdaJsy6TTs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Why does Window not reduce rows?\n",
        "\n",
        "Answer: A window function computes values over a set of rows (a “window”) but does not collapse rows like groupBy does.\n",
        "Each input row remains in the output; Spark just adds extra columns with computed values (e.g., rank, moving average).\n",
        "Reason: Window functions are designed for analytics where you need row-level detail plus aggregated contex"
      ],
      "metadata": {
        "id": "GVtVEk7h6sa7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Why does repartition always cause shuffle?\n",
        "\n",
        "Answer: repartition(n) changes the number of partitions and redistributes data evenly across them.\n",
        "To achieve even distribution, Spark must shuffle data across the cluster.\n",
        "Reason: It’s a full shuffle operation because Spark cannot predict which partition each row should go to without redistributing."
      ],
      "metadata": {
        "id": "vtJb-HLN6W8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Why is coalesce cheaper than repartition?\n",
        "\n",
        "Answer: coalesce(n) reduces the number of partitions without a full shuffle by merging existing partitions.\n",
        "It avoids moving data unnecessarily; only partitions that need merging are touched.\n",
        "Reason: Coalesce is efficient for reducing partitions, but not for increasing them (which requires shuffle)"
      ],
      "metadata": {
        "id": "szapZPuT65D8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Why does Spark delay execution until an action?\n",
        "\n",
        "Answer: Spark uses lazy evaluation for transformations (like map, filter, groupBy).\n",
        "It builds a logical DAG of operations but does not execute until an action (like collect, count, save) is called.\n",
        "Reason: This allows Spark to optimize the entire pipeline before execution (e.g., combine stages, minimize shuffles)."
      ],
      "metadata": {
        "id": "vjukTnaj7Cqw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. When would you avoid window functions?\n",
        "\n",
        "Answer: Avoid window functions when:\n",
        "Data is huge and window operations require sorting or shuffling (very expensive).\n",
        "You only need aggregated results (use groupBy instead).\n",
        "Performance is critical and simpler aggregations suffice.\n",
        "Reason: Window functions often involve full partition sorting, which is costly in distributed systems."
      ],
      "metadata": {
        "id": "KsR2QJQ07JI3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gLq7AJNC4NH8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}