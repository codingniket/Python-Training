{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1x1UdobfSgb"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName(\"exercise\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rides_data = [\n",
        "(\"R001\",\"U001\",\"Hyderabad\",12.5,240,\"Completed\"),\n",
        "(\"R002\",\"U002\",\"Delhi\",8.2,180,\"Completed\"),\n",
        "(\"R003\",\"U003\",\"Mumbai\",15.0,300,\"Cancelled\"),\n",
        "(\"R004\",\"U004\",\"Bangalore\",5.5,120,\"Completed\"),\n",
        "(\"R005\",\"U005\",\"Hyderabad\",20.0,360,\"Completed\"),\n",
        "(\"R006\",\"U006\",\"Delhi\",25.0,420,\"Completed\"),\n",
        "(\"R007\",\"U007\",\"Mumbai\",7.5,150,\"Completed\"),\n",
        "(\"R008\",\"U008\",\"Bangalore\",18.0,330,\"Completed\"),\n",
        "(\"R009\",\"U009\",\"Delhi\",6.0,140,\"Cancelled\"),\n",
        "(\"R010\",\"U010\",\"Hyderabad\",10.0,200,\"Completed\")\n",
        "]\n",
        "rides_cols = [\n",
        "\"ride_id\",\n",
        "\"user_id\",\n",
        "\"city\",\n",
        "\"distance_km\",\n",
        "\"duration_seconds\",\n",
        "\"status\"\n",
        "]\n",
        "\n",
        "rides_df = spark.createDataFrame(rides_data, rides_cols)\n",
        "rides_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cWziRkEftWy",
        "outputId": "72bc244d-5f0c-4eb5-f287-ccca481a8c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+---------+-----------+----------------+---------+\n",
            "|ride_id|user_id|     city|distance_km|duration_seconds|   status|\n",
            "+-------+-------+---------+-----------+----------------+---------+\n",
            "|   R001|   U001|Hyderabad|       12.5|             240|Completed|\n",
            "|   R002|   U002|    Delhi|        8.2|             180|Completed|\n",
            "|   R003|   U003|   Mumbai|       15.0|             300|Cancelled|\n",
            "|   R004|   U004|Bangalore|        5.5|             120|Completed|\n",
            "|   R005|   U005|Hyderabad|       20.0|             360|Completed|\n",
            "|   R006|   U006|    Delhi|       25.0|             420|Completed|\n",
            "|   R007|   U007|   Mumbai|        7.5|             150|Completed|\n",
            "|   R008|   U008|Bangalore|       18.0|             330|Completed|\n",
            "|   R009|   U009|    Delhi|        6.0|             140|Cancelled|\n",
            "|   R010|   U010|Hyderabad|       10.0|             200|Completed|\n",
            "+-------+-------+---------+-----------+----------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "surge_data = [\n",
        "(\"Hyderabad\",1.2),\n",
        "(\"Delhi\",1.5),\n",
        "(\"Mumbai\",1.8),\n",
        "(\"Bangalore\",1.3)\n",
        "]\n",
        "surge_cols = [\"city\",\"surge_multiplier\"]\n",
        "surge_df = spark.createDataFrame(surge_data, surge_cols)\n",
        "surge_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVBPGb7SfzHq",
        "outputId": "6a2c54bd-1500-470e-fcda-3fc5c077b8c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------------+\n",
            "|     city|surge_multiplier|\n",
            "+---------+----------------+\n",
            "|Hyderabad|             1.2|\n",
            "|    Delhi|             1.5|\n",
            "|   Mumbai|             1.8|\n",
            "|Bangalore|             1.3|\n",
            "+---------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "filtered_orders = rides_df.filter(col(\"status\") == \"Completed\").select(\"ride_id\", \"city\", \"distance_km\")\n",
        "rows = filtered_orders.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybZ9tVkHf_Sz",
        "outputId": "d43e5159-88d7-4bf9-e0da-e273053ad224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+-----------+\n",
            "|ride_id|     city|distance_km|\n",
            "+-------+---------+-----------+\n",
            "|   R001|Hyderabad|       12.5|\n",
            "|   R002|    Delhi|        8.2|\n",
            "|   R004|Bangalore|        5.5|\n",
            "|   R005|Hyderabad|       20.0|\n",
            "|   R006|    Delhi|       25.0|\n",
            "|   R007|   Mumbai|        7.5|\n",
            "|   R008|Bangalore|       18.0|\n",
            "|   R010|Hyderabad|       10.0|\n",
            "+-------+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation — Has Spark executed anything?**\n",
        "\n",
        "No. Spark uses lazy evaluation: transformations build a DAG, but nothing runs until an action (e.g., count, show, write). The code above only constructs the logical plan."
      ],
      "metadata": {
        "id": "ARXrxW9GwmB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rows = filtered_orders.count()"
      ],
      "metadata": {
        "id": "vfz_u5y5wvrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What caused execution?**\n",
        "\n",
        "The line pipeline_df.count() is the action that triggers job execution.\n",
        "Previous lines are transformations; they didn’t execute because Spark defers computation until an action is called."
      ],
      "metadata": {
        "id": "_zHpm4u3w0TT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "filtered_selected =rides_df.filter(col(\"status\") == \"Completed\").filter(col(\"distance_km\") > 10).select(\"ride_id\", \"city\", \"distance_km\")\n",
        "filtered_selected.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY_e4NzhnzUM",
        "outputId": "24eccbb7-4777-4864-8f40-251a7d9a68cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+-----------+\n",
            "|ride_id|     city|distance_km|\n",
            "+-------+---------+-----------+\n",
            "|   R001|Hyderabad|       12.5|\n",
            "|   R005|Hyderabad|       20.0|\n",
            "|   R006|    Delhi|       25.0|\n",
            "|   R008|Bangalore|       18.0|\n",
            "+-------+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_selected.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxsADjcOjrbm",
        "outputId": "fa9b50b6-d0b4-4115-ae30-0cfe44fdae81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Project ['ride_id, 'city, 'distance_km]\n",
            "+- Filter (distance_km#3 > cast(10 as double))\n",
            "   +- Filter (status#5 = Completed)\n",
            "      +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "ride_id: string, city: string, distance_km: double\n",
            "Project [ride_id#0, city#2, distance_km#3]\n",
            "+- Filter (distance_km#3 > cast(10 as double))\n",
            "   +- Filter (status#5 = Completed)\n",
            "      +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [ride_id#0, city#2, distance_km#3]\n",
            "+- Filter ((isnotnull(status#5) AND isnotnull(distance_km#3)) AND ((status#5 = Completed) AND (distance_km#3 > 10.0)))\n",
            "   +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "\n",
            "== Physical Plan ==\n",
            "*(1) Project [ride_id#0, city#2, distance_km#3]\n",
            "+- *(1) Filter ((isnotnull(status#5) AND isnotnull(distance_km#3)) AND ((status#5 = Completed) AND (distance_km#3 > 10.0)))\n",
            "   +- *(1) Scan ExistingRDD[ride_id#0,user_id#1,city#2,distance_km#3,duration_seconds#4L,status#5]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rides_df.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENZtxluejwxu",
        "outputId": "359f2929-e286-4122-d9ec-60cca978a2b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_repart=rides_df.repartition(3)\n",
        "df_repart.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZ6JmoVTkF1x",
        "outputId": "22711947-65ed-4565-b7dd-0c0ad404c923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_coalsec=rides_df.coalesce(1)\n",
        "df_coalsec.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "os59DVbQo7cs",
        "outputId": "a24235d4-f2cd-4bab-b994-d4ed2b58c20a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_selected.write.mode(\"overwrite\").parquet(\"/tmp/output_parquet\")"
      ],
      "metadata": {
        "id": "saYb858lpE77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_repart=rides_df.repartition(\"city\")\n",
        "df_repart.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4glRAxC-pRRL",
        "outputId": "2607c06e-b442-4ff6-9e49-6fd61d49915d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Is a shuffle introduced?**\n",
        "\n",
        "Yes. Repartitioning by a column requires redistributing rows by key across executors, leading to an Exchange (shuffle) operator in the physical plan."
      ],
      "metadata": {
        "id": "JXEeRimsxJWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rides_df.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGjwdxoEpbD8",
        "outputId": "900a7cf3-1d45-48e9-e8e7-e6c4ade78a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "ride_id: string, user_id: string, city: string, distance_km: double, duration_seconds: bigint, status: string\n",
            "LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "\n",
            "== Physical Plan ==\n",
            "*(1) Scan ExistingRDD[ride_id#0,user_id#1,city#2,distance_km#3,duration_seconds#4L,status#5]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joined_df = rides_df.join(\n",
        "    surge_df,\n",
        "    on=\"city\",\n",
        "    how=\"inner\"\n",
        ")\n",
        "joined_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1wptXQIqDpS",
        "outputId": "d98cf9e6-68ad-4742-cd0c-8cab3772dfdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+-------+-----------+----------------+---------+----------------+\n",
            "|     city|ride_id|user_id|distance_km|duration_seconds|   status|surge_multiplier|\n",
            "+---------+-------+-------+-----------+----------------+---------+----------------+\n",
            "|Bangalore|   R004|   U004|        5.5|             120|Completed|             1.3|\n",
            "|Bangalore|   R008|   U008|       18.0|             330|Completed|             1.3|\n",
            "|    Delhi|   R002|   U002|        8.2|             180|Completed|             1.5|\n",
            "|    Delhi|   R006|   U006|       25.0|             420|Completed|             1.5|\n",
            "|    Delhi|   R009|   U009|        6.0|             140|Cancelled|             1.5|\n",
            "|Hyderabad|   R001|   U001|       12.5|             240|Completed|             1.2|\n",
            "|Hyderabad|   R005|   U005|       20.0|             360|Completed|             1.2|\n",
            "|Hyderabad|   R010|   U010|       10.0|             200|Completed|             1.2|\n",
            "|   Mumbai|   R003|   U003|       15.0|             300|Cancelled|             1.8|\n",
            "|   Mumbai|   R007|   U007|        7.5|             150|Completed|             1.8|\n",
            "+---------+-------+-------+-----------+----------------+---------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joined_df.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WJoBOrHqKBQ",
        "outputId": "729b8880-82af-4a63-f41e-adbc11812b0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Join UsingJoin(Inner, [city])\n",
            ":- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "+- LogicalRDD [city#25, surge_multiplier#26], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city: string, ride_id: string, user_id: string, distance_km: double, duration_seconds: bigint, status: string, surge_multiplier: double\n",
            "Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#26]\n",
            "+- Join Inner, (city#2 = city#25)\n",
            "   :- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "   +- LogicalRDD [city#25, surge_multiplier#26], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#26]\n",
            "+- Join Inner, (city#2 = city#25)\n",
            "   :- Filter isnotnull(city#2)\n",
            "   :  +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "   +- Filter isnotnull(city#25)\n",
            "      +- LogicalRDD [city#25, surge_multiplier#26], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#26]\n",
            "   +- SortMergeJoin [city#2], [city#25], Inner\n",
            "      :- Sort [city#2 ASC NULLS FIRST], false, 0\n",
            "      :  +- Exchange hashpartitioning(city#2, 200), ENSURE_REQUIREMENTS, [plan_id=1527]\n",
            "      :     +- Filter isnotnull(city#2)\n",
            "      :        +- Scan ExistingRDD[ride_id#0,user_id#1,city#2,distance_km#3,duration_seconds#4L,status#5]\n",
            "      +- Sort [city#25 ASC NULLS FIRST], false, 0\n",
            "         +- Exchange hashpartitioning(city#25, 200), ENSURE_REQUIREMENTS, [plan_id=1528]\n",
            "            +- Filter isnotnull(city#25)\n",
            "               +- Scan ExistingRDD[city#25,surge_multiplier#26]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rides_df = rides_df.filter(col(\"distance_km\") > 10)\n",
        "joined_df = rides_df.join(\n",
        "    surge_df,\n",
        "    on=\"city\",\n",
        "    how=\"inner\"\n",
        ")\n",
        "joined_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYkd3xJ0qW9R",
        "outputId": "1ef706db-2688-4b4a-976b-30b24145f885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+-------+-----------+----------------+---------+----------------+\n",
            "|     city|ride_id|user_id|distance_km|duration_seconds|   status|surge_multiplier|\n",
            "+---------+-------+-------+-----------+----------------+---------+----------------+\n",
            "|Bangalore|   R008|   U008|       18.0|             330|Completed|             1.3|\n",
            "|    Delhi|   R006|   U006|       25.0|             420|Completed|             1.5|\n",
            "|Hyderabad|   R001|   U001|       12.5|             240|Completed|             1.2|\n",
            "|Hyderabad|   R005|   U005|       20.0|             360|Completed|             1.2|\n",
            "|   Mumbai|   R003|   U003|       15.0|             300|Cancelled|             1.8|\n",
            "+---------+-------+-------+-----------+----------------+---------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joined_df.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9dsL1FQquVT",
        "outputId": "c88ae269-5fcf-4cc9-de4e-3bfaf0c671fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Join UsingJoin(Inner, [city])\n",
            ":- Filter (distance_km#3 > cast(10 as double))\n",
            ":  +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "+- LogicalRDD [city#25, surge_multiplier#26], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city: string, ride_id: string, user_id: string, distance_km: double, duration_seconds: bigint, status: string, surge_multiplier: double\n",
            "Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#26]\n",
            "+- Join Inner, (city#2 = city#25)\n",
            "   :- Filter (distance_km#3 > cast(10 as double))\n",
            "   :  +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "   +- LogicalRDD [city#25, surge_multiplier#26], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#26]\n",
            "+- Join Inner, (city#2 = city#25)\n",
            "   :- Filter ((isnotnull(distance_km#3) AND (distance_km#3 > 10.0)) AND isnotnull(city#2))\n",
            "   :  +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "   +- Filter isnotnull(city#25)\n",
            "      +- LogicalRDD [city#25, surge_multiplier#26], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#26]\n",
            "   +- SortMergeJoin [city#2], [city#25], Inner\n",
            "      :- Sort [city#2 ASC NULLS FIRST], false, 0\n",
            "      :  +- Exchange hashpartitioning(city#2, 200), ENSURE_REQUIREMENTS, [plan_id=1671]\n",
            "      :     +- Filter ((isnotnull(distance_km#3) AND (distance_km#3 > 10.0)) AND isnotnull(city#2))\n",
            "      :        +- Scan ExistingRDD[ride_id#0,user_id#1,city#2,distance_km#3,duration_seconds#4L,status#5]\n",
            "      +- Sort [city#25 ASC NULLS FIRST], false, 0\n",
            "         +- Exchange hashpartitioning(city#25, 200), ENSURE_REQUIREMENTS, [plan_id=1672]\n",
            "            +- Filter isnotnull(city#25)\n",
            "               +- Scan ExistingRDD[city#25,surge_multiplier#26]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import broadcast\n",
        "rides_df = rides_df.filter(col(\"distance_km\") > 10)\n",
        "broadcast_joined_df = rides_df.join(\n",
        "    broadcast(surge_df),\n",
        "    on=\"city\",\n",
        "    how=\"inner\"\n",
        ")\n",
        "broadcast_joined_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PuL-ieKqzOM",
        "outputId": "4b4372ed-7163-417e-88f8-29929c9db66e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+-------+-----------+----------------+---------+----------------+\n",
            "|     city|ride_id|user_id|distance_km|duration_seconds|   status|surge_multiplier|\n",
            "+---------+-------+-------+-----------+----------------+---------+----------------+\n",
            "|Hyderabad|   R001|   U001|       12.5|             240|Completed|             1.2|\n",
            "|   Mumbai|   R003|   U003|       15.0|             300|Cancelled|             1.8|\n",
            "|Hyderabad|   R005|   U005|       20.0|             360|Completed|             1.2|\n",
            "|    Delhi|   R006|   U006|       25.0|             420|Completed|             1.5|\n",
            "|Bangalore|   R008|   U008|       18.0|             330|Completed|             1.3|\n",
            "+---------+-------+-------+-----------+----------------+---------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "broadcast_joined_df.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysYE_k6Kq7Ne",
        "outputId": "6955c22b-8c4b-41ad-8561-4845dc5971ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Join UsingJoin(Inner, [city])\n",
            ":- Filter (distance_km#3 > cast(10 as double))\n",
            ":  +- Filter (distance_km#3 > cast(10 as double))\n",
            ":     +- Filter (distance_km#3 > cast(10 as double))\n",
            ":        +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "+- ResolvedHint (strategy=broadcast)\n",
            "   +- LogicalRDD [city#25, surge_multiplier#26], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city: string, ride_id: string, user_id: string, distance_km: double, duration_seconds: bigint, status: string, surge_multiplier: double\n",
            "Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#26]\n",
            "+- Join Inner, (city#2 = city#25)\n",
            "   :- Filter (distance_km#3 > cast(10 as double))\n",
            "   :  +- Filter (distance_km#3 > cast(10 as double))\n",
            "   :     +- Filter (distance_km#3 > cast(10 as double))\n",
            "   :        +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "   +- ResolvedHint (strategy=broadcast)\n",
            "      +- LogicalRDD [city#25, surge_multiplier#26], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#26]\n",
            "+- Join Inner, (city#2 = city#25), rightHint=(strategy=broadcast)\n",
            "   :- Filter ((isnotnull(distance_km#3) AND (distance_km#3 > 10.0)) AND isnotnull(city#2))\n",
            "   :  +- LogicalRDD [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], false\n",
            "   +- Filter isnotnull(city#25)\n",
            "      +- LogicalRDD [city#25, surge_multiplier#26], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#26]\n",
            "   +- BroadcastHashJoin [city#2], [city#25], Inner, BuildRight, false\n",
            "      :- Filter ((isnotnull(distance_km#3) AND (distance_km#3 > 10.0)) AND isnotnull(city#2))\n",
            "      :  +- Scan ExistingRDD[ride_id#0,user_id#1,city#2,distance_km#3,duration_seconds#4L,status#5]\n",
            "      +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=1879]\n",
            "         +- Filter isnotnull(city#25)\n",
            "            +- Scan ExistingRDD[city#25,surge_multiplier#26]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compare physical plans (non-broadcast vs broadcast)**\n",
        "\n",
        "Operators that disappear with broadcast:\n",
        "\n",
        "Exchange (shuffle by city)\n",
        "Sort (for SortMergeJoin)\n",
        "\n",
        "\n",
        "Performance impact:\n",
        "\n",
        "Removes expensive network shuffle and sorts → fewer stages, lower latency.\n",
        "Ideal when one side (lookup table) is small enough to fit in executor memory."
      ],
      "metadata": {
        "id": "Rsf4SmYixa8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "broadcast_joined_df.explain(mode=\"formatted\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bigwZ6brTqf",
        "outputId": "6d95392c-b0ea-488d-c486-b06d2c83ccab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan (8)\n",
            "+- Project (7)\n",
            "   +- BroadcastHashJoin Inner BuildRight (6)\n",
            "      :- Filter (2)\n",
            "      :  +- Scan ExistingRDD (1)\n",
            "      +- BroadcastExchange (5)\n",
            "         +- Filter (4)\n",
            "            +- Scan ExistingRDD (3)\n",
            "\n",
            "\n",
            "(1) Scan ExistingRDD\n",
            "Output [6]: [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5]\n",
            "Arguments: [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5], MapPartitionsRDD[4] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n",
            "\n",
            "(2) Filter\n",
            "Input [6]: [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5]\n",
            "Condition : ((isnotnull(distance_km#3) AND (distance_km#3 > 10.0)) AND isnotnull(city#2))\n",
            "\n",
            "(3) Scan ExistingRDD\n",
            "Output [2]: [city#25, surge_multiplier#26]\n",
            "Arguments: [city#25, surge_multiplier#26], MapPartitionsRDD[11] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:0, ExistingRDD, UnknownPartitioning(0)\n",
            "\n",
            "(4) Filter\n",
            "Input [2]: [city#25, surge_multiplier#26]\n",
            "Condition : isnotnull(city#25)\n",
            "\n",
            "(5) BroadcastExchange\n",
            "Input [2]: [city#25, surge_multiplier#26]\n",
            "Arguments: HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=1879]\n",
            "\n",
            "(6) BroadcastHashJoin\n",
            "Left keys [1]: [city#2]\n",
            "Right keys [1]: [city#25]\n",
            "Join type: Inner\n",
            "Join condition: None\n",
            "\n",
            "(7) Project\n",
            "Output [7]: [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#26]\n",
            "Input [8]: [ride_id#0, user_id#1, city#2, distance_km#3, duration_seconds#4L, status#5, city#25, surge_multiplier#26]\n",
            "\n",
            "(8) AdaptiveSparkPlan\n",
            "Output [7]: [city#2, ride_id#0, user_id#1, distance_km#3, duration_seconds#4L, status#5, surge_multiplier#26]\n",
            "Arguments: isFinalPlan=false\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 6.1 — Identify expensive operators & classify**\n",
        "\n",
        "Common expensive operators you’ll see in the physical plan:\n",
        "\n",
        "Exchange (shuffle) → Network-heavy (data moved across executors; also disk spill possible).\n",
        "Sort / SortMergeJoin → CPU-heavy (sorting large datasets), can be memory-heavy for buffers.\n",
        "HashAggregate / HashJoin → Memory-heavy (hash tables), also some CPU for hashing.\n",
        "BroadcastExchange → Network (sending small table to executors), lower cost vs full shuffle.\n",
        "FileScan on large inputs → I/O-heavy (disk), not CPU.\n",
        "\n",
        "\n",
        "**Exercise 6.2 — Why Spark defaults to SortMergeJoin?**\n",
        "\n",
        "For large equijoins, SortMergeJoin scales well: it sorts both sides and streams the merge—stable and spillable.\n",
        "It avoids building very large in-memory hash tables, which can be risky under pressure.\n",
        "Defaults are tuned for correctness and scalability; Spark uses broadcast or hash joins when configurations and size estimates indicate they’re better."
      ],
      "metadata": {
        "id": "Vaur15iZxvYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lower,col\n",
        "check_df=broadcast_joined_df.filter(col(\"status\")==\"Completed\").withColumn(\"city\",lower(col(\"city\"))).select(\"city\",\"ride_id\",\"user_id\")\n"
      ],
      "metadata": {
        "id": "PX9tUyEVr3UR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What has Spark done so far?**\n",
        "\n",
        "Spark has parsed your transformations, built the logical plan, applied Catalyst optimizations, and prepared a physical plan. Actual computation is deferred until you call an action."
      ],
      "metadata": {
        "id": "7cCUrwYrxjN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_df=check_df.count()\n",
        "check_df.show()\n",
        "\n",
        "output_path = \"/tmp/output_parquet\"\n",
        "\n",
        "check_df.write.mode(\"overwrite\").parquet(output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LmOfp2QsvDA",
        "outputId": "0070ae70-df62-4b8b-da7c-4f77166a3606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+-------+\n",
            "|     city|ride_id|user_id|\n",
            "+---------+-------+-------+\n",
            "|hyderabad|   R001|   U001|\n",
            "|hyderabad|   R005|   U005|\n",
            "|    delhi|   R006|   U006|\n",
            "|bangalore|   R008|   U008|\n",
            "+---------+-------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.**Why does broadcast remove shuffle from the DAG?**\n",
        "\n",
        "Broadcast sends the smaller DataFrame to all executors, so each partition of the larger DataFrame can join locally.\n",
        "This eliminates the need to redistribute data by key across the cluster.\n",
        "Result: No shuffle stage in the physical plan for the join.\n",
        "\n",
        "\n",
        "2.**Why does repartition always introduce shuffle?**\n",
        "\n",
        "Repartition changes how data is distributed across partitions.\n",
        "To achieve even distribution or partitioning by a column, Spark must move rows between executors.\n",
        "This movement is implemented as a shuffle (Exchange operator).\n",
        "\n",
        "\n",
        "3.**Why is coalesce cheaper than repartition?**\n",
        "\n",
        "Coalesce only reduces partitions by merging existing ones without redistributing data.\n",
        "It avoids a full shuffle and keeps data mostly where it is.\n",
        "Repartition, in contrast, always shuffles to evenly spread data.\n",
        "\n",
        "\n",
        "**4.Why does Spark delay execution until an action?**\n",
        "\n",
        "Spark uses lazy evaluation to build a logical DAG of transformations first.\n",
        "This allows Catalyst to optimize the entire plan before running it.\n",
        "Execution happens only when an action (e.g., count, show, write)\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VIa6qJXKty0U"
      }
    }
  ]
}