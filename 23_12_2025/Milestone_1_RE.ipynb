{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6rgq4NY52sd5QYQ2S5lll",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codingniket/Python-Training/blob/main/23_12_2025/Milestone_1_RE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_dRneyKr1L83"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, lit, when,regexp_replace, split, trim, array_compact, transform, get_json_object, lower\n",
        "spark = SparkSession.builder.appName(\"MileStone1\").getOrCreate()\n",
        "from pyspark.sql.types import (StructType, StructField, StringType,LongType,IntegerType,ArrayType,MapType)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Define an explicit schema\n",
        "\n",
        "2. Create a DataFrame using the schema\n",
        "3. Print schema and validate data types"
      ],
      "metadata": {
        "id": "d6epnOR52fNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_data = [\n",
        "(\"O001\",\"Delhi \",\"Laptop\",\"45000\",\"2024-01-05\",\"Completed\"),\n",
        "(\"O002\",\"Mumbai\",\"Mobile \",\"32000\",\"05/01/2024\",\"Completed\"),\n",
        "(\"O003\",\"Bangalore\",\"Tablet\",\"30000\",\"2024/01/06\",\"Completed\"),\n",
        "(\"O004\",\"Delhi\",\"Laptop\",\"\",\"2024-01-07\",\"Cancelled\"),\n",
        "(\"O005\",\"Mumbai\",\"Mobile\",\"invalid\",\"2024-01-08\",\"Completed\"),\n",
        "(\"O006\",\"Chennai\",\"Tablet\",None,\"2024-01-08\",\"Completed\"),\n",
        "(\"O007\",\"Delhi\",\"Laptop\",\"47000\",\"09-01-2024\",\"Completed\"),\n",
        "(\"O008\",\"Bangalore\",\"Mobile\",\"28000\",\"2024-01-09\",\"Completed\"),\n",
        "(\"O009\",\"Mumbai\",\"Laptop\",\"55000\",\"2024-01-10\",\"Completed\"),\n",
        "(\"O009\",\"Mumbai\",\"Laptop\",\"55000\",\"2024-01-10\",\"Completed\")\n",
        "]"
      ],
      "metadata": {
        "id": "xzZIdGFX1Uea"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orders_schema = StructType([\n",
        "    StructField(\"order_id\", StringType(), True),\n",
        "    StructField(\"city\", StringType(), True),\n",
        "    StructField(\"product\",StringType(),True),\n",
        "    StructField(\"amount\",StringType(),True),\n",
        "    StructField(\"order_date\",StringType(),True),\n",
        "     StructField(\"status\",StringType(),True),\n",
        "])\n",
        "\n",
        "\n",
        "order_df =  spark.createDataFrame(orders_data,orders_schema)"
      ],
      "metadata": {
        "id": "Ki0moV_b1ZGf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "order_df.printSchema()\n",
        "order_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN3fcjhg2nPW",
        "outputId": "1ff435c4-3bf6-43a8-fee4-51a44f384a76"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- order_id: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- product: string (nullable = true)\n",
            " |-- amount: string (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            "\n",
            "+--------+---------+-------+-------+----------+---------+\n",
            "|order_id|     city|product| amount|      date|   status|\n",
            "+--------+---------+-------+-------+----------+---------+\n",
            "|    O001|   Delhi | Laptop|  45000|2024-01-05|Completed|\n",
            "|    O002|   Mumbai|Mobile |  32000|05/01/2024|Completed|\n",
            "|    O003|Bangalore| Tablet|  30000|2024/01/06|Completed|\n",
            "|    O004|    Delhi| Laptop|       |2024-01-07|Cancelled|\n",
            "|    O005|   Mumbai| Mobile|invalid|2024-01-08|Completed|\n",
            "|    O006|  Chennai| Tablet|   NULL|2024-01-08|Completed|\n",
            "|    O007|    Delhi| Laptop|  47000|09-01-2024|Completed|\n",
            "|    O008|Bangalore| Mobile|  28000|2024-01-09|Completed|\n",
            "|    O009|   Mumbai| Laptop|  55000|2024-01-10|Completed|\n",
            "|    O009|   Mumbai| Laptop|  55000|2024-01-10|Completed|\n",
            "+--------+---------+-------+-------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, upper ,to_date, coalesce, split, lit, array_remove, try_to_timestamp,regexp_extract"
      ],
      "metadata": {
        "id": "O9pZqJ_X2EEU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Trim all string columns\n",
        "\n",
        ". Standardize city and product values\n",
        "\n",
        ". Convert amount to IntegerType\n",
        "\n",
        ". Handle invalid and null amount values\n",
        "\n",
        ". Remove duplicate orders\n",
        "\n",
        ". Keep only Completed order"
      ],
      "metadata": {
        "id": "7DpYyDki20Di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_price_str = regexp_extract(col(\"amount\"), r\"(\\d+)\", 0)\n",
        "clean_order_df = order_df.withColumn(\n",
        "    \"order_date\",\n",
        "    coalesce(\n",
        "        to_date(try_to_timestamp(col(\"order_date\"), lit(\"yyyy-MM-dd\"))),\n",
        "        to_date(try_to_timestamp(col(\"order_date\"), lit(\"dd/MM/yyyy\"))),\n",
        "        to_date(try_to_timestamp(col(\"order_date\"), lit(\"yyyy/MM/dd\")))\n",
        "    )\n",
        ")\\\n",
        ".withColumn(\"amount\",when((numeric_price_str == \"\") | numeric_price_str.isNull(), lit(0)).otherwise(numeric_price_str.cast('int')))\\\n",
        ".withColumn(\"product\",trim(col(\"product\")))\\\n",
        ".withColumn(\"city\",trim(col(\"city\")))\n",
        "\n",
        "clean_order_df = clean_order_df.dropDuplicates()\n",
        "\n",
        "completed_df = clean_order_df.filter(col(\"status\") == \"Completed\")\n",
        "\n",
        "\n",
        "\n",
        "completed_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdGJi2yR1wsd",
        "outputId": "0b780898-bb94-4a6f-ff89-b736519b6fd7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+-------+------+----------+---------+\n",
            "|order_id|     city|product|amount|order_date|   status|\n",
            "+--------+---------+-------+------+----------+---------+\n",
            "|    O002|   Mumbai| Mobile| 32000|2024-01-05|Completed|\n",
            "|    O005|   Mumbai| Mobile|     0|2024-01-08|Completed|\n",
            "|    O001|    Delhi| Laptop| 45000|2024-01-05|Completed|\n",
            "|    O003|Bangalore| Tablet| 30000|2024-01-06|Completed|\n",
            "|    O009|   Mumbai| Laptop| 55000|2024-01-10|Completed|\n",
            "|    O008|Bangalore| Mobile| 28000|2024-01-09|Completed|\n",
            "|    O006|  Chennai| Tablet|     0|2024-01-08|Completed|\n",
            "|    O007|    Delhi| Laptop| 47000|      NULL|Completed|\n",
            "+--------+---------+-------+------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "order_df = completed_df"
      ],
      "metadata": {
        "id": "rDYXw3qk2qFz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tasks\n",
        "\n",
        ". Total revenue per city\n",
        "\n",
        ". Total revenue per product\n",
        "\n",
        ". Average order value per city"
      ],
      "metadata": {
        "id": "94OINt7O3eMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_revenue_per_city = order_df.groupBy(\"city\").agg({\"amount\": \"sum\"})\n",
        "total_revenue_per_city.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcFk8GS23bKm",
        "outputId": "9d18d748-dee0-4540-9c94-b96ba85f6648"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+\n",
            "|     city|sum(amount)|\n",
            "+---------+-----------+\n",
            "|Bangalore|      58000|\n",
            "|  Chennai|          0|\n",
            "|   Mumbai|      87000|\n",
            "|    Delhi|      92000|\n",
            "+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_revenue_per_product = order_df.groupBy(\"product\").agg({\"amount\": \"sum\"})\n",
        "total_revenue_per_product.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mf_j8Sx3kwL",
        "outputId": "49a3b966-5fef-4ec8-9717-11ba5b541aa1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+\n",
            "|product|sum(amount)|\n",
            "+-------+-----------+\n",
            "| Laptop|     147000|\n",
            "| Mobile|      60000|\n",
            "| Tablet|      30000|\n",
            "+-------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_order_value_per_city = order_df.groupBy(\"city\").agg({\"amount\": \"avg\"})\n",
        "avg_order_value_per_city.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mK0q_i93owU",
        "outputId": "f9f98dfd-c1a0-4511-b58c-3b9b102054de"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+\n",
            "|     city|avg(amount)|\n",
            "+---------+-----------+\n",
            "|Bangalore|    29000.0|\n",
            "|  Chennai|        0.0|\n",
            "|   Mumbai|    29000.0|\n",
            "|    Delhi|    46000.0|\n",
            "+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tasks\n",
        "\n",
        ". Rank cities by total revenue\n",
        "\n",
        ". Identify top-performing city"
      ],
      "metadata": {
        "id": "tSsaDsnb38Ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import rank, desc\n",
        "\n",
        "city_revenue_ranked = order_df.groupBy(\"city\").agg({\"amount\": \"sum\"}).withColumnRenamed(\"sum(amount)\", \"total_revenue\")\n",
        "city_revenue_ranked = city_revenue_ranked.orderBy(desc(\"total_revenue\"))\n",
        "\n",
        "window_spec = Window.orderBy(desc(\"total_revenue\"))\n",
        "city_revenue_ranked = city_revenue_ranked.withColumn(\"city_rank\", rank().over(window_spec))\n",
        "city_revenue_ranked.show()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJbvsbP946rL",
        "outputId": "126b0508-83da-4102-a659-07e484b64e58"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------+---------+\n",
            "|     city|total_revenue|city_rank|\n",
            "+---------+-------------+---------+\n",
            "|    Delhi|        92000|        1|\n",
            "|   Mumbai|        87000|        2|\n",
            "|Bangalore|        58000|        3|\n",
            "|  Chennai|            0|        4|\n",
            "+---------+-------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "city_revenue_ranked.limit(3).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nds3kTMl5Eb6",
        "outputId": "3d5bbed9-3d92-42a7-e378-6233a291e617"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------+---------+\n",
            "|     city|total_revenue|city_rank|\n",
            "+---------+-------------+---------+\n",
            "|    Delhi|        92000|        1|\n",
            "|   Mumbai|        87000|        2|\n",
            "|Bangalore|        58000|        3|\n",
            "+---------+-------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tasks\n",
        "\n",
        ". Cache the cleaned DataFrame\n",
        "\n",
        ". Run two aggregations and observe behavior\n",
        "\n",
        ". Use explain(True) to inspect the plan"
      ],
      "metadata": {
        "id": "tw60dMRp5YVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "order_df.cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQvNXU8W5K6d",
        "outputId": "b9b11bf0-10ad-4eea-853b-32dd52493b89"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[order_id: string, city: string, product: string, amount: int, order_date: date, status: string]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "order_df.groupBy(\"city\").sum(\"amount\").show()\n",
        "order_df.groupBy(\"product\").avg(\"amount\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vguTrQOu5kDX",
        "outputId": "1b4760d0-5a38-4ba5-97d5-3f8e43a1b2b5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+\n",
            "|     city|sum(amount)|\n",
            "+---------+-----------+\n",
            "|   Mumbai|      87000|\n",
            "|Bangalore|      58000|\n",
            "|    Delhi|      92000|\n",
            "|  Chennai|          0|\n",
            "+---------+-----------+\n",
            "\n",
            "+-------+-----------+\n",
            "|product|avg(amount)|\n",
            "+-------+-----------+\n",
            "| Laptop|    49000.0|\n",
            "| Mobile|    20000.0|\n",
            "| Tablet|    15000.0|\n",
            "+-------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "order_df.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjtvIF0l5pdv",
        "outputId": "1a2c8522-bca0-4ffa-f5cd-772d36000ae5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Filter '`=`('status, Completed)\n",
            "+- Deduplicate [city#63, order_id#31, amount#61, product#62, order_date#60, status#36]\n",
            "   +- Project [order_id#31, trim(city#32, None) AS city#63, product#62, amount#61, order_date#60, status#36]\n",
            "      +- Project [order_id#31, city#32, trim(product#33, None) AS product#62, amount#61, order_date#60, status#36]\n",
            "         +- Project [order_id#31, city#32, product#33, CASE WHEN ((regexp_extract(amount#34, (\\d+), 0) = ) OR isnull(regexp_extract(amount#34, (\\d+), 0))) THEN 0 ELSE cast(regexp_extract(amount#34, (\\d+), 0) as int) END AS amount#61, order_date#60, status#36]\n",
            "            +- Project [order_id#31, city#32, product#33, amount#34, coalesce(to_date(try_to_timestamp(order_date#35, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(order_date#35, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(order_date#35, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true)) AS order_date#60, status#36]\n",
            "               +- LogicalRDD [order_id#31, city#32, product#33, amount#34, order_date#35, status#36], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "order_id: string, city: string, product: string, amount: int, order_date: date, status: string\n",
            "Filter (status#36 = Completed)\n",
            "+- Deduplicate [city#63, order_id#31, amount#61, product#62, order_date#60, status#36]\n",
            "   +- Project [order_id#31, trim(city#32, None) AS city#63, product#62, amount#61, order_date#60, status#36]\n",
            "      +- Project [order_id#31, city#32, trim(product#33, None) AS product#62, amount#61, order_date#60, status#36]\n",
            "         +- Project [order_id#31, city#32, product#33, CASE WHEN ((regexp_extract(amount#34, (\\d+), 0) = ) OR isnull(regexp_extract(amount#34, (\\d+), 0))) THEN 0 ELSE cast(regexp_extract(amount#34, (\\d+), 0) as int) END AS amount#61, order_date#60, status#36]\n",
            "            +- Project [order_id#31, city#32, product#33, amount#34, coalesce(to_date(try_to_timestamp(order_date#35, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(order_date#35, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(order_date#35, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true)) AS order_date#60, status#36]\n",
            "               +- LogicalRDD [order_id#31, city#32, product#33, amount#34, order_date#35, status#36], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "InMemoryRelation [order_id#31, city#63, product#62, amount#61, order_date#60, status#36], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "   +- AdaptiveSparkPlan isFinalPlan=true\n",
            "      +- == Final Plan ==\n",
            "         ResultQueryStage 1\n",
            "         +- *(2) HashAggregate(keys=[city#63, order_id#31, amount#61, product#62, order_date#60, status#36], functions=[], output=[order_id#31, city#63, product#62, amount#61, order_date#60, status#36])\n",
            "            +- ShuffleQueryStage 0\n",
            "               +- Exchange hashpartitioning(city#63, order_id#31, amount#61, product#62, order_date#60, status#36, 200), ENSURE_REQUIREMENTS, [plan_id=994]\n",
            "                  +- *(1) HashAggregate(keys=[city#63, order_id#31, amount#61, product#62, order_date#60, status#36], functions=[], output=[city#63, order_id#31, amount#61, product#62, order_date#60, status#36])\n",
            "                     +- *(1) Project [order_id#31, trim(city#32, None) AS city#63, trim(product#33, None) AS product#62, CASE WHEN ((regexp_extract(amount#34, (\\d+), 0) = ) OR isnull(regexp_extract(amount#34, (\\d+), 0))) THEN 0 ELSE cast(regexp_extract(amount#34, (\\d+), 0) as int) END AS amount#61, coalesce(cast(gettimestamp(order_date#35, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#35, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#35, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date#60, status#36]\n",
            "                        +- *(1) Filter (isnotnull(status#36) AND (status#36 = Completed))\n",
            "                           +- *(1) Scan ExistingRDD[order_id#31,city#32,product#33,amount#34,order_date#35,status#36]\n",
            "      +- == Initial Plan ==\n",
            "         HashAggregate(keys=[city#63, order_id#31, amount#61, product#62, order_date#60, status#36], functions=[], output=[order_id#31, city#63, product#62, amount#61, order_date#60, status#36])\n",
            "         +- Exchange hashpartitioning(city#63, order_id#31, amount#61, product#62, order_date#60, status#36, 200), ENSURE_REQUIREMENTS, [plan_id=954]\n",
            "            +- HashAggregate(keys=[city#63, order_id#31, amount#61, product#62, order_date#60, status#36], functions=[], output=[city#63, order_id#31, amount#61, product#62, order_date#60, status#36])\n",
            "               +- Project [order_id#31, trim(city#32, None) AS city#63, trim(product#33, None) AS product#62, CASE WHEN ((regexp_extract(amount#34, (\\d+), 0) = ) OR isnull(regexp_extract(amount#34, (\\d+), 0))) THEN 0 ELSE cast(regexp_extract(amount#34, (\\d+), 0) as int) END AS amount#61, coalesce(cast(gettimestamp(order_date#35, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#35, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#35, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date#60, status#36]\n",
            "                  +- Filter (isnotnull(status#36) AND (status#36 = Completed))\n",
            "                     +- Scan ExistingRDD[order_id#31,city#32,product#33,amount#34,order_date#35,status#36]\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- InMemoryTableScan [order_id#31, city#63, product#62, amount#61, order_date#60, status#36]\n",
            "      +- InMemoryRelation [order_id#31, city#63, product#62, amount#61, order_date#60, status#36], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "            +- AdaptiveSparkPlan isFinalPlan=true\n",
            "               +- == Final Plan ==\n",
            "                  ResultQueryStage 1\n",
            "                  +- *(2) HashAggregate(keys=[city#63, order_id#31, amount#61, product#62, order_date#60, status#36], functions=[], output=[order_id#31, city#63, product#62, amount#61, order_date#60, status#36])\n",
            "                     +- ShuffleQueryStage 0\n",
            "                        +- Exchange hashpartitioning(city#63, order_id#31, amount#61, product#62, order_date#60, status#36, 200), ENSURE_REQUIREMENTS, [plan_id=994]\n",
            "                           +- *(1) HashAggregate(keys=[city#63, order_id#31, amount#61, product#62, order_date#60, status#36], functions=[], output=[city#63, order_id#31, amount#61, product#62, order_date#60, status#36])\n",
            "                              +- *(1) Project [order_id#31, trim(city#32, None) AS city#63, trim(product#33, None) AS product#62, CASE WHEN ((regexp_extract(amount#34, (\\d+), 0) = ) OR isnull(regexp_extract(amount#34, (\\d+), 0))) THEN 0 ELSE cast(regexp_extract(amount#34, (\\d+), 0) as int) END AS amount#61, coalesce(cast(gettimestamp(order_date#35, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#35, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#35, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date#60, status#36]\n",
            "                                 +- *(1) Filter (isnotnull(status#36) AND (status#36 = Completed))\n",
            "                                    +- *(1) Scan ExistingRDD[order_id#31,city#32,product#33,amount#34,order_date#35,status#36]\n",
            "               +- == Initial Plan ==\n",
            "                  HashAggregate(keys=[city#63, order_id#31, amount#61, product#62, order_date#60, status#36], functions=[], output=[order_id#31, city#63, product#62, amount#61, order_date#60, status#36])\n",
            "                  +- Exchange hashpartitioning(city#63, order_id#31, amount#61, product#62, order_date#60, status#36, 200), ENSURE_REQUIREMENTS, [plan_id=954]\n",
            "                     +- HashAggregate(keys=[city#63, order_id#31, amount#61, product#62, order_date#60, status#36], functions=[], output=[city#63, order_id#31, amount#61, product#62, order_date#60, status#36])\n",
            "                        +- Project [order_id#31, trim(city#32, None) AS city#63, trim(product#33, None) AS product#62, CASE WHEN ((regexp_extract(amount#34, (\\d+), 0) = ) OR isnull(regexp_extract(amount#34, (\\d+), 0))) THEN 0 ELSE cast(regexp_extract(amount#34, (\\d+), 0) as int) END AS amount#61, coalesce(cast(gettimestamp(order_date#35, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#35, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#35, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date#60, status#36]\n",
            "                           +- Filter (isnotnull(status#36) AND (status#36 = Completed))\n",
            "                              +- Scan ExistingRDD[order_id#31,city#32,product#33,amount#34,order_date#35,status#36]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x8swR49O6Crg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}