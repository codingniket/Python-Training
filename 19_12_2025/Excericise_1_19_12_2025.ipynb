{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHm1AQ84DvMqBWJYNnVy23",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codingniket/Python-Training/blob/main/19_12_2025/Excericise_1_19_12_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REAL-TIME CASE STUDY"
      ],
      "metadata": {
        "id": "oxJjZegW6bKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, lit, when,regexp_replace, split, trim, array_compact, transform, get_json_object\n",
        "spark = SparkSession.builder.appName(\"Excercise1\").getOrCreate()"
      ],
      "metadata": {
        "id": "x2t2_pyc6whi"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YL2rGhRy5nxg"
      },
      "outputs": [],
      "source": [
        "user_data = [\n",
        "(\"U001\",\"Amit\",\"28\",\"Hyderabad\",\"AI,ML,Cloud\"),\n",
        "(\"U002\",\"Neha\",\"Thirty\",\"Delhi\",\"Testing\"),\n",
        "(\"U003\",\"Ravi\",None,\"Bangalore\",[\"Data\",\"Spark\"]),\n",
        "(\"U004\",\"Pooja\",\"29\",\"Mumbai\",\"AI|ML\"),\n",
        "(\"U005\",\"\", \"31\",\"Chennai\",None)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import (StructType, StructField, StringType,LongType,IntegerType,ArrayType,MapType)"
      ],
      "metadata": {
        "id": "1ujOvzlB7dmI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_schema = StructType([\n",
        "    StructField(\"user_id\", StringType(), nullable=False),\n",
        "    StructField(\"name\", StringType(), nullable=True),\n",
        "    StructField(\"age\", StringType(), nullable=True),\n",
        "    StructField(\"city\", StringType(), nullable=True),\n",
        "    StructField(\"skills\", StringType(), nullable=True)\n",
        "])\n",
        "\n",
        "df_data = spark.createDataFrame(user_data, user_schema)\n",
        "df_data.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhQppC__7Q0m",
        "outputId": "5d85e25c-7ed4-48f4-addb-7facbb6940a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+------+---------+-------------+\n",
            "|user_id|name |age   |city     |skills       |\n",
            "+-------+-----+------+---------+-------------+\n",
            "|U001   |Amit |28    |Hyderabad|AI,ML,Cloud  |\n",
            "|U002   |Neha |Thirty|Delhi    |Testing      |\n",
            "|U003   |Ravi |NULL  |Bangalore|[Data, Spark]|\n",
            "|U004   |Pooja|29    |Mumbai   |AI|ML        |\n",
            "|U005   |     |31    |Chennai  |NULL         |\n",
            "+-------+-----+------+---------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_df = df_data.withColumn(\"age\", when(col(\"age\") == \"\", None)\n",
        "    .when(col(\"age\").rlike(r\"^\\d+$\"),\n",
        "          col(\"age\").cast(IntegerType()))\n",
        "    .otherwise(None))\n",
        "\n"
      ],
      "metadata": {
        "id": "vvKtWwk_71Yi"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_data = clean_df.withColumn(\n",
        "    \"skills\",\n",
        "    (when(\n",
        "        col(\"skills\").isNull(),\n",
        "        None\n",
        "    ).otherwise(\n",
        "        array_compact(\n",
        "            transform(\n",
        "                split(\n",
        "                    regexp_replace(\n",
        "                        regexp_replace(col(\"skills\"), r\"\\[|\\]\", \"\"),\n",
        "                        r\"'|\\|\", \",\"),\n",
        "                    \",\"),lambda x: trim(x)\n",
        "            )\n",
        "        )\n",
        "    )).cast(ArrayType(StringType()))\n",
        ")\n",
        "\n",
        "clean_data.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGu15gFkIB2t",
        "outputId": "4f3fcf0d-5d57-4d11-9559-2f157dbe7bb8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+----+---------+---------------+\n",
            "|user_id|name |age |city     |skills         |\n",
            "+-------+-----+----+---------+---------------+\n",
            "|U001   |Amit |28  |Hyderabad|[AI, ML, Cloud]|\n",
            "|U002   |Neha |NULL|Delhi    |[Testing]      |\n",
            "|U003   |Ravi |NULL|Bangalore|[Data, Spark]  |\n",
            "|U004   |Pooja|29  |Mumbai   |[AI, ML]       |\n",
            "|U005   |     |31  |Chennai  |NULL           |\n",
            "+-------+-----+----+---------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users_df=clean_data"
      ],
      "metadata": {
        "id": "NYn-vrIZIQ0W"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "courses_data = [\n",
        "(\"C001\",\"PySpark Mastery\",\"Data Engineering\",\"Advanced\",\"₹9999\"),\n",
        "(\"C002\",\"AI for Testers\",\"QA\",\"Beginner\",\"8999\"),\n",
        "(\"C003\",\"ML Foundations\",\"AI\",\"Intermediate\",None),\n",
        "(\"C004\",\"Data Engineering Bootcamp\",\"Data\",\"Advanced\",\"₹14999\")\n",
        "]"
      ],
      "metadata": {
        "id": "Hah_5Qn99ur5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "course_schema = StructType([\n",
        "    StructField(\"course_id\", StringType(), nullable=False),\n",
        "    StructField(\"course_name\", StringType(), nullable=True),\n",
        "    StructField(\"skills\", StringType(), nullable=True),\n",
        "     StructField(\"level\", StringType(), nullable=True),\n",
        "    StructField(\"amount\", StringType(), nullable=True),\n",
        "])\n",
        "\n",
        "df_course = spark.createDataFrame(courses_data, course_schema)\n",
        "df_course.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tODJPsJ69w2s",
        "outputId": "b49a184f-e08b-44cb-d1fd-509ec9098d9e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------------------+----------------+------------+------+\n",
            "|course_id|course_name              |skills          |level       |amount|\n",
            "+---------+-------------------------+----------------+------------+------+\n",
            "|C001     |PySpark Mastery          |Data Engineering|Advanced    |₹9999 |\n",
            "|C002     |AI for Testers           |QA              |Beginner    |8999  |\n",
            "|C003     |ML Foundations           |AI              |Intermediate|NULL  |\n",
            "|C004     |Data Engineering Bootcamp|Data            |Advanced    |₹14999|\n",
            "+---------+-------------------------+----------------+------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "course_clean_data = df_course.withColumn(\n",
        "    \"amount\",\n",
        "    when(col(\"amount\").isNull() , 0 ).otherwise(regexp_replace(col(\"amount\"), \"₹\", \"\"))\n",
        "    .cast('int')\n",
        ")\n",
        "course_clean_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCN1a6Xt-dV_",
        "outputId": "6f5da8aa-8fa8-4dfc-9581-8b4db9fc2b81"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------------+----------------+------------+------+\n",
            "|course_id|         course_name|          skills|       level|amount|\n",
            "+---------+--------------------+----------------+------------+------+\n",
            "|     C001|     PySpark Mastery|Data Engineering|    Advanced|  9999|\n",
            "|     C002|      AI for Testers|              QA|    Beginner|  8999|\n",
            "|     C003|      ML Foundations|              AI|Intermediate|     0|\n",
            "|     C004|Data Engineering ...|            Data|    Advanced| 14999|\n",
            "+---------+--------------------+----------------+------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "courses_df=course_clean_data"
      ],
      "metadata": {
        "id": "ImVXCcATJX_J"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_enrollment_data = [\n",
        "(\"U001\",\"C001\",\"2024-01-05\"),\n",
        "(\"U002\",\"C002\",\"05/01/2024\"),\n",
        "(\"U003\",\"C001\",\"2024/01/06\"),\n",
        "(\"U004\",\"C003\",\"invalid_date\"),\n",
        "(\"U001\",\"C004\",\"2024-01-10\"),\n",
        "(\"U005\",\"C002\",\"2024-01-12\")\n",
        "]"
      ],
      "metadata": {
        "id": "MJaXP6A6-rfn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enrollment_schema = StructType([\n",
        "    StructField(\"user_id\", StringType(), nullable=False),\n",
        "    StructField(\"course_id\", StringType(), nullable=False),\n",
        "    StructField(\"enrollment_date\", StringType(), nullable=True),\n",
        "])\n",
        "\n",
        "df_enrollment = spark.createDataFrame(user_enrollment_data, enrollment_schema)\n",
        "df_enrollment.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUOlyZb5_Ed1",
        "outputId": "45ec3ae4-3810-4d0f-e6e3-0e3bd5b3091b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+---------------+\n",
            "|user_id|course_id|enrollment_date|\n",
            "+-------+---------+---------------+\n",
            "|U001   |C001     |2024-01-05     |\n",
            "|U002   |C002     |05/01/2024     |\n",
            "|U003   |C001     |2024/01/06     |\n",
            "|U004   |C003     |invalid_date   |\n",
            "|U001   |C004     |2024-01-10     |\n",
            "|U005   |C002     |2024-01-12     |\n",
            "+-------+---------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import coalesce, try_to_timestamp,array\n",
        "from pyspark.sql.types import DateType\n",
        "\n",
        "df_enrollment_clean = df_enrollment.withColumn(\n",
        "    \"enrollment_date\",\n",
        "    coalesce(\n",
        "        try_to_timestamp(col(\"enrollment_date\"), lit(\"yyyy-MM-dd\")).cast(DateType()),\n",
        "        try_to_timestamp(col(\"enrollment_date\"), lit(\"dd/MM/yyyy\")).cast(DateType()),\n",
        "        try_to_timestamp(col(\"enrollment_date\"), lit(\"yyyy/MM/dd\")).cast(DateType())\n",
        "    )\n",
        ")\n",
        "\n",
        "df_enrollment_clean.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRBB_IAG_QHr",
        "outputId": "2adb47b9-b34d-4be7-ff17-13d685de6e90"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+---------------+\n",
            "|user_id|course_id|enrollment_date|\n",
            "+-------+---------+---------------+\n",
            "|U001   |C001     |2024-01-05     |\n",
            "|U002   |C002     |2024-01-05     |\n",
            "|U003   |C001     |2024-01-06     |\n",
            "|U004   |C003     |NULL           |\n",
            "|U001   |C004     |2024-01-10     |\n",
            "|U005   |C002     |2024-01-12     |\n",
            "+-------+---------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enrollments_df=df_enrollment_clean"
      ],
      "metadata": {
        "id": "y-OW3pQ-JizB"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_activity_log = [\n",
        "(\"U001\",\"login,watch,logout\",\"{'device':'mobile'}\",120),\n",
        "(\"U002\",[\"login\",\"watch\"],\"device=laptop\",90),\n",
        "(\"U003\",\"login|logout\",None,30),\n",
        "(\"U004\",None,\"{'device':'tablet'}\",60),\n",
        "(\"U005\",\"login\",\"{'device':'mobile'}\",15)\n",
        "]"
      ],
      "metadata": {
        "id": "EVNi3uyc_2Qi"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_activity_schema = StructType([\n",
        "    StructField(\"user_id\", StringType(), nullable=False),\n",
        "    StructField(\"activity_log\", StringType(), nullable=True),\n",
        "    StructField(\"device_info\", StringType(), nullable=True),\n",
        "    StructField(\"time\",IntegerType(), nullable=True)\n",
        "])\n",
        "\n",
        "df_activity = spark.createDataFrame(user_activity_log, user_activity_schema)\n",
        "df_activity.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cAw870EAekR",
        "outputId": "b4428cd8-ed92-4ca7-f789-7f02ba7c5ac7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-------------------+----+\n",
            "|user_id|activity_log      |device_info        |time|\n",
            "+-------+------------------+-------------------+----+\n",
            "|U001   |login,watch,logout|{'device':'mobile'}|120 |\n",
            "|U002   |[login, watch]    |device=laptop      |90  |\n",
            "|U003   |login|logout      |NULL               |30  |\n",
            "|U004   |NULL              |{'device':'tablet'}|60  |\n",
            "|U005   |login             |{'device':'mobile'}|15  |\n",
            "+-------+------------------+-------------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_activity_clean = df_activity.withColumn(\n",
        "    \"activity_log\",\n",
        "    (when(\n",
        "        col(\"activity_log\").isNull(),\n",
        "        None\n",
        "    ).otherwise(\n",
        "        array_compact(\n",
        "            transform(\n",
        "                split(\n",
        "                    regexp_replace(\n",
        "                        regexp_replace(col(\"activity_log\"), r\"\\[|\\]\", \"\"),\n",
        "                        r\"'|\\|\", \",\"),\n",
        "                    \",\"),lambda x: trim(x)\n",
        "            )\n",
        "        )\n",
        "    )).cast(ArrayType(StringType()))\n",
        ").withColumn(\n",
        "    \"device_info\",\n",
        "    when(col(\"device_info\").isNull(), None)\n",
        "    .when(col(\"device_info\").like(\"{'device':%}\"), get_json_object(col(\"device_info\"), \"$.device\"))\n",
        "    .when(col(\"device_info\").like(\"device=%\"), split(col(\"device_info\"), \"=\").getItem(1))\n",
        "    .otherwise(None)\n",
        ")\n",
        "\n",
        "df_activity_clean.show(truncate=False)\n",
        "df_activity_clean.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAMUzaRrBJRp",
        "outputId": "ed753be3-49c3-44b6-8c9c-6a92d525cbf6"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------------------+-----------+----+\n",
            "|user_id|activity_log          |device_info|time|\n",
            "+-------+----------------------+-----------+----+\n",
            "|U001   |[login, watch, logout]|mobile     |120 |\n",
            "|U002   |[login, watch]        |laptop     |90  |\n",
            "|U003   |[login, logout]       |NULL       |30  |\n",
            "|U004   |NULL                  |tablet     |60  |\n",
            "|U005   |[login]               |mobile     |15  |\n",
            "+-------+----------------------+-----------+----+\n",
            "\n",
            "root\n",
            " |-- user_id: string (nullable = false)\n",
            " |-- activity_log: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- device_info: string (nullable = true)\n",
            " |-- time: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "activity_df = df_activity_clean"
      ],
      "metadata": {
        "id": "-Qdq-ZcRQDXX"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART A — DATA CLEANING & STRUCTURING\n",
        "\n",
        "1. Design explicit schemas for all datasets\n",
        "2. Normalize data types (age, price, dates)\n",
        "3. Convert skills and actions into arrays\n",
        "4. Handle missing and invalid records gracefully\n",
        "5. Produce clean DataFrames:\n",
        "users_df\n",
        "courses_df\n",
        "enrollments_df\n",
        "activity_df"
      ],
      "metadata": {
        "id": "3xw9B_jybGp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI06_eLvMUa5",
        "outputId": "5f69ecb0-3c18-4bec-ce2d-8a864ecef602"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+----+---------+---------------+\n",
            "|user_id| name| age|     city|         skills|\n",
            "+-------+-----+----+---------+---------------+\n",
            "|   U001| Amit|  28|Hyderabad|[AI, ML, Cloud]|\n",
            "|   U002| Neha|NULL|    Delhi|      [Testing]|\n",
            "|   U003| Ravi|NULL|Bangalore|  [Data, Spark]|\n",
            "|   U004|Pooja|  29|   Mumbai|       [AI, ML]|\n",
            "|   U005|     |  31|  Chennai|           NULL|\n",
            "+-------+-----+----+---------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "courses_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgnfPXISP5qd",
        "outputId": "c4eb54c0-b59a-4a54-ff04-eca8fb2ab934"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------------+----------------+------------+------+\n",
            "|course_id|         course_name|          skills|       level|amount|\n",
            "+---------+--------------------+----------------+------------+------+\n",
            "|     C001|     PySpark Mastery|Data Engineering|    Advanced|  9999|\n",
            "|     C002|      AI for Testers|              QA|    Beginner|  8999|\n",
            "|     C003|      ML Foundations|              AI|Intermediate|     0|\n",
            "|     C004|Data Engineering ...|            Data|    Advanced| 14999|\n",
            "+---------+--------------------+----------------+------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enrollments_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lBlGGzXP8Y6",
        "outputId": "b3763336-af15-4935-a72a-1ceaa7efd594"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+---------------+\n",
            "|user_id|course_id|enrollment_date|\n",
            "+-------+---------+---------------+\n",
            "|   U001|     C001|     2024-01-05|\n",
            "|   U002|     C002|     2024-01-05|\n",
            "|   U003|     C001|     2024-01-06|\n",
            "|   U004|     C003|           NULL|\n",
            "|   U001|     C004|     2024-01-10|\n",
            "|   U005|     C002|     2024-01-12|\n",
            "+-------+---------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "activity_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Quc21InP_Dy",
        "outputId": "b5b03fef-9f5e-4cd9-d2c4-bbf0d81ecb35"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+-----------+----+\n",
            "|user_id|        activity_log|device_info|time|\n",
            "+-------+--------------------+-----------+----+\n",
            "|   U001|[login, watch, lo...|     mobile| 120|\n",
            "|   U002|      [login, watch]|     laptop|  90|\n",
            "|   U003|     [login, logout]|       NULL|  30|\n",
            "|   U004|                NULL|     tablet|  60|\n",
            "|   U005|             [login]|     mobile|  15|\n",
            "+-------+--------------------+-----------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART B — DATA INTEGRATION (JOINS)\n",
        "\n",
        "6. Join users with enrollments\n",
        "7. Join enrollments with courses\n",
        "8. Decide which table(s) should be broadcast\n",
        "9. Justify your decision using explain(True)\n",
        "10. Eliminate orphan records"
      ],
      "metadata": {
        "id": "gko-krCFbaF_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0c497d1",
        "outputId": "54b999ee-fc5b-48a2-9c54-d62a6e6927ab"
      },
      "source": [
        "users_enrollments_df = users_df.join(enrollments_df, \"user_id\", \"inner\")\n",
        "users_enrollments_df.show(truncate=False)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+----+---------+---------------+---------+---------------+\n",
            "|user_id|name |age |city     |skills         |course_id|enrollment_date|\n",
            "+-------+-----+----+---------+---------------+---------+---------------+\n",
            "|U001   |Amit |28  |Hyderabad|[AI, ML, Cloud]|C001     |2024-01-05     |\n",
            "|U001   |Amit |28  |Hyderabad|[AI, ML, Cloud]|C004     |2024-01-10     |\n",
            "|U002   |Neha |NULL|Delhi    |[Testing]      |C002     |2024-01-05     |\n",
            "|U003   |Ravi |NULL|Bangalore|[Data, Spark]  |C001     |2024-01-06     |\n",
            "|U004   |Pooja|29  |Mumbai   |[AI, ML]       |C003     |NULL           |\n",
            "|U005   |     |31  |Chennai  |NULL           |C002     |2024-01-12     |\n",
            "+-------+-----+----+---------+---------------+---------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "407bd6c1",
        "outputId": "9c1f94a3-967f-4243-ba39-3fc12459329d"
      },
      "source": [
        "from pyspark.sql.functions import broadcast\n",
        "\n",
        "final_df = users_enrollments_df.join(broadcast(courses_df), \"course_id\", \"inner\")\n",
        "final_df.show(truncate=False)\n",
        "final_df.explain(True)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+-----+----+---------+---------------+---------------+-------------------------+----------------+------------+------+\n",
            "|course_id|user_id|name |age |city     |skills         |enrollment_date|course_name              |skills          |level       |amount|\n",
            "+---------+-------+-----+----+---------+---------------+---------------+-------------------------+----------------+------------+------+\n",
            "|C001     |U001   |Amit |28  |Hyderabad|[AI, ML, Cloud]|2024-01-05     |PySpark Mastery          |Data Engineering|Advanced    |9999  |\n",
            "|C004     |U001   |Amit |28  |Hyderabad|[AI, ML, Cloud]|2024-01-10     |Data Engineering Bootcamp|Data            |Advanced    |14999 |\n",
            "|C002     |U002   |Neha |NULL|Delhi    |[Testing]      |2024-01-05     |AI for Testers           |QA              |Beginner    |8999  |\n",
            "|C001     |U003   |Ravi |NULL|Bangalore|[Data, Spark]  |2024-01-06     |PySpark Mastery          |Data Engineering|Advanced    |9999  |\n",
            "|C003     |U004   |Pooja|29  |Mumbai   |[AI, ML]       |NULL           |ML Foundations           |AI              |Intermediate|0     |\n",
            "|C002     |U005   |     |31  |Chennai  |NULL           |2024-01-12     |AI for Testers           |QA              |Beginner    |8999  |\n",
            "+---------+-------+-----+----+---------+---------------+---------------+-------------------------+----------------+------------+------+\n",
            "\n",
            "== Parsed Logical Plan ==\n",
            "'Join UsingJoin(Inner, [course_id])\n",
            ":- Project [user_id#0, name#1, age#343, city#3, skills#344, course_id#99, enrollment_date#147]\n",
            ":  +- Join Inner, (user_id#0 = user_id#98)\n",
            ":     :- Project [user_id#0, name#1, age#343, city#3, cast(CASE WHEN isnull(skills#4) THEN cast(null as array<string>) ELSE array_compact(transform(split(regexp_replace(regexp_replace(skills#4, \\[|\\], , 1), '|\\|, ,, 1), ,, -1), lambdafunction(trim(lambda x_8#345, None), lambda x_8#345, false))) END as array<string>) AS skills#344]\n",
            ":     :  +- Project [user_id#0, name#1, CASE WHEN (age#2 = ) THEN cast(null as int) WHEN RLIKE(age#2, ^\\d+$) THEN cast(age#2 as int) ELSE cast(null as int) END AS age#343, city#3, skills#4]\n",
            ":     :     +- LogicalRDD [user_id#0, name#1, age#2, city#3, skills#4], false\n",
            ":     +- Project [user_id#98, course_id#99, coalesce(cast(try_to_timestamp(enrollment_date#100, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(enrollment_date#100, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(enrollment_date#100, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date)) AS enrollment_date#147]\n",
            ":        +- LogicalRDD [user_id#98, course_id#99, enrollment_date#100], false\n",
            "+- ResolvedHint (strategy=broadcast)\n",
            "   +- Project [course_id#59, course_name#60, skills#61, level#62, cast(CASE WHEN isnull(amount#63) THEN cast(0 as bigint) ELSE cast(regexp_replace(amount#63, ₹, , 1) as bigint) END as int) AS amount#81]\n",
            "      +- LogicalRDD [course_id#59, course_name#60, skills#61, level#62, amount#63], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "course_id: string, user_id: string, name: string, age: int, city: string, skills: array<string>, enrollment_date: date, course_name: string, skills: string, level: string, amount: int\n",
            "Project [course_id#99, user_id#0, name#1, age#343, city#3, skills#344, enrollment_date#147, course_name#60, skills#61, level#62, amount#81]\n",
            "+- Join Inner, (course_id#99 = course_id#59)\n",
            "   :- Project [user_id#0, name#1, age#343, city#3, skills#344, course_id#99, enrollment_date#147]\n",
            "   :  +- Join Inner, (user_id#0 = user_id#98)\n",
            "   :     :- Project [user_id#0, name#1, age#343, city#3, cast(CASE WHEN isnull(skills#4) THEN cast(null as array<string>) ELSE array_compact(transform(split(regexp_replace(regexp_replace(skills#4, \\[|\\], , 1), '|\\|, ,, 1), ,, -1), lambdafunction(trim(lambda x_8#345, None), lambda x_8#345, false))) END as array<string>) AS skills#344]\n",
            "   :     :  +- Project [user_id#0, name#1, CASE WHEN (age#2 = ) THEN cast(null as int) WHEN RLIKE(age#2, ^\\d+$) THEN cast(age#2 as int) ELSE cast(null as int) END AS age#343, city#3, skills#4]\n",
            "   :     :     +- LogicalRDD [user_id#0, name#1, age#2, city#3, skills#4], false\n",
            "   :     +- Project [user_id#98, course_id#99, coalesce(cast(try_to_timestamp(enrollment_date#100, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(enrollment_date#100, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(enrollment_date#100, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date)) AS enrollment_date#147]\n",
            "   :        +- LogicalRDD [user_id#98, course_id#99, enrollment_date#100], false\n",
            "   +- ResolvedHint (strategy=broadcast)\n",
            "      +- Project [course_id#59, course_name#60, skills#61, level#62, cast(CASE WHEN isnull(amount#63) THEN cast(0 as bigint) ELSE cast(regexp_replace(amount#63, ₹, , 1) as bigint) END as int) AS amount#81]\n",
            "         +- LogicalRDD [course_id#59, course_name#60, skills#61, level#62, amount#63], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [course_id#99, user_id#0, name#1, age#343, city#3, skills#344, enrollment_date#147, course_name#60, skills#61, level#62, amount#81]\n",
            "+- Join Inner, (course_id#99 = course_id#59), rightHint=(strategy=broadcast)\n",
            "   :- Project [user_id#0, name#1, age#343, city#3, skills#344, course_id#99, enrollment_date#147]\n",
            "   :  +- Join Inner, (user_id#0 = user_id#98)\n",
            "   :     :- Project [user_id#0, name#1, CASE WHEN (age#2 = ) THEN null WHEN RLIKE(age#2, ^\\d+$) THEN cast(age#2 as int) END AS age#343, city#3, CASE WHEN isnull(skills#4) THEN null ELSE knownnotcontainsnull(filter(transform(split(regexp_replace(regexp_replace(skills#4, \\[|\\], , 1), '|\\|, ,, 1), ,, -1), lambdafunction(trim(lambda x_8#345, None), lambda x_8#345, false)), lambdafunction(isnotnull(lambda arg#346), lambda arg#346, false))) END AS skills#344]\n",
            "   :     :  +- LogicalRDD [user_id#0, name#1, age#2, city#3, skills#4], false\n",
            "   :     +- Project [user_id#98, course_id#99, coalesce(cast(gettimestamp(enrollment_date#100, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(enrollment_date#100, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(enrollment_date#100, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS enrollment_date#147]\n",
            "   :        +- LogicalRDD [user_id#98, course_id#99, enrollment_date#100], false\n",
            "   +- Project [course_id#59, course_name#60, skills#61, level#62, CASE WHEN isnull(amount#63) THEN 0 ELSE cast(cast(regexp_replace(amount#63, ₹, , 1) as bigint) as int) END AS amount#81]\n",
            "      +- LogicalRDD [course_id#59, course_name#60, skills#61, level#62, amount#63], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [course_id#99, user_id#0, name#1, age#343, city#3, skills#344, enrollment_date#147, course_name#60, skills#61, level#62, amount#81]\n",
            "   +- BroadcastHashJoin [course_id#99], [course_id#59], Inner, BuildRight, false\n",
            "      :- Project [user_id#0, name#1, age#343, city#3, skills#344, course_id#99, enrollment_date#147]\n",
            "      :  +- SortMergeJoin [user_id#0], [user_id#98], Inner\n",
            "      :     :- Sort [user_id#0 ASC NULLS FIRST], false, 0\n",
            "      :     :  +- Exchange hashpartitioning(user_id#0, 200), ENSURE_REQUIREMENTS, [plan_id=912]\n",
            "      :     :     +- Project [user_id#0, name#1, CASE WHEN (age#2 = ) THEN null WHEN RLIKE(age#2, ^\\d+$) THEN cast(age#2 as int) END AS age#343, city#3, CASE WHEN isnull(skills#4) THEN null ELSE knownnotcontainsnull(filter(transform(split(regexp_replace(regexp_replace(skills#4, \\[|\\], , 1), '|\\|, ,, 1), ,, -1), lambdafunction(trim(lambda x_8#345, None), lambda x_8#345, false)), lambdafunction(isnotnull(lambda arg#346), lambda arg#346, false))) END AS skills#344]\n",
            "      :     :        +- Scan ExistingRDD[user_id#0,name#1,age#2,city#3,skills#4]\n",
            "      :     +- Sort [user_id#98 ASC NULLS FIRST], false, 0\n",
            "      :        +- Exchange hashpartitioning(user_id#98, 200), ENSURE_REQUIREMENTS, [plan_id=913]\n",
            "      :           +- Project [user_id#98, course_id#99, coalesce(cast(gettimestamp(enrollment_date#100, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(enrollment_date#100, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(enrollment_date#100, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS enrollment_date#147]\n",
            "      :              +- Scan ExistingRDD[user_id#98,course_id#99,enrollment_date#100]\n",
            "      +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=919]\n",
            "         +- Project [course_id#59, course_name#60, skills#61, level#62, CASE WHEN isnull(amount#63) THEN 0 ELSE cast(cast(regexp_replace(amount#63, ₹, , 1) as bigint) as int) END AS amount#81]\n",
            "            +- Scan ExistingRDD[course_id#59,course_name#60,skills#61,level#62,amount#63]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa4df10e",
        "outputId": "a49d42a5-5331-4084-c29b-addc802fb463"
      },
      "source": [
        "from pyspark.sql.functions import broadcast\n",
        "\n",
        "users_enrollments_broadcast_df = users_df.join(broadcast(enrollments_df), \"user_id\", \"inner\")\n",
        "users_enrollments_broadcast_df.show(truncate=False)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+----+---------+---------------+---------+---------------+\n",
            "|user_id|name |age |city     |skills         |course_id|enrollment_date|\n",
            "+-------+-----+----+---------+---------------+---------+---------------+\n",
            "|U001   |Amit |28  |Hyderabad|[AI, ML, Cloud]|C004     |2024-01-10     |\n",
            "|U001   |Amit |28  |Hyderabad|[AI, ML, Cloud]|C001     |2024-01-05     |\n",
            "|U002   |Neha |NULL|Delhi    |[Testing]      |C002     |2024-01-05     |\n",
            "|U003   |Ravi |NULL|Bangalore|[Data, Spark]  |C001     |2024-01-06     |\n",
            "|U004   |Pooja|29  |Mumbai   |[AI, ML]       |C003     |NULL           |\n",
            "|U005   |     |31  |Chennai  |NULL           |C002     |2024-01-12     |\n",
            "+-------+-----+----+---------+---------------+---------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00309f66",
        "outputId": "60716ee1-8a6f-497b-f126-9ade72bc1f8d"
      },
      "source": [
        "final_df_with_both_broadcasts = users_enrollments_broadcast_df.join(broadcast(courses_df), \"course_id\", \"inner\")\n",
        "final_df_with_both_broadcasts.show(truncate=False)\n",
        "final_df_with_both_broadcasts.explain(True)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+-----+----+---------+---------------+---------------+-------------------------+----------------+------------+------+\n",
            "|course_id|user_id|name |age |city     |skills         |enrollment_date|course_name              |skills          |level       |amount|\n",
            "+---------+-------+-----+----+---------+---------------+---------------+-------------------------+----------------+------------+------+\n",
            "|C004     |U001   |Amit |28  |Hyderabad|[AI, ML, Cloud]|2024-01-10     |Data Engineering Bootcamp|Data            |Advanced    |14999 |\n",
            "|C001     |U001   |Amit |28  |Hyderabad|[AI, ML, Cloud]|2024-01-05     |PySpark Mastery          |Data Engineering|Advanced    |9999  |\n",
            "|C002     |U002   |Neha |NULL|Delhi    |[Testing]      |2024-01-05     |AI for Testers           |QA              |Beginner    |8999  |\n",
            "|C001     |U003   |Ravi |NULL|Bangalore|[Data, Spark]  |2024-01-06     |PySpark Mastery          |Data Engineering|Advanced    |9999  |\n",
            "|C003     |U004   |Pooja|29  |Mumbai   |[AI, ML]       |NULL           |ML Foundations           |AI              |Intermediate|0     |\n",
            "|C002     |U005   |     |31  |Chennai  |NULL           |2024-01-12     |AI for Testers           |QA              |Beginner    |8999  |\n",
            "+---------+-------+-----+----+---------+---------------+---------------+-------------------------+----------------+------------+------+\n",
            "\n",
            "== Parsed Logical Plan ==\n",
            "'Join UsingJoin(Inner, [course_id])\n",
            ":- Project [user_id#0, name#1, age#343, city#3, skills#344, course_id#99, enrollment_date#147]\n",
            ":  +- Join Inner, (user_id#0 = user_id#98)\n",
            ":     :- Project [user_id#0, name#1, age#343, city#3, cast(CASE WHEN isnull(skills#4) THEN cast(null as array<string>) ELSE array_compact(transform(split(regexp_replace(regexp_replace(skills#4, \\[|\\], , 1), '|\\|, ,, 1), ,, -1), lambdafunction(trim(lambda x_8#345, None), lambda x_8#345, false))) END as array<string>) AS skills#344]\n",
            ":     :  +- Project [user_id#0, name#1, CASE WHEN (age#2 = ) THEN cast(null as int) WHEN RLIKE(age#2, ^\\d+$) THEN cast(age#2 as int) ELSE cast(null as int) END AS age#343, city#3, skills#4]\n",
            ":     :     +- LogicalRDD [user_id#0, name#1, age#2, city#3, skills#4], false\n",
            ":     +- ResolvedHint (strategy=broadcast)\n",
            ":        +- Project [user_id#98, course_id#99, coalesce(cast(try_to_timestamp(enrollment_date#100, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(enrollment_date#100, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(enrollment_date#100, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date)) AS enrollment_date#147]\n",
            ":           +- LogicalRDD [user_id#98, course_id#99, enrollment_date#100], false\n",
            "+- ResolvedHint (strategy=broadcast)\n",
            "   +- Project [course_id#59, course_name#60, skills#61, level#62, cast(CASE WHEN isnull(amount#63) THEN cast(0 as bigint) ELSE cast(regexp_replace(amount#63, ₹, , 1) as bigint) END as int) AS amount#81]\n",
            "      +- LogicalRDD [course_id#59, course_name#60, skills#61, level#62, amount#63], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "course_id: string, user_id: string, name: string, age: int, city: string, skills: array<string>, enrollment_date: date, course_name: string, skills: string, level: string, amount: int\n",
            "Project [course_id#99, user_id#0, name#1, age#343, city#3, skills#344, enrollment_date#147, course_name#60, skills#61, level#62, amount#81]\n",
            "+- Join Inner, (course_id#99 = course_id#59)\n",
            "   :- Project [user_id#0, name#1, age#343, city#3, skills#344, course_id#99, enrollment_date#147]\n",
            "   :  +- Join Inner, (user_id#0 = user_id#98)\n",
            "   :     :- Project [user_id#0, name#1, age#343, city#3, cast(CASE WHEN isnull(skills#4) THEN cast(null as array<string>) ELSE array_compact(transform(split(regexp_replace(regexp_replace(skills#4, \\[|\\], , 1), '|\\|, ,, 1), ,, -1), lambdafunction(trim(lambda x_8#345, None), lambda x_8#345, false))) END as array<string>) AS skills#344]\n",
            "   :     :  +- Project [user_id#0, name#1, CASE WHEN (age#2 = ) THEN cast(null as int) WHEN RLIKE(age#2, ^\\d+$) THEN cast(age#2 as int) ELSE cast(null as int) END AS age#343, city#3, skills#4]\n",
            "   :     :     +- LogicalRDD [user_id#0, name#1, age#2, city#3, skills#4], false\n",
            "   :     +- ResolvedHint (strategy=broadcast)\n",
            "   :        +- Project [user_id#98, course_id#99, coalesce(cast(try_to_timestamp(enrollment_date#100, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(enrollment_date#100, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(enrollment_date#100, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date)) AS enrollment_date#147]\n",
            "   :           +- LogicalRDD [user_id#98, course_id#99, enrollment_date#100], false\n",
            "   +- ResolvedHint (strategy=broadcast)\n",
            "      +- Project [course_id#59, course_name#60, skills#61, level#62, cast(CASE WHEN isnull(amount#63) THEN cast(0 as bigint) ELSE cast(regexp_replace(amount#63, ₹, , 1) as bigint) END as int) AS amount#81]\n",
            "         +- LogicalRDD [course_id#59, course_name#60, skills#61, level#62, amount#63], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [course_id#99, user_id#0, name#1, age#343, city#3, skills#344, enrollment_date#147, course_name#60, skills#61, level#62, amount#81]\n",
            "+- Join Inner, (course_id#99 = course_id#59), rightHint=(strategy=broadcast)\n",
            "   :- Project [user_id#0, name#1, age#343, city#3, skills#344, course_id#99, enrollment_date#147]\n",
            "   :  +- Join Inner, (user_id#0 = user_id#98), rightHint=(strategy=broadcast)\n",
            "   :     :- Project [user_id#0, name#1, CASE WHEN (age#2 = ) THEN null WHEN RLIKE(age#2, ^\\d+$) THEN cast(age#2 as int) END AS age#343, city#3, CASE WHEN isnull(skills#4) THEN null ELSE knownnotcontainsnull(filter(transform(split(regexp_replace(regexp_replace(skills#4, \\[|\\], , 1), '|\\|, ,, 1), ,, -1), lambdafunction(trim(lambda x_8#345, None), lambda x_8#345, false)), lambdafunction(isnotnull(lambda arg#346), lambda arg#346, false))) END AS skills#344]\n",
            "   :     :  +- LogicalRDD [user_id#0, name#1, age#2, city#3, skills#4], false\n",
            "   :     +- Project [user_id#98, course_id#99, coalesce(cast(gettimestamp(enrollment_date#100, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(enrollment_date#100, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(enrollment_date#100, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS enrollment_date#147]\n",
            "   :        +- LogicalRDD [user_id#98, course_id#99, enrollment_date#100], false\n",
            "   +- Project [course_id#59, course_name#60, skills#61, level#62, CASE WHEN isnull(amount#63) THEN 0 ELSE cast(cast(regexp_replace(amount#63, ₹, , 1) as bigint) as int) END AS amount#81]\n",
            "      +- LogicalRDD [course_id#59, course_name#60, skills#61, level#62, amount#63], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [course_id#99, user_id#0, name#1, age#343, city#3, skills#344, enrollment_date#147, course_name#60, skills#61, level#62, amount#81]\n",
            "   +- BroadcastHashJoin [course_id#99], [course_id#59], Inner, BuildRight, false\n",
            "      :- Project [user_id#0, name#1, age#343, city#3, skills#344, course_id#99, enrollment_date#147]\n",
            "      :  +- BroadcastHashJoin [user_id#0], [user_id#98], Inner, BuildRight, false\n",
            "      :     :- Project [user_id#0, name#1, CASE WHEN (age#2 = ) THEN null WHEN RLIKE(age#2, ^\\d+$) THEN cast(age#2 as int) END AS age#343, city#3, CASE WHEN isnull(skills#4) THEN null ELSE knownnotcontainsnull(filter(transform(split(regexp_replace(regexp_replace(skills#4, \\[|\\], , 1), '|\\|, ,, 1), ,, -1), lambdafunction(trim(lambda x_8#345, None), lambda x_8#345, false)), lambdafunction(isnotnull(lambda arg#346), lambda arg#346, false))) END AS skills#344]\n",
            "      :     :  +- Scan ExistingRDD[user_id#0,name#1,age#2,city#3,skills#4]\n",
            "      :     +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=1164]\n",
            "      :        +- Project [user_id#98, course_id#99, coalesce(cast(gettimestamp(enrollment_date#100, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(enrollment_date#100, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(enrollment_date#100, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS enrollment_date#147]\n",
            "      :           +- Scan ExistingRDD[user_id#98,course_id#99,enrollment_date#100]\n",
            "      +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=1168]\n",
            "         +- Project [course_id#59, course_name#60, skills#61, level#62, CASE WHEN isnull(amount#63) THEN 0 ELSE cast(cast(regexp_replace(amount#63, ₹, , 1) as bigint) as int) END AS amount#81]\n",
            "            +- Scan ExistingRDD[course_id#59,course_name#60,skills#61,level#62,amount#63]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART C — ANALYTICS & AGGREGATIONS\n",
        "\n",
        "11. Total enrollments per course\n",
        "12. Total revenue per course\n",
        "13. Average engagement time per course\n",
        "14. Total courses enrolled per user\n",
        "15. Identify users with zero activity"
      ],
      "metadata": {
        "id": "1yWsf2gSbePi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wZnlCWvNVFur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66ce8dac",
        "outputId": "197d11e3-7a42-486c-a9a2-852d68c20391"
      },
      "source": [
        "enrollments_per_course = enrollments_df.groupBy(\"course_id\").count()\n",
        "enrollments_per_course.show()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+\n",
            "|course_id|count|\n",
            "+---------+-----+\n",
            "|     C001|    2|\n",
            "|     C002|    2|\n",
            "|     C003|    1|\n",
            "|     C004|    1|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f020ec48",
        "outputId": "134ea94b-f7e4-4680-dc33-8bad6fc5704b"
      },
      "source": [
        "from pyspark.sql.functions import sum\n",
        "\n",
        "total_revenue_per_course = enrollments_df.join(courses_df, \"course_id\", \"inner\") \\\n",
        "                                         .groupBy(\"course_id\") \\\n",
        "                                         .agg(sum(\"amount\").alias(\"total_revenue\"))\n",
        "\n",
        "total_revenue_per_course.show()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------+\n",
            "|course_id|total_revenue|\n",
            "+---------+-------------+\n",
            "|     C001|        19998|\n",
            "|     C002|        17998|\n",
            "|     C003|            0|\n",
            "|     C004|        14999|\n",
            "+---------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "452d23c9",
        "outputId": "be550de7-4ac3-48bc-a9d7-54f4c1df7b97"
      },
      "source": [
        "from pyspark.sql.functions import avg\n",
        "\n",
        "average_engagement_per_course = enrollments_df.join(activity_df, \"user_id\", \"inner\") \\\n",
        "                                               .groupBy(\"course_id\") \\\n",
        "                                               .agg(avg(\"time\").alias(\"average_engagement_time\"))\n",
        "\n",
        "average_engagement_per_course.show()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------------------+\n",
            "|course_id|average_engagement_time|\n",
            "+---------+-----------------------+\n",
            "|     C003|                   60.0|\n",
            "|     C004|                  120.0|\n",
            "|     C001|                   75.0|\n",
            "|     C002|                   52.5|\n",
            "+---------+-----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6200655",
        "outputId": "654e15eb-6a10-4c76-8a77-9eb06205108c"
      },
      "source": [
        "from pyspark.sql.functions import countDistinct\n",
        "\n",
        "total_courses_per_user = enrollments_df.groupBy(\"user_id\").agg(countDistinct(\"course_id\").alias(\"total_courses_enrolled\"))\n",
        "total_courses_per_user.show()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------------------+\n",
            "|user_id|total_courses_enrolled|\n",
            "+-------+----------------------+\n",
            "|   U004|                     1|\n",
            "|   U005|                     1|\n",
            "|   U002|                     1|\n",
            "|   U003|                     1|\n",
            "|   U001|                     2|\n",
            "+-------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART D — WINDOW FUNCTIONS\n",
        "\n",
        "16. Rank users by total time spent\n",
        "17. Calculate running revenue per course by enrollment date\n",
        "18. Identify top 2 users per course by engagement\n",
        "19. Compare GroupBy vs Window results for at least one metric"
      ],
      "metadata": {
        "id": "ohGuD4dpblvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import row_number, col\n",
        "\n",
        "window_spec = Window.partitionBy(\"user_id\").orderBy(col(\"time\").desc())\n",
        "ranked_df = activity_df.withColumn(\"row_num\", row_number().over(window_spec))\n",
        "ranked_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AbxKZpQV4B6",
        "outputId": "2de6e4ca-6e7b-49da-91a4-c29e17499f95"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+-----------+----+-------+\n",
            "|user_id|        activity_log|device_info|time|row_num|\n",
            "+-------+--------------------+-----------+----+-------+\n",
            "|   U001|[login, watch, lo...|     mobile| 120|      1|\n",
            "|   U002|      [login, watch]|     laptop|  90|      1|\n",
            "|   U003|     [login, logout]|       NULL|  30|      1|\n",
            "|   U004|                NULL|     tablet|  60|      1|\n",
            "|   U005|             [login]|     mobile|  15|      1|\n",
            "+-------+--------------------+-----------+----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import sum\n",
        "\n",
        "enrollments_with_revenue = enrollments_df.join(courses_df, \"course_id\", \"inner\")\n",
        "\n",
        "window_spec_running_revenue = Window.partitionBy(\"course_id\").orderBy(\"enrollment_date\")\n",
        "\n",
        "running_revenue_per_course = enrollments_with_revenue.withColumn(\n",
        "    \"running_revenue\",\n",
        "    sum(\"amount\").over(window_spec_running_revenue)\n",
        ")\n",
        "\n",
        "running_revenue_per_course.orderBy(\"course_id\", \"enrollment_date\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE2i9C96XdQP",
        "outputId": "e483ebc9-e9e1-4889-b765-bd2de773113d"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+---------------+-------------------------+----------------+------------+------+---------------+\n",
            "|course_id|user_id|enrollment_date|course_name              |skills          |level       |amount|running_revenue|\n",
            "+---------+-------+---------------+-------------------------+----------------+------------+------+---------------+\n",
            "|C001     |U001   |2024-01-05     |PySpark Mastery          |Data Engineering|Advanced    |9999  |9999           |\n",
            "|C001     |U003   |2024-01-06     |PySpark Mastery          |Data Engineering|Advanced    |9999  |19998          |\n",
            "|C002     |U002   |2024-01-05     |AI for Testers           |QA              |Beginner    |8999  |8999           |\n",
            "|C002     |U005   |2024-01-12     |AI for Testers           |QA              |Beginner    |8999  |17998          |\n",
            "|C003     |U004   |NULL           |ML Foundations           |AI              |Intermediate|0     |0              |\n",
            "|C004     |U001   |2024-01-10     |Data Engineering Bootcamp|Data            |Advanced    |14999 |14999          |\n",
            "+---------+-------+---------------+-------------------------+----------------+------------+------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "activity_df.orderBy(col(\"time\").desc()).limit(2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zn5fGynHavnG",
        "outputId": "7bf11f26-f660-40c9-8a36-7e28c887120a"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+-----------+----+\n",
            "|user_id|        activity_log|device_info|time|\n",
            "+-------+--------------------+-----------+----+\n",
            "|   U001|[login, watch, lo...|     mobile| 120|\n",
            "|   U002|      [login, watch]|     laptop|  90|\n",
            "+-------+--------------------+-----------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART E — UDF (ONLY IF REQUIRED)\n",
        "\n",
        "20. Classify users into engagement levels:\n",
        "High\n",
        "Medium\n",
        "Low\n",
        "\n",
        "Rules:\n",
        "Use built-in functions where possible\n",
        "Use UDF only if unavoidable\n",
        "Explain why UDF was needed (or avoided)"
      ],
      "metadata": {
        "id": "eFpMEN_YbwDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = activity_df.withColumn(\"grade\",\n",
        "    when(col(\"time\") >= 80, \"High\")\n",
        "    .when(col(\"time\") >= 60, \"Medium\")\n",
        "    .otherwise(\"Low\")\n",
        ")\n",
        "\n",
        "df.orderBy(\"grade\",df.time.desc()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJYU9l5fZGka",
        "outputId": "f924d2af-0cdc-4259-e295-44cc7c7ff9d3"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+-----------+----+------+\n",
            "|user_id|        activity_log|device_info|time| grade|\n",
            "+-------+--------------------+-----------+----+------+\n",
            "|   U001|[login, watch, lo...|     mobile| 120|  High|\n",
            "|   U002|      [login, watch]|     laptop|  90|  High|\n",
            "|   U003|     [login, logout]|       NULL|  30|   Low|\n",
            "|   U005|             [login]|     mobile|  15|   Low|\n",
            "|   U004|                NULL|     tablet|  60|Medium|\n",
            "+-------+--------------------+-----------+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART F — SORTING & ORDERING\n",
        "\n",
        "21. Sort courses by total revenue (descending)\n",
        "22. Sort users by engagement within each city\n",
        "\n",
        "23. Explain why sorting caused a shuffle"
      ],
      "metadata": {
        "id": "dxwMSyt2bytH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import desc\n",
        "\n",
        "total_revenue_per_course.orderBy(desc(\"total_revenue\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pT_s5BkZlJd",
        "outputId": "4b2942f8-55aa-494e-c9d4-b83a298cf2f5"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------+\n",
            "|course_id|total_revenue|\n",
            "+---------+-------------+\n",
            "|     C001|        19998|\n",
            "|     C002|        17998|\n",
            "|     C004|        14999|\n",
            "|     C003|            0|\n",
            "+---------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import desc, sum, rank\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "final_df_with_check = final_df_with_both_broadcasts.join(broadcast(activity_df), \"user_id\", \"inner\")\n",
        "final_df_with_check.show(truncate=False)\n",
        "\n",
        "user_engagement_by_city = final_df_with_check.groupBy(\"city\", \"user_id\").agg(sum(\"time\").alias(\"total_engagement_time\"))\n",
        "\n",
        "window_spec_city_engagement = Window.partitionBy(\"city\").orderBy(desc(\"total_engagement_time\"))\n",
        "\n",
        "ranked_users_by_city_engagement = user_engagement_by_city.withColumn(\"rank_in_city\", rank().over(window_spec_city_engagement))\n",
        "\n",
        "ranked_users_by_city_engagement.orderBy(\"city\", \"rank_in_city\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zegD_fPBb-if",
        "outputId": "83d4294d-753b-4c35-b9f4-5068eb9a22ee"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+-----+----+---------+---------------+---------------+-------------------------+----------------+------------+------+----------------------+-----------+----+\n",
            "|user_id|course_id|name |age |city     |skills         |enrollment_date|course_name              |skills          |level       |amount|activity_log          |device_info|time|\n",
            "+-------+---------+-----+----+---------+---------------+---------------+-------------------------+----------------+------------+------+----------------------+-----------+----+\n",
            "|U001   |C004     |Amit |28  |Hyderabad|[AI, ML, Cloud]|2024-01-10     |Data Engineering Bootcamp|Data            |Advanced    |14999 |[login, watch, logout]|mobile     |120 |\n",
            "|U001   |C001     |Amit |28  |Hyderabad|[AI, ML, Cloud]|2024-01-05     |PySpark Mastery          |Data Engineering|Advanced    |9999  |[login, watch, logout]|mobile     |120 |\n",
            "|U002   |C002     |Neha |NULL|Delhi    |[Testing]      |2024-01-05     |AI for Testers           |QA              |Beginner    |8999  |[login, watch]        |laptop     |90  |\n",
            "|U003   |C001     |Ravi |NULL|Bangalore|[Data, Spark]  |2024-01-06     |PySpark Mastery          |Data Engineering|Advanced    |9999  |[login, logout]       |NULL       |30  |\n",
            "|U004   |C003     |Pooja|29  |Mumbai   |[AI, ML]       |NULL           |ML Foundations           |AI              |Intermediate|0     |NULL                  |tablet     |60  |\n",
            "|U005   |C002     |     |31  |Chennai  |NULL           |2024-01-12     |AI for Testers           |QA              |Beginner    |8999  |[login]               |mobile     |15  |\n",
            "+-------+---------+-----+----+---------+---------------+---------------+-------------------------+----------------+------------+------+----------------------+-----------+----+\n",
            "\n",
            "+---------+-------+---------------------+------------+\n",
            "|city     |user_id|total_engagement_time|rank_in_city|\n",
            "+---------+-------+---------------------+------------+\n",
            "|Bangalore|U003   |30                   |1           |\n",
            "|Chennai  |U005   |15                   |1           |\n",
            "|Delhi    |U002   |90                   |1           |\n",
            "|Hyderabad|U001   |240                  |1           |\n",
            "|Mumbai   |U004   |60                   |1           |\n",
            "+---------+-------+---------------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART G — SET OPERATIONS\n",
        "\n",
        "Create two DataFrames:\n",
        "Users who enrolled\n",
        "Users who completed activity\n",
        "\n",
        "\n",
        "\n",
        "24. Find users who enrolled but never became active\n",
        "25. Find users who are both enrolled and active\n",
        "26. Explain why set operations are different from joins"
      ],
      "metadata": {
        "id": "jR1VyRJQb2xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users_enrolled = enrollments_df.select(\"user_id\").distinct()\n",
        "users_active = activity_df.select(\"user_id\").distinct()\n",
        "\n",
        "users_enrolled_but_inactive = users_enrolled.join(users_active, \"user_id\", \"left_anti\")\n",
        "users_enrolled_but_inactive.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwoOmCnCcAan",
        "outputId": "56b19927-6210-49e9-c169-b7cb215159d1"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|user_id|\n",
            "+-------+\n",
            "+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users_enrolled = enrollments_df.select(\"user_id\").distinct()\n",
        "users_active = activity_df.select(\"user_id\").distinct()\n",
        "\n",
        "users_enrolled_and_active = users_enrolled.join(users_active, \"user_id\", \"inner\")\n",
        "users_enrolled_and_active.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qhlLE3ncAQe",
        "outputId": "a240d479-5c40-425a-9393-bd5a94b51b6f"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+\n",
            "|user_id|\n",
            "+-------+\n",
            "|   U002|\n",
            "|   U003|\n",
            "|   U001|\n",
            "|   U004|\n",
            "|   U005|\n",
            "+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wM7VxjuucAHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART H — DAG & PERFORMANCE ANALYSIS\n",
        "\n",
        "27. For at least three operations, run explain(True)\n",
        "28. Identify:\n",
        "Shuffles\n",
        "Broadcast joins\n",
        "Sort operations\n",
        "29. Suggest one performance improvement"
      ],
      "metadata": {
        "id": "raReITqab8SD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users_df.explain(True)\n",
        "courses_df.explain(True)\n",
        "enrollments_df.explain(True)\n",
        "activity_df.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NIQGL-OaB-i",
        "outputId": "47c88247-d27d-4cdf-b8c6-b835e332ed33"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Project [unresolvedstarwithcolumns(skills, cast(CASE WHEN 'isNull('skills) THEN null ELSE 'array_compact('transform('split('regexp_replace('regexp_replace('skills, \\[|\\], ), '|\\|, ,), ,, -1), lambdafunction('trim(lambda 'x_8), lambda 'x_8, false))) END as array<string>), None)]\n",
            "+- Project [user_id#0, name#1, CASE WHEN (age#2 = ) THEN cast(null as int) WHEN RLIKE(age#2, ^\\d+$) THEN cast(age#2 as int) ELSE cast(null as int) END AS age#343, city#3, skills#4]\n",
            "   +- LogicalRDD [user_id#0, name#1, age#2, city#3, skills#4], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "user_id: string, name: string, age: int, city: string, skills: array<string>\n",
            "Project [user_id#0, name#1, age#343, city#3, cast(CASE WHEN isnull(skills#4) THEN cast(null as array<string>) ELSE array_compact(transform(split(regexp_replace(regexp_replace(skills#4, \\[|\\], , 1), '|\\|, ,, 1), ,, -1), lambdafunction(trim(lambda x_8#345, None), lambda x_8#345, false))) END as array<string>) AS skills#344]\n",
            "+- Project [user_id#0, name#1, CASE WHEN (age#2 = ) THEN cast(null as int) WHEN RLIKE(age#2, ^\\d+$) THEN cast(age#2 as int) ELSE cast(null as int) END AS age#343, city#3, skills#4]\n",
            "   +- LogicalRDD [user_id#0, name#1, age#2, city#3, skills#4], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [user_id#0, name#1, CASE WHEN (age#2 = ) THEN null WHEN RLIKE(age#2, ^\\d+$) THEN cast(age#2 as int) END AS age#343, city#3, CASE WHEN isnull(skills#4) THEN null ELSE knownnotcontainsnull(filter(transform(split(regexp_replace(regexp_replace(skills#4, \\[|\\], , 1), '|\\|, ,, 1), ,, -1), lambdafunction(trim(lambda x_8#345, None), lambda x_8#345, false)), lambdafunction(isnotnull(lambda arg#346), lambda arg#346, false))) END AS skills#344]\n",
            "+- LogicalRDD [user_id#0, name#1, age#2, city#3, skills#4], false\n",
            "\n",
            "== Physical Plan ==\n",
            "Project [user_id#0, name#1, CASE WHEN (age#2 = ) THEN null WHEN RLIKE(age#2, ^\\d+$) THEN cast(age#2 as int) END AS age#343, city#3, CASE WHEN isnull(skills#4) THEN null ELSE knownnotcontainsnull(filter(transform(split(regexp_replace(regexp_replace(skills#4, \\[|\\], , 1), '|\\|, ,, 1), ,, -1), lambdafunction(trim(lambda x_8#345, None), lambda x_8#345, false)), lambdafunction(isnotnull(lambda arg#346), lambda arg#346, false))) END AS skills#344]\n",
            "+- *(1) Scan ExistingRDD[user_id#0,name#1,age#2,city#3,skills#4]\n",
            "\n",
            "== Parsed Logical Plan ==\n",
            "'Project [unresolvedstarwithcolumns(amount, cast(CASE WHEN 'isNull('amount) THEN 0 ELSE 'regexp_replace('amount, ₹, ) END as int), None)]\n",
            "+- LogicalRDD [course_id#59, course_name#60, skills#61, level#62, amount#63], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "course_id: string, course_name: string, skills: string, level: string, amount: int\n",
            "Project [course_id#59, course_name#60, skills#61, level#62, cast(CASE WHEN isnull(amount#63) THEN cast(0 as bigint) ELSE cast(regexp_replace(amount#63, ₹, , 1) as bigint) END as int) AS amount#81]\n",
            "+- LogicalRDD [course_id#59, course_name#60, skills#61, level#62, amount#63], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [course_id#59, course_name#60, skills#61, level#62, CASE WHEN isnull(amount#63) THEN 0 ELSE cast(cast(regexp_replace(amount#63, ₹, , 1) as bigint) as int) END AS amount#81]\n",
            "+- LogicalRDD [course_id#59, course_name#60, skills#61, level#62, amount#63], false\n",
            "\n",
            "== Physical Plan ==\n",
            "*(1) Project [course_id#59, course_name#60, skills#61, level#62, CASE WHEN isnull(amount#63) THEN 0 ELSE cast(cast(regexp_replace(amount#63, ₹, , 1) as bigint) as int) END AS amount#81]\n",
            "+- *(1) Scan ExistingRDD[course_id#59,course_name#60,skills#61,level#62,amount#63]\n",
            "\n",
            "== Parsed Logical Plan ==\n",
            "'Project [unresolvedstarwithcolumns(enrollment_date, 'coalesce(cast('try_to_timestamp('enrollment_date, yyyy-MM-dd) as date), cast('try_to_timestamp('enrollment_date, dd/MM/yyyy) as date), cast('try_to_timestamp('enrollment_date, yyyy/MM/dd) as date)), None)]\n",
            "+- LogicalRDD [user_id#98, course_id#99, enrollment_date#100], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "user_id: string, course_id: string, enrollment_date: date\n",
            "Project [user_id#98, course_id#99, coalesce(cast(try_to_timestamp(enrollment_date#100, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(enrollment_date#100, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false) as date), cast(try_to_timestamp(enrollment_date#100, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false) as date)) AS enrollment_date#147]\n",
            "+- LogicalRDD [user_id#98, course_id#99, enrollment_date#100], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [user_id#98, course_id#99, coalesce(cast(gettimestamp(enrollment_date#100, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(enrollment_date#100, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(enrollment_date#100, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS enrollment_date#147]\n",
            "+- LogicalRDD [user_id#98, course_id#99, enrollment_date#100], false\n",
            "\n",
            "== Physical Plan ==\n",
            "*(1) Project [user_id#98, course_id#99, coalesce(cast(gettimestamp(enrollment_date#100, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(enrollment_date#100, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(enrollment_date#100, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS enrollment_date#147]\n",
            "+- *(1) Scan ExistingRDD[user_id#98,course_id#99,enrollment_date#100]\n",
            "\n",
            "== Parsed Logical Plan ==\n",
            "'Project [unresolvedstarwithcolumns(device_info, CASE WHEN 'isNull('device_info) THEN null WHEN 'like('device_info, {'device':%}) THEN 'get_json_object('device_info, $.device) WHEN 'like('device_info, device=%) THEN 'split('device_info, =, -1)[1] ELSE null END, None)]\n",
            "+- Project [user_id#130, cast(CASE WHEN isnull(activity_log#131) THEN cast(null as array<string>) ELSE array_compact(transform(split(regexp_replace(regexp_replace(activity_log#131, \\[|\\], , 1), '|\\|, ,, 1), ,, -1), lambdafunction(trim(lambda x_13#445, None), lambda x_13#445, false))) END as array<string>) AS activity_log#444, device_info#132, time#133]\n",
            "   +- LogicalRDD [user_id#130, activity_log#131, device_info#132, time#133], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "user_id: string, activity_log: array<string>, device_info: string, time: int\n",
            "Project [user_id#130, activity_log#444, CASE WHEN isnull(device_info#132) THEN cast(null as string) WHEN device_info#132 LIKE {'device':%} THEN get_json_object(device_info#132, $.device) WHEN device_info#132 LIKE device=% THEN split(device_info#132, =, -1)[1] ELSE cast(null as string) END AS device_info#447, time#133]\n",
            "+- Project [user_id#130, cast(CASE WHEN isnull(activity_log#131) THEN cast(null as array<string>) ELSE array_compact(transform(split(regexp_replace(regexp_replace(activity_log#131, \\[|\\], , 1), '|\\|, ,, 1), ,, -1), lambdafunction(trim(lambda x_13#445, None), lambda x_13#445, false))) END as array<string>) AS activity_log#444, device_info#132, time#133]\n",
            "   +- LogicalRDD [user_id#130, activity_log#131, device_info#132, time#133], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [user_id#130, CASE WHEN isnull(activity_log#131) THEN null ELSE knownnotcontainsnull(filter(transform(split(regexp_replace(regexp_replace(activity_log#131, \\[|\\], , 1), '|\\|, ,, 1), ,, -1), lambdafunction(trim(lambda x_13#445, None), lambda x_13#445, false)), lambdafunction(isnotnull(lambda arg#446), lambda arg#446, false))) END AS activity_log#444, CASE WHEN isnull(device_info#132) THEN null WHEN ((length(device_info#132) >= 11) AND (StartsWith(device_info#132, {'device':) AND EndsWith(device_info#132, }))) THEN get_json_object(device_info#132, $.device) WHEN StartsWith(device_info#132, device=) THEN split(device_info#132, =, -1)[1] END AS device_info#447, time#133]\n",
            "+- LogicalRDD [user_id#130, activity_log#131, device_info#132, time#133], false\n",
            "\n",
            "== Physical Plan ==\n",
            "Project [user_id#130, CASE WHEN isnull(activity_log#131) THEN null ELSE knownnotcontainsnull(filter(transform(split(regexp_replace(regexp_replace(activity_log#131, \\[|\\], , 1), '|\\|, ,, 1), ,, -1), lambdafunction(trim(lambda x_13#445, None), lambda x_13#445, false)), lambdafunction(isnotnull(lambda arg#446), lambda arg#446, false))) END AS activity_log#444, CASE WHEN isnull(device_info#132) THEN null WHEN ((length(device_info#132) >= 11) AND (StartsWith(device_info#132, {'device':) AND EndsWith(device_info#132, }))) THEN get_json_object(device_info#132, $.device) WHEN StartsWith(device_info#132, device=) THEN split(device_info#132, =, -1)[1] END AS device_info#447, time#133]\n",
            "+- *(1) Scan ExistingRDD[user_id#130,activity_log#131,device_info#132,time#133]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wwqaVXuucCxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eX5yDPmccCo2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}