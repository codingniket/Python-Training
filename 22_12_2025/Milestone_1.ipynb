{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXOdHHvxtoetIzg9bU2wpd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codingniket/Python-Training/blob/main/22_12_2025/Milestone_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ASErbb6ts1qw"
      },
      "outputs": [],
      "source": [
        "raw_drivers = [\n",
        "(\"D001\",\"Ramesh\",\"35\",\"Hyderabad\",\"Car,Bike\"),\n",
        "(\"D002\",\"Suresh\",\"Forty\",\"Bangalore\",\"Auto\"),\n",
        "(\"D003\",\"Anita\",None,\"Mumbai\",[\"Car\"]),\n",
        "(\"D004\",\"Kiran\",\"29\",\"Delhi\",\"Car|Bike\"),\n",
        "(\"D005\",\"\", \"42\",\"Chennai\",None)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, lit, when,regexp_replace, split, trim, array_compact, transform, get_json_object, lower\n",
        "spark = SparkSession.builder.appName(\"MileStone1\").getOrCreate()\n",
        "from pyspark.sql.types import (StructType, StructField, StringType,LongType,IntegerType,ArrayType,MapType)"
      ],
      "metadata": {
        "id": "n7GrBZiItR20"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "driver_schema = StructType([\n",
        "    StructField(\"driverid\", StringType(), nullable=False),\n",
        "    StructField(\"name\", StringType(), nullable=True),\n",
        "    StructField(\"age\", StringType(), nullable=True),\n",
        "    StructField(\"city\", StringType(), nullable=True),\n",
        "    StructField(\"vechile\", StringType(), nullable=True)\n",
        "])\n",
        "df = spark.createDataFrame(raw_drivers,driver_schema)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymtMrX6hxErG",
        "outputId": "b872cd1d-1d0d-443e-81ce-75a95847b022"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+-----+---------+--------+\n",
            "|driverid|  name|  age|     city| vechile|\n",
            "+--------+------+-----+---------+--------+\n",
            "|    D001|Ramesh|   35|Hyderabad|Car,Bike|\n",
            "|    D002|Suresh|Forty|Bangalore|    Auto|\n",
            "|    D003| Anita| NULL|   Mumbai|   [Car]|\n",
            "|    D004| Kiran|   29|    Delhi|Car|Bike|\n",
            "|    D005|      |   42|  Chennai|    NULL|\n",
            "+--------+------+-----+---------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fixing Given Issue Below"
      ],
      "metadata": {
        "id": "xZKeWHh_xths"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Known Issues\n",
        "Age in mixed formats\n",
        "\n",
        "Vehicle types in string / array / multiple delimiters\n",
        "\n",
        "Missing names\n",
        "\n",
        "Null value"
      ],
      "metadata": {
        "id": "d-Vt2sZFxv78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clean_age = df.withColumn(\"age\", when(col(\"age\") == \"\", None)\n",
        "    .when(col(\"age\").rlike(r\"^\\d+$\"),\n",
        "          col(\"age\").cast(IntegerType()))\n",
        "    .otherwise(None))\n",
        "\n",
        "clean_name_city_vechile = clean_age.withColumn(\"name\", when(col(\"name\") == \"\", None)\n",
        "    .otherwise(col(\"name\"))) \\\n",
        ".withColumn(\"city\",trim(col(\"city\")))\\\n",
        ".withColumn(\n",
        "    \"vechile\",\n",
        "    (when(\n",
        "        col(\"vechile\").isNull(),\n",
        "        None\n",
        "    ).otherwise(\n",
        "        array_compact(\n",
        "            transform(\n",
        "                split(\n",
        "                    regexp_replace(\n",
        "                        col(\"vechile\"),\n",
        "                        r\"\\[|\\]|'|\\|\", \",\"),\n",
        "                    \",\"),\n",
        "                lambda x: when(trim(x) != lit(\"\"), trim(x)).otherwise(lit(None))\n",
        "            )\n",
        "        )\n",
        "    )).cast(ArrayType(StringType()))\n",
        ")\n",
        "\n",
        "clean_name_city_vechile.show()\n",
        "\n",
        "driver_df = clean_name_city_vechile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSH9j2Msw8is",
        "outputId": "d17f59dd-6ac6-47a2-e281-b3b515ab52f1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+----+---------+-----------+\n",
            "|driverid|  name| age|     city|    vechile|\n",
            "+--------+------+----+---------+-----------+\n",
            "|    D001|Ramesh|  35|Hyderabad|[Car, Bike]|\n",
            "|    D002|Suresh|NULL|Bangalore|     [Auto]|\n",
            "|    D003| Anita|NULL|   Mumbai|      [Car]|\n",
            "|    D004| Kiran|  29|    Delhi|[Car, Bike]|\n",
            "|    D005|  NULL|  42|  Chennai|       NULL|\n",
            "+--------+------+----+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_cities = [\n",
        "(\"Hyderabad\",\"South\"),\n",
        "(\"Bangalore\",\"South\"),\n",
        "(\"Mumbai\",\"West\"),\n",
        "(\"Delhi\",\"North\"),\n",
        "(\"Chennai\",\"South\")\n",
        "]"
      ],
      "metadata": {
        "id": "vOmeLYy-yWa0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "city_schema = StructType([\n",
        "    StructField(\"city\", StringType(), nullable=True),\n",
        "    StructField(\"region\", StringType(), nullable=True)\n",
        "])\n",
        "city_df = spark.createDataFrame(raw_cities,city_schema)\n",
        "city_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOvesvwSzeSF",
        "outputId": "e0812eca-4ff6-4ea9-8488-9dc2768e1f2c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------+\n",
            "|     city|region|\n",
            "+---------+------+\n",
            "|Hyderabad| South|\n",
            "|Bangalore| South|\n",
            "|   Mumbai|  West|\n",
            "|    Delhi| North|\n",
            "|  Chennai| South|\n",
            "+---------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes\n",
        "\n",
        "Small reference dataset\n",
        "\n",
        "Intended for broadcast join"
      ],
      "metadata": {
        "id": "6gZQX4XI0Dnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import broadcast"
      ],
      "metadata": {
        "id": "QHgxJCb_0XqD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "driver_join  = driver_df.join(broadcast(city_df), \"city\", \"inner\")\n",
        "driver_join.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sonBQ6bz4x0",
        "outputId": "92695fc0-1066-46e3-df63-3b8d3a0e1549"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------+----+-----------+------+\n",
            "|     city|driverid|  name| age|    vechile|region|\n",
            "+---------+--------+------+----+-----------+------+\n",
            "|Hyderabad|    D001|Ramesh|  35|[Car, Bike]| South|\n",
            "|Bangalore|    D002|Suresh|NULL|     [Auto]| South|\n",
            "|   Mumbai|    D003| Anita|NULL|      [Car]|  West|\n",
            "|    Delhi|    D004| Kiran|  29|[Car, Bike]| North|\n",
            "|  Chennai|    D005|  NULL|  42|       NULL| South|\n",
            "+---------+--------+------+----+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_trips = [\n",
        "(\"T001\",\"D001\",\"Hyderabad\",\"2024-01-05\",\"Completed\",\"450\"),\n",
        "(\"T002\",\"D002\",\"Bangalore\",\"05/01/2024\",\"Cancelled\",\"0\"),\n",
        "(\"T003\",\"D003\",\"Mumbai\",\"2024/01/06\",\"Completed\",\"620\"),\n",
        "(\"T004\",\"D004\",\"Delhi\",\"invalid_date\",\"Completed\",\"540\"),\n",
        "(\"T005\",\"D001\",\"Hyderabad\",\"2024-01-10\",\"Completed\",\"700\"),\n",
        "(\"T006\",\"D005\",\"Chennai\",\"2024-01-12\",\"Completed\",\"350\")\n",
        "]"
      ],
      "metadata": {
        "id": "pHV7sDvK0lsq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trips_schema = StructType([\n",
        "    StructField(\"userid\", StringType(), nullable=False),\n",
        "    StructField(\"driverid\", StringType(), nullable=False),\n",
        "    StructField(\"city\", StringType(), nullable=True),\n",
        "    StructField(\"date\", StringType(), nullable=True),\n",
        "    StructField(\"status\", StringType(), nullable=True),\n",
        "    StructField(\"amount\", StringType(), nullable=True),\n",
        "])\n",
        "trips_df = spark.createDataFrame(raw_trips,trips_schema)\n",
        "trips_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LsiSpMP0uy8",
        "outputId": "2ed312ef-c074-49e9-d963-9e059051c067"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+---------+------------+---------+------+\n",
            "|userid|driverid|     city|        date|   status|amount|\n",
            "+------+--------+---------+------------+---------+------+\n",
            "|  T001|    D001|Hyderabad|  2024-01-05|Completed|   450|\n",
            "|  T002|    D002|Bangalore|  05/01/2024|Cancelled|     0|\n",
            "|  T003|    D003|   Mumbai|  2024/01/06|Completed|   620|\n",
            "|  T004|    D004|    Delhi|invalid_date|Completed|   540|\n",
            "|  T005|    D001|Hyderabad|  2024-01-10|Completed|   700|\n",
            "|  T006|    D005|  Chennai|  2024-01-12|Completed|   350|\n",
            "+------+--------+---------+------------+---------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, to_date, coalesce, split, lit, array_remove, try_to_timestamp"
      ],
      "metadata": {
        "id": "lqBlF9Cf1Zmg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_date_amount = trips_df.withColumn(\"amount\", col(\"amount\").cast(IntegerType()))\\\n",
        ".withColumn(\n",
        "    \"date\",\n",
        "    coalesce(\n",
        "        to_date(try_to_timestamp(col(\"date\"), lit(\"yyyy-MM-dd\"))),\n",
        "        to_date(try_to_timestamp(col(\"date\"), lit(\"dd/MM/yyyy\"))),\n",
        "        to_date(try_to_timestamp(col(\"date\"), lit(\"yyyy/MM/dd\")))\n",
        "    )\n",
        ")\n",
        "\n",
        "clean_date_amount = clean_date_amount.filter(col(\"amount\") > 0)\n",
        "\n",
        "clean_date_amount.show()\n",
        "tripsdf=clean_date_amount"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLOOrDH51DIR",
        "outputId": "fd942731-6ca9-403c-cd73-fa89aacaffd9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+---------+----------+---------+------+\n",
            "|userid|driverid|     city|      date|   status|amount|\n",
            "+------+--------+---------+----------+---------+------+\n",
            "|  T001|    D001|Hyderabad|2024-01-05|Completed|   450|\n",
            "|  T003|    D003|   Mumbai|2024-01-06|Completed|   620|\n",
            "|  T004|    D004|    Delhi|      NULL|Completed|   540|\n",
            "|  T005|    D001|Hyderabad|2024-01-10|Completed|   700|\n",
            "|  T006|    D005|  Chennai|2024-01-12|Completed|   350|\n",
            "+------+--------+---------+----------+---------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nH5cE_Fk1scJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_activity = [\n",
        "(\"D001\",\"login,accept_trip,logout\",\"{'device':'mobile'}\",180),\n",
        "(\"D002\",[\"login\",\"logout\"],\"device=laptop\",60),\n",
        "(\"D003\",\"login|accept_trip\",None,120),\n",
        "(\"D004\",None,\"{'device':'tablet'}\",90),\n",
        "(\"D005\",\"login\",\"{'device':'mobile'}\",30)\n",
        "]"
      ],
      "metadata": {
        "id": "zuF572HI2xHt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activity_schema = StructType([\n",
        "    StructField(\"userid\", StringType(), nullable=False),\n",
        "    StructField(\"actions\", StringType(), nullable=True),\n",
        "    StructField(\"device\", StringType(), nullable=True),\n",
        "    StructField(\"amount\", IntegerType(), nullable=True),\n",
        "])\n",
        "activity_df = spark.createDataFrame(raw_activity,activity_schema)\n",
        "activity_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rQUyG9Q1bTp",
        "outputId": "693253df-9fda-4f0d-b17b-c0edfa2967ab"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------------+-------------------+------+\n",
            "|userid|             actions|             device|amount|\n",
            "+------+--------------------+-------------------+------+\n",
            "|  D001|login,accept_trip...|{'device':'mobile'}|   180|\n",
            "|  D002|     [login, logout]|      device=laptop|    60|\n",
            "|  D003|   login|accept_trip|               NULL|   120|\n",
            "|  D004|                NULL|{'device':'tablet'}|    90|\n",
            "|  D005|               login|{'device':'mobile'}|    30|\n",
            "+------+--------------------+-------------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Known Issues\n",
        "Actions in multiple formats\n",
        "Metadata as JSON-like strings\n",
        "Missing actions"
      ],
      "metadata": {
        "id": "gJjoKUMf4KNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_activity_clean = activity_df.withColumn(\n",
        "    \"actions\",\n",
        "    (when(\n",
        "        col(\"actions\").isNull(),\n",
        "        None\n",
        "    ).otherwise(\n",
        "        array_compact(\n",
        "            transform(\n",
        "                split(\n",
        "                    regexp_replace(\n",
        "                        col(\"actions\"),\n",
        "                        r\"\\[|\\]|'|\\|\", \",\"),\n",
        "                    \",\"),\n",
        "                lambda x: when(trim(x) != lit(\"\"), trim(x)).otherwise(lit(None))\n",
        "            )\n",
        "        )\n",
        "    )).cast(ArrayType(StringType()))\n",
        ").withColumn(\n",
        "    \"device\",\n",
        "    when(col(\"device\").isNull(), None)\n",
        "    .when(col(\"device\").like(\"{'device':%}\"), get_json_object(col(\"device\"), \"$.device\"))\n",
        "    .when(col(\"device\").like(\"device=%\"), split(col(\"device\"), \"=\").getItem(1))\n",
        "    .otherwise(None)\n",
        ")\n",
        "\n",
        "df_activity_clean.show(truncate=False)\n",
        "df_activity_clean.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIMlaV643E7y",
        "outputId": "2710f595-caa5-416e-e294-8889cf4afae1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------------------------+------+------+\n",
            "|userid|actions                     |device|amount|\n",
            "+------+----------------------------+------+------+\n",
            "|D001  |[login, accept_trip, logout]|mobile|180   |\n",
            "|D002  |[login, logout]             |laptop|60    |\n",
            "|D003  |[login, accept_trip]        |NULL  |120   |\n",
            "|D004  |NULL                        |tablet|90    |\n",
            "|D005  |[login]                     |mobile|30    |\n",
            "+------+----------------------------+------+------+\n",
            "\n",
            "root\n",
            " |-- userid: string (nullable = false)\n",
            " |-- actions: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- device: string (nullable = true)\n",
            " |-- amount: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All clean data"
      ],
      "metadata": {
        "id": "0jCLbnH34hX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART A — DATA CLEANING & STRUCTURING\n",
        "\n",
        ". Design explicit schemas for all\n",
        " datasets\n",
        ". Normalize:\n",
        "\n",
        "Age\n",
        "\n",
        "Fare\n",
        "\n",
        "Dates\n",
        "\n",
        ". Convert vehicle types and actions into arrays\n",
        "\n",
        ". Handle missing and invalid records gracefully\n",
        "\n",
        ". Produce clean DataFrames:\n",
        "\n",
        "drivers_df\n",
        "\n",
        "cities_df\n",
        "\n",
        "trips_df\n",
        "\n",
        "activity_df"
      ],
      "metadata": {
        "id": "cXim-JGi4qfO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K3OvcDVJ4qQO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_activity_clean.show()\n",
        "tripsdf.show()\n",
        "driver_join.show()\n",
        "driver_df.show()\n",
        "city_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KYxNuNv3oDK",
        "outputId": "bb62650a-76ab-4714-a7a5-c871202fd3c9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------------+------+------+\n",
            "|userid|             actions|device|amount|\n",
            "+------+--------------------+------+------+\n",
            "|  D001|[login, accept_tr...|mobile|   180|\n",
            "|  D002|     [login, logout]|laptop|    60|\n",
            "|  D003|[login, accept_trip]|  NULL|   120|\n",
            "|  D004|                NULL|tablet|    90|\n",
            "|  D005|             [login]|mobile|    30|\n",
            "+------+--------------------+------+------+\n",
            "\n",
            "+------+--------+---------+----------+---------+------+\n",
            "|userid|driverid|     city|      date|   status|amount|\n",
            "+------+--------+---------+----------+---------+------+\n",
            "|  T001|    D001|Hyderabad|2024-01-05|Completed|   450|\n",
            "|  T003|    D003|   Mumbai|2024-01-06|Completed|   620|\n",
            "|  T004|    D004|    Delhi|      NULL|Completed|   540|\n",
            "|  T005|    D001|Hyderabad|2024-01-10|Completed|   700|\n",
            "|  T006|    D005|  Chennai|2024-01-12|Completed|   350|\n",
            "+------+--------+---------+----------+---------+------+\n",
            "\n",
            "+---------+--------+------+----+-----------+------+\n",
            "|     city|driverid|  name| age|    vechile|region|\n",
            "+---------+--------+------+----+-----------+------+\n",
            "|Hyderabad|    D001|Ramesh|  35|[Car, Bike]| South|\n",
            "|Bangalore|    D002|Suresh|NULL|     [Auto]| South|\n",
            "|   Mumbai|    D003| Anita|NULL|      [Car]|  West|\n",
            "|    Delhi|    D004| Kiran|  29|[Car, Bike]| North|\n",
            "|  Chennai|    D005|  NULL|  42|       NULL| South|\n",
            "+---------+--------+------+----+-----------+------+\n",
            "\n",
            "+--------+------+----+---------+-----------+\n",
            "|driverid|  name| age|     city|    vechile|\n",
            "+--------+------+----+---------+-----------+\n",
            "|    D001|Ramesh|  35|Hyderabad|[Car, Bike]|\n",
            "|    D002|Suresh|NULL|Bangalore|     [Auto]|\n",
            "|    D003| Anita|NULL|   Mumbai|      [Car]|\n",
            "|    D004| Kiran|  29|    Delhi|[Car, Bike]|\n",
            "|    D005|  NULL|  42|  Chennai|       NULL|\n",
            "+--------+------+----+---------+-----------+\n",
            "\n",
            "+---------+------+\n",
            "|     city|region|\n",
            "+---------+------+\n",
            "|Hyderabad| South|\n",
            "|Bangalore| South|\n",
            "|   Mumbai|  West|\n",
            "|    Delhi| North|\n",
            "|  Chennai| South|\n",
            "+---------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART B — DATA INTEGRATION (JOINS)\n",
        "\n",
        ". Join trips with drivers\n",
        "\n",
        ". Join trips with cities\n",
        "\n",
        ". Decide which dataset should be\n",
        "broadcast\n",
        "\n",
        ". Prove your decision using explain(True)\n",
        "\n",
        ". Remove orphan trips (drivers not in master"
      ],
      "metadata": {
        "id": "OqcI2OuY40Fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "city_df.show()\n",
        "\n",
        "trips_city_join  = tripsdf.join(broadcast(city_df), \"city\", \"inner\")\n",
        "trips_city_join.show()\n",
        "\n",
        "trips_city_join.explain(True)\n",
        "\n",
        "ophan = trips_city_join.filter(~trips_city_join[\"date\"].isNull())\n",
        "ophan.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZa4-xaG4iT1",
        "outputId": "373176b5-af74-44c0-a761-dd0d4e57383b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------+\n",
            "|     city|region|\n",
            "+---------+------+\n",
            "|Hyderabad| South|\n",
            "|Bangalore| South|\n",
            "|   Mumbai|  West|\n",
            "|    Delhi| North|\n",
            "|  Chennai| South|\n",
            "+---------+------+\n",
            "\n",
            "+---------+------+--------+----------+---------+------+------+\n",
            "|     city|userid|driverid|      date|   status|amount|region|\n",
            "+---------+------+--------+----------+---------+------+------+\n",
            "|Hyderabad|  T001|    D001|2024-01-05|Completed|   450| South|\n",
            "|   Mumbai|  T003|    D003|2024-01-06|Completed|   620|  West|\n",
            "|    Delhi|  T004|    D004|      NULL|Completed|   540| North|\n",
            "|Hyderabad|  T005|    D001|2024-01-10|Completed|   700| South|\n",
            "|  Chennai|  T006|    D005|2024-01-12|Completed|   350| South|\n",
            "+---------+------+--------+----------+---------+------+------+\n",
            "\n",
            "== Parsed Logical Plan ==\n",
            "'Join UsingJoin(Inner, [city])\n",
            ":- Filter (amount#97 > 0)\n",
            ":  +- Project [userid#72, driverid#73, city#74, coalesce(to_date(try_to_timestamp(date#75, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(date#75, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(date#75, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true)) AS date#98, status#76, amount#97]\n",
            ":     +- Project [userid#72, driverid#73, city#74, date#75, status#76, cast(amount#77 as int) AS amount#97]\n",
            ":        +- LogicalRDD [userid#72, driverid#73, city#74, date#75, status#76, amount#77], false\n",
            "+- ResolvedHint (strategy=broadcast)\n",
            "   +- LogicalRDD [city#44, region#45], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city: string, userid: string, driverid: string, date: date, status: string, amount: int, region: string\n",
            "Project [city#74, userid#72, driverid#73, date#98, status#76, amount#97, region#45]\n",
            "+- Join Inner, (city#74 = city#44)\n",
            "   :- Filter (amount#97 > 0)\n",
            "   :  +- Project [userid#72, driverid#73, city#74, coalesce(to_date(try_to_timestamp(date#75, Some(yyyy-MM-dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(date#75, Some(dd/MM/yyyy), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true), to_date(try_to_timestamp(date#75, Some(yyyy/MM/dd), TimestampType, Some(Etc/UTC), false), None, Some(Etc/UTC), true)) AS date#98, status#76, amount#97]\n",
            "   :     +- Project [userid#72, driverid#73, city#74, date#75, status#76, cast(amount#77 as int) AS amount#97]\n",
            "   :        +- LogicalRDD [userid#72, driverid#73, city#74, date#75, status#76, amount#77], false\n",
            "   +- ResolvedHint (strategy=broadcast)\n",
            "      +- LogicalRDD [city#44, region#45], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [city#74, userid#72, driverid#73, date#98, status#76, amount#97, region#45]\n",
            "+- Join Inner, (city#74 = city#44), rightHint=(strategy=broadcast)\n",
            "   :- Project [userid#72, driverid#73, city#74, coalesce(cast(gettimestamp(date#75, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(date#75, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(date#75, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS date#98, status#76, cast(amount#77 as int) AS amount#97]\n",
            "   :  +- Filter ((isnotnull(amount#77) AND (cast(amount#77 as int) > 0)) AND isnotnull(city#74))\n",
            "   :     +- LogicalRDD [userid#72, driverid#73, city#74, date#75, status#76, amount#77], false\n",
            "   +- Filter isnotnull(city#44)\n",
            "      +- LogicalRDD [city#44, region#45], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [city#74, userid#72, driverid#73, date#98, status#76, amount#97, region#45]\n",
            "   +- BroadcastHashJoin [city#74], [city#44], Inner, BuildRight, false\n",
            "      :- Project [userid#72, driverid#73, city#74, coalesce(cast(gettimestamp(date#75, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(date#75, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(date#75, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS date#98, status#76, cast(amount#77 as int) AS amount#97]\n",
            "      :  +- Filter ((isnotnull(amount#77) AND (cast(amount#77 as int) > 0)) AND isnotnull(city#74))\n",
            "      :     +- Scan ExistingRDD[userid#72,driverid#73,city#74,date#75,status#76,amount#77]\n",
            "      +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=406]\n",
            "         +- Filter isnotnull(city#44)\n",
            "            +- Scan ExistingRDD[city#44,region#45]\n",
            "\n",
            "+---------+------+--------+----------+---------+------+------+\n",
            "|     city|userid|driverid|      date|   status|amount|region|\n",
            "+---------+------+--------+----------+---------+------+------+\n",
            "|Hyderabad|  T001|    D001|2024-01-05|Completed|   450| South|\n",
            "|   Mumbai|  T003|    D003|2024-01-06|Completed|   620|  West|\n",
            "|Hyderabad|  T005|    D001|2024-01-10|Completed|   700| South|\n",
            "|  Chennai|  T006|    D005|2024-01-12|Completed|   350| South|\n",
            "+---------+------+--------+----------+---------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART C — ANALYTICS & AGGREGATIONS\n",
        "\n",
        ". Total trips per city\n",
        "\n",
        ". Total revenue per city\n",
        "\n",
        ". Average fare per driver\n",
        "\n",
        ". Total completed trips per driver\n",
        "\n",
        ". Identify drivers with no completed trip"
      ],
      "metadata": {
        "id": "UIi7Qsq46YST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import count\n",
        "\n",
        "total_trips_per_city = (\n",
        "    trips_df\n",
        "    .groupBy(\"city\")\n",
        "    .agg(count(\"*\").alias(\"Total revenue per city\"))\n",
        ")\n",
        "\n",
        "total_trips_per_city.show()\n"
      ],
      "metadata": {
        "id": "qgpVzMd15I-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aa03f17-cae2-4147-d8cb-a73242b52df3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------------------+\n",
            "|     city|Total revenue per city|\n",
            "+---------+----------------------+\n",
            "|Bangalore|                     1|\n",
            "|   Mumbai|                     1|\n",
            "|Hyderabad|                     2|\n",
            "|  Chennai|                     1|\n",
            "|    Delhi|                     1|\n",
            "+---------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum\n",
        "\n",
        "total_rev_per_city = (\n",
        "    trips_df\n",
        "    .groupBy(\"city\")\n",
        "    .agg(sum(\"amount\").alias(\"total_trips\"))\n",
        ")\n",
        "\n",
        "total_rev_per_city.show()\n"
      ],
      "metadata": {
        "id": "ycuPaTrj5U-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "563bf4e9-d3ba-4bc2-a6b8-8f7864e60d24"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+\n",
            "|     city|total_trips|\n",
            "+---------+-----------+\n",
            "|Bangalore|        0.0|\n",
            "|   Mumbai|      620.0|\n",
            "|Hyderabad|     1150.0|\n",
            "|  Chennai|      350.0|\n",
            "|    Delhi|      540.0|\n",
            "+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import count\n",
        "\n",
        "total_trips_completed = (\n",
        "    trips_df\n",
        "    .groupBy(\"driverid\")\n",
        "    .agg(count(\"*\").alias(\"total_trips_completed\"))\n",
        ")\n",
        "\n",
        "total_trips_completed.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVQtGe2WWjjn",
        "outputId": "f3b92685-9ffa-4911-826e-ed65c821e579"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------------------+\n",
            "|driverid|total_trips_completed|\n",
            "+--------+---------------------+\n",
            "|    D002|                    1|\n",
            "|    D003|                    1|\n",
            "|    D001|                    2|\n",
            "|    D004|                    1|\n",
            "|    D005|                    1|\n",
            "+--------+---------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trips_df.filter(trips_df[\"status\"] == \"Not Completed\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XRnoCA8WxjL",
        "outputId": "ee56eab5-9dcf-41da-cd38-64996cfe2064"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+----+----+------+------+\n",
            "|userid|driverid|city|date|status|amount|\n",
            "+------+--------+----+----+------+------+\n",
            "+------+--------+----+----+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART D — WINDOW FUNCTIONS\n",
        ". Rank drivers by total revenue (overall)\n",
        ". Rank drivers by revenue within each city\n",
        ". Calculate running revenue per city by date\n",
        ". Compare GroupBy vs Window for one metric"
      ],
      "metadata": {
        "id": "EwpcNjjB74MG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trips_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH_MX7IX8ShO",
        "outputId": "cc6099d0-2507-4d0a-a6b4-0ed836eb1e8d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+---------+------------+---------+------+\n",
            "|userid|driverid|     city|        date|   status|amount|\n",
            "+------+--------+---------+------------+---------+------+\n",
            "|  T001|    D001|Hyderabad|  2024-01-05|Completed|   450|\n",
            "|  T002|    D002|Bangalore|  05/01/2024|Cancelled|     0|\n",
            "|  T003|    D003|   Mumbai|  2024/01/06|Completed|   620|\n",
            "|  T004|    D004|    Delhi|invalid_date|Completed|   540|\n",
            "|  T005|    D001|Hyderabad|  2024-01-10|Completed|   700|\n",
            "|  T006|    D005|  Chennai|  2024-01-12|Completed|   350|\n",
            "+------+--------+---------+------------+---------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "driver_revenue = trips_df.groupBy(\"driverid\") \\\n",
        "    .agg(F.sum(\"amount\").alias(\"total_revenue\")) \\\n",
        "    .orderBy(F.desc(\"total_revenue\"))\n",
        "\n",
        "driver_revenue.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlYX0tne75JH",
        "outputId": "b6715ab2-01d8-482c-e102-bf665524299c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-------------+\n",
            "|driverid|total_revenue|\n",
            "+--------+-------------+\n",
            "|    D001|       1150.0|\n",
            "|    D003|        620.0|\n",
            "|    D004|        540.0|\n",
            "|    D005|        350.0|\n",
            "|    D002|          0.0|\n",
            "+--------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window"
      ],
      "metadata": {
        "id": "Oug-Lbhb8iqK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "city_driver_rank = trips_df.groupBy(\"city\", \"driverid\") \\\n",
        "    .agg(F.sum(\"amount\").alias(\"city_revenue\")) \\\n",
        "    .withColumn(\"rank\", F.rank().over(Window.partitionBy(\"city\").orderBy(F.desc(\"city_revenue\"))))\n",
        "city_driver_rank.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THk0umdU76Us",
        "outputId": "b1bdfd7a-d974-400d-aba8-0d713c9b7caa"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------+----+\n",
            "|     city|driverid|city_revenue|rank|\n",
            "+---------+--------+------------+----+\n",
            "|Bangalore|    D002|         0.0|   1|\n",
            "|  Chennai|    D005|       350.0|   1|\n",
            "|    Delhi|    D004|       540.0|   1|\n",
            "|Hyderabad|    D001|      1150.0|   1|\n",
            "|   Mumbai|    D003|       620.0|   1|\n",
            "+---------+--------+------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "\n",
        "city_date_window = Window.partitionBy(\"city\").orderBy(\"date\") \\\n",
        "    .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
        "\n",
        "running_revenue = trips_df.groupBy(\"city\", \"date\") \\\n",
        "    .agg(F.sum(\"amount\").alias(\"daily_revenue\")) \\\n",
        "    .withColumn(\"running_revenue\", F.sum(\"daily_revenue\").over(city_date_window))"
      ],
      "metadata": {
        "id": "VlXMLWXk8kHo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ". Compare GroupBy vs Window for one metric\n",
        "GroupBy: Aggregates data into fewer rows (e.g., total revenue per driver).\n",
        "Window: Keeps original granularity but adds computed columns (e.g., rank, cumulative sum).\n",
        "Use Case:\n",
        "GroupBy → summary reports.\n",
        "Window → analytics like ranking, running totals without collapsing rows"
      ],
      "metadata": {
        "id": "Q1BfWmA98-96"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART E — UDF (ONLY IF REQUIRED)\n",
        ". Classify drivers into performance levels:\n",
        "High\n",
        "Medium\n",
        "Rules:\n",
        "Low\n",
        "Prefer built-in functions\n",
        "Use UDF only if unavoidable\n",
        "Justify your choic"
      ],
      "metadata": {
        "id": "YEMO9tMx9WkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql.functions import udf, col\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "# Define classification based on revenue\n",
        "def classify_revenue(revenue):\n",
        "    if revenue >= 1000:\n",
        "        return \"High\"\n",
        "    elif revenue >= 500:\n",
        "        return \"Medium\"\n",
        "    else:\n",
        "        return \"Low\"\n",
        "\n",
        "# Register UDF\n",
        "classify_revenue_udf = udf(classify_revenue, StringType())\n",
        "\n",
        "# Apply UDF on city_revenue column\n",
        "city_driver_rank.withColumn(\"revenue_grade\", classify_revenue_udf(col(\"city_revenue\"))).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFLOfixe894m",
        "outputId": "723a1610-4168-42c8-8285-79ec1ad7e6da"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------+----+-------------+\n",
            "|     city|driverid|city_revenue|rank|revenue_grade|\n",
            "+---------+--------+------------+----+-------------+\n",
            "|Bangalore|    D002|         0.0|   1|          Low|\n",
            "|  Chennai|    D005|       350.0|   1|          Low|\n",
            "|    Delhi|    D004|       540.0|   1|       Medium|\n",
            "|Hyderabad|    D001|      1150.0|   1|         High|\n",
            "|   Mumbai|    D003|       620.0|   1|       Medium|\n",
            "+---------+--------+------------+----+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART F — SORTING & ORDERING\n",
        "\n",
        "21. Sort cities by total revenue (descending)\n",
        "\n",
        "22. Sort drivers by revenue within each city\n",
        "\n",
        "23. Explain why sorting caused a shuffle"
      ],
      "metadata": {
        "id": "o93gVPSQVP9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import desc\n",
        "\n",
        "sorted_cities_by_revenue = (\n",
        "     trips_df\n",
        "    .groupBy(\"city\")\n",
        "    .agg(sum(\"amount\").alias(\"total_revenue\"))\n",
        "    .orderBy(desc(\"total_revenue\"))\n",
        ")\n",
        "\n",
        "sorted_cities_by_revenue.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d40PCDd9XWXV",
        "outputId": "c4f533ae-8c11-46c7-a13e-2d298d4ffc3b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------+\n",
            "|     city|total_revenue|\n",
            "+---------+-------------+\n",
            "|Hyderabad|       1150.0|\n",
            "|   Mumbai|        620.0|\n",
            "|    Delhi|        540.0|\n",
            "|  Chennai|        350.0|\n",
            "|Bangalore|          0.0|\n",
            "+---------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum\n",
        "\n",
        "driver_city_revenue = (\n",
        "    trips_df\n",
        "    .groupBy(\"city\", \"driverid\")\n",
        "    .agg(sum(\"amount\").alias(\"driver_revenue\"))\n",
        ")\n",
        "\n",
        "driver_city_revenue.show()\n",
        "\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import desc, row_number\n",
        "\n",
        "city_window = Window.partitionBy(\"city\").orderBy(desc(\"driver_revenue\"))\n",
        "\n",
        "sorted_drivers_within_city = (\n",
        "    driver_city_revenue\n",
        "    .withColumn(\"rank\", row_number().over(city_window))\n",
        "    .orderBy(\"city\", \"rank\")\n",
        ")\n",
        "\n",
        "sorted_drivers_within_city.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToKVPfp1XXhd",
        "outputId": "dec13648-2d93-4d1a-e123-877e35677112"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+--------------+\n",
            "|     city|driverid|driver_revenue|\n",
            "+---------+--------+--------------+\n",
            "|Bangalore|    D002|           0.0|\n",
            "|   Mumbai|    D003|         620.0|\n",
            "|Hyderabad|    D001|        1150.0|\n",
            "|  Chennai|    D005|         350.0|\n",
            "|    Delhi|    D004|         540.0|\n",
            "+---------+--------+--------------+\n",
            "\n",
            "+---------+--------+--------------+----+\n",
            "|     city|driverid|driver_revenue|rank|\n",
            "+---------+--------+--------------+----+\n",
            "|Bangalore|    D002|           0.0|   1|\n",
            "|  Chennai|    D005|         350.0|   1|\n",
            "|    Delhi|    D004|         540.0|   1|\n",
            "|Hyderabad|    D001|        1150.0|   1|\n",
            "|   Mumbai|    D003|         620.0|   1|\n",
            "+---------+--------+--------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sorting causes a shuffle because Spark must move data across partitions to establish a global or partition-level order."
      ],
      "metadata": {
        "id": "unqsShy2Y8Uc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART G — SET OPERATIONS\n",
        "\n",
        "Create two DataFrames:\n",
        "\n",
        "Drivers who completed trips\n",
        "\n",
        "Drivers who were active (login)\n",
        "\n",
        "24. Find drivers who logged in but never completed trips\n",
        "\n",
        "25. Find drivers who completed trips and were active\n",
        "\n",
        "26. Explain why set operations differ from joins\n"
      ],
      "metadata": {
        "id": "ov-wqLmpVVeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completed_drivers_df = (\n",
        "    trips_df\n",
        "    .filter(trips_df.status == \"Completed\")\n",
        "    .select(\"driverid\")\n",
        "    .distinct()\n",
        ")\n",
        "\n",
        "completed_drivers_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiiIAe1tY_UH",
        "outputId": "48abb7ba-96d2-4252-f025-26c6423510c2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|driverid|\n",
            "+--------+\n",
            "|    D003|\n",
            "|    D001|\n",
            "|    D004|\n",
            "|    D005|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_activity_clean.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zzl8EfZwZU60",
        "outputId": "eacf384b-0cb8-48bb-e6e3-01f6c136a82f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------------------------+------+------+\n",
            "|userid|actions                     |device|amount|\n",
            "+------+----------------------------+------+------+\n",
            "|D001  |[login, accept_trip, logout]|mobile|180   |\n",
            "|D002  |[login, logout]             |laptop|60    |\n",
            "|D003  |[login, accept_trip]        |NULL  |120   |\n",
            "|D004  |NULL                        |tablet|90    |\n",
            "|D005  |[login]                     |mobile|30    |\n",
            "+------+----------------------------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import array_contains\n",
        "\n",
        "active_drivers_df = (\n",
        "    df_activity_clean\n",
        "    .filter(array_contains(\"actions\", \"login\")  & ~array_contains(\"actions\", \"logout\"))\n",
        "    .select(\"userid\")\n",
        "    .distinct()\n",
        ")\n",
        "\n",
        "active_drivers_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqAi5sfDY_AJ",
        "outputId": "eee9a2f1-d31e-4942-ab80-31aedb6584ef"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+\n",
            "|userid|\n",
            "+------+\n",
            "|  D003|\n",
            "|  D005|\n",
            "+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set operations work on entire rows and treat DataFrames as mathematical sets, while joins combine columns based on matching keys."
      ],
      "metadata": {
        "id": "i9Fds02naBYO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ybjC3HDZY-rQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART H — DAG & PERFORMANCE ANALYSIS\n",
        "\n",
        "27. Run explain(True) for:\n",
        "Join with city master\n",
        "Window ranking\n",
        "Sorting\n",
        "\n",
        "\n",
        "28. Identify:\n",
        "Shuffles\n",
        "Broadcast joins\n",
        "Sort stages\n",
        "\n",
        "\n",
        "29. Suggest one performance improvement"
      ],
      "metadata": {
        "id": "LrSkq_wRVa5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trip_city_join_df = trips_df.join(\n",
        "    city_df,\n",
        "    on=\"city\",\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "trip_city_join_df.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ3xJpkTZCJA",
        "outputId": "435ae96c-f9bb-4e91-ede0-3f4849c6715a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Join UsingJoin(LeftOuter, [city])\n",
            ":- LogicalRDD [userid#72, driverid#73, city#74, date#75, status#76, amount#77], false\n",
            "+- LogicalRDD [city#44, region#45], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city: string, userid: string, driverid: string, date: string, status: string, amount: string, region: string\n",
            "Project [city#74, userid#72, driverid#73, date#75, status#76, amount#77, region#45]\n",
            "+- Join LeftOuter, (city#74 = city#44)\n",
            "   :- LogicalRDD [userid#72, driverid#73, city#74, date#75, status#76, amount#77], false\n",
            "   +- LogicalRDD [city#44, region#45], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [city#74, userid#72, driverid#73, date#75, status#76, amount#77, region#45]\n",
            "+- Join LeftOuter, (city#74 = city#44)\n",
            "   :- LogicalRDD [userid#72, driverid#73, city#74, date#75, status#76, amount#77], false\n",
            "   +- Filter isnotnull(city#44)\n",
            "      +- LogicalRDD [city#44, region#45], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [city#74, userid#72, driverid#73, date#75, status#76, amount#77, region#45]\n",
            "   +- SortMergeJoin [city#74], [city#44], LeftOuter\n",
            "      :- Sort [city#74 ASC NULLS FIRST], false, 0\n",
            "      :  +- Exchange hashpartitioning(city#74, 200), ENSURE_REQUIREMENTS, [plan_id=1763]\n",
            "      :     +- Scan ExistingRDD[userid#72,driverid#73,city#74,date#75,status#76,amount#77]\n",
            "      +- Sort [city#44 ASC NULLS FIRST], false, 0\n",
            "         +- Exchange hashpartitioning(city#44, 200), ENSURE_REQUIREMENTS, [plan_id=1764]\n",
            "            +- Filter isnotnull(city#44)\n",
            "               +- Scan ExistingRDD[city#44,region#45]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_drivers_within_city.explain(True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F1ZLHWdZB7H",
        "outputId": "3bdfeda5-83cc-4d78-f635-665ce8a82b49"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Sort ['city ASC NULLS FIRST, 'rank ASC NULLS FIRST], true\n",
            "+- Project [city#74, driverid#73, driver_revenue#572, rank#593]\n",
            "   +- Project [city#74, driverid#73, driver_revenue#572, rank#593, rank#593]\n",
            "      +- Window [row_number() windowspecdefinition(city#74, driver_revenue#572 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank#593], [city#74], [driver_revenue#572 DESC NULLS LAST]\n",
            "         +- Project [city#74, driverid#73, driver_revenue#572]\n",
            "            +- Aggregate [city#74, driverid#73], [city#74, driverid#73, sum(cast(amount#77 as double)) AS driver_revenue#572]\n",
            "               +- LogicalRDD [userid#72, driverid#73, city#74, date#75, status#76, amount#77], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city: string, driverid: string, driver_revenue: double, rank: int\n",
            "Sort [city#74 ASC NULLS FIRST, rank#593 ASC NULLS FIRST], true\n",
            "+- Project [city#74, driverid#73, driver_revenue#572, rank#593]\n",
            "   +- Project [city#74, driverid#73, driver_revenue#572, rank#593, rank#593]\n",
            "      +- Window [row_number() windowspecdefinition(city#74, driver_revenue#572 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank#593], [city#74], [driver_revenue#572 DESC NULLS LAST]\n",
            "         +- Project [city#74, driverid#73, driver_revenue#572]\n",
            "            +- Aggregate [city#74, driverid#73], [city#74, driverid#73, sum(cast(amount#77 as double)) AS driver_revenue#572]\n",
            "               +- LogicalRDD [userid#72, driverid#73, city#74, date#75, status#76, amount#77], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Sort [city#74 ASC NULLS FIRST, rank#593 ASC NULLS FIRST], true\n",
            "+- Window [row_number() windowspecdefinition(city#74, driver_revenue#572 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank#593], [city#74], [driver_revenue#572 DESC NULLS LAST]\n",
            "   +- Aggregate [city#74, driverid#73], [city#74, driverid#73, sum(cast(amount#77 as double)) AS driver_revenue#572]\n",
            "      +- Project [driverid#73, city#74, amount#77]\n",
            "         +- LogicalRDD [userid#72, driverid#73, city#74, date#75, status#76, amount#77], false\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Sort [city#74 ASC NULLS FIRST, rank#593 ASC NULLS FIRST], true, 0\n",
            "   +- Exchange rangepartitioning(city#74 ASC NULLS FIRST, rank#593 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=1799]\n",
            "      +- Window [row_number() windowspecdefinition(city#74, driver_revenue#572 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rank#593], [city#74], [driver_revenue#572 DESC NULLS LAST]\n",
            "         +- Sort [city#74 ASC NULLS FIRST, driver_revenue#572 DESC NULLS LAST], false, 0\n",
            "            +- Exchange hashpartitioning(city#74, 200), ENSURE_REQUIREMENTS, [plan_id=1795]\n",
            "               +- HashAggregate(keys=[city#74, driverid#73], functions=[sum(cast(amount#77 as double))], output=[city#74, driverid#73, driver_revenue#572])\n",
            "                  +- Exchange hashpartitioning(city#74, driverid#73, 200), ENSURE_REQUIREMENTS, [plan_id=1792]\n",
            "                     +- HashAggregate(keys=[city#74, driverid#73], functions=[partial_sum(cast(amount#77 as double))], output=[city#74, driverid#73, sum#584])\n",
            "                        +- Project [driverid#73, city#74, amount#77]\n",
            "                           +- Scan ExistingRDD[userid#72,driverid#73,city#74,date#75,status#76,amount#77]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import broadcast\n",
        "\n",
        "optimized_join_df = trips_df.join(\n",
        "    broadcast(city_df),\n",
        "    on=\"city\",\n",
        "    how=\"left\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "IiDtDGrI8_S7"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PFLiShSqamDs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}